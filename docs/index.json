[{"authors":["admin"],"categories":null,"content":"Claus Wilke is the Jane and Roland Blumberg Centennial Professor in Molecular Evolution at The University of Texas at Austin. He holds a PhD in Theoretical Physics from the University of Bochum in Germany, and he received postdoctoral training in biological physics in the lab of Chris Adami at Caltech. Claus Wilke has published extensively in the areas of computational biology, evolutionary biology, protein biochemistry, and virology. He has also authored several popular R packages used for data visualization, such as cowplot, ggridges, and ggtext, and he is a regular contributor to the package ggplot2.\nOpinions expressed on this site are personal and are not meant to represent the official position of The University of Texas at Austin.\n","date":1599523200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1599523200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Claus Wilke is the Jane and Roland Blumberg Centennial Professor in Molecular Evolution at The University of Texas at Austin. He holds a PhD in Theoretical Physics from the University of Bochum in Germany, and he received postdoctoral training in biological physics in the lab of Chris Adami at Caltech. Claus Wilke has published extensively in the areas of computational biology, evolutionary biology, protein biochemistry, and virology. He has also authored several popular R packages used for data visualization, such as cowplot, ggridges, and ggtext, and he is a regular contributor to the package ggplot2.","tags":null,"title":"Claus O. Wilke","type":"authors"},{"authors":["Claus O. Wilke"],"categories":["Blogging"],"content":"  The R package blogdown has become a widely popular solution to setting up personal blogs. It makes it super easy to set up quite elaborate websites, and to write posts that contain R code, generated output and figures, footnotes, figure references, and math.1 However, one problem with blogdown is that it likes to re-knit .Rmd files.2 This may be fine if you’re just starting out with your site or if your posts generally don’t contain any sophisticated R code, but in a long-standing blog you’ll eventually run into trouble. First, re-knitting hundreds of posts may be quite slow. And second, if you’ve got a bunch of old posts chances are some will not knit anymore, and then you may have got a serious problem with no simple solution.\nThis problem has been recognized for a while, and the proposed solution is usually to knit only on demand. See e.g. here. The experimental hugodown package likewise aims to limit any unnecessary re-knitting. Here, I’m taking a different approach. My perspective is that I want to be able to re-knit any time without worrying that I’ll destroy anything of value, and I also want to be able to add code and output to posts containing prior code that doesn’t run anymore today.\nMy approach is to copy the knitted markdown code and output back into the .Rmd file. This requires some amount of manual work, but it’s not that bad, and I value the benefits I get from this approach. Maybe at some point somebody will write a package that can automate this process.\nI do not necessarily recommend the approach I’m taking here. This post is mostly for my own purposes, so I can retrace my steps in the future. If you want to see the source code resulting from this process, you can check out the source for this post on github.\nTo provide an example scenario, I include here one chunk of R code that generates a figure. This code has various features that will likely generate issues in the future or in a blog with many posts:\n It depends on a bunch of packages, including one only available from github. It uses various fonts that need to be installed locally. It is slow to render.  So it is critical that we can capture the output and don’t ever have to re-render it again.\nHere is the example:\nlibrary(tidyverse) library(cowplot) library(colorspace) library(sf) library(ggtext) # attach data set, requires practicalgg package # remotes::install_github(\u0026quot;wilkelab/practicalgg\u0026quot;) data(texas_income, package = \u0026quot;practicalgg\u0026quot;) ggplot(texas_income, aes(fill = estimate)) + geom_sf(color = \u0026quot;white\u0026quot;) + coord_sf(xlim = c(538250, 2125629), crs = 3083) + scale_fill_continuous_sequential( palette = \u0026quot;Blues\u0026quot;, rev = TRUE, na.value = \u0026quot;grey60\u0026quot;, name = \u0026quot;annual median income (USD)\u0026quot;, limits = c(18000, 90000), breaks = 20000*c(1:4), labels = c(\u0026quot;$20,000\u0026quot;, \u0026quot;$40,000\u0026quot;, \u0026quot;$60,000\u0026quot;, \u0026quot;$80,000\u0026quot;), guide = guide_colorbar( direction = \u0026quot;horizontal\u0026quot;, label.position = \u0026quot;bottom\u0026quot;, title.position = \u0026quot;top\u0026quot;, barwidth = grid::unit(3.0, \u0026quot;in\u0026quot;), barheight = grid::unit(0.2, \u0026quot;in\u0026quot;) ) ) + labs(caption = \u0026quot; \u0026lt;span style=\u0026#39;font-family: \\\u0026quot;Font Awesome 5 Brands\\\u0026quot;\u0026#39;\u0026gt;\u0026amp;#xf099;\u0026lt;/span\u0026gt; @clauswilke\u0026lt;br\u0026gt; \u0026lt;span style=\u0026#39;font-family: \\\u0026quot;Font Awesome 5 Free Solid\\\u0026quot;\u0026#39;\u0026gt;\u0026amp;#xf781;\u0026lt;/span\u0026gt; clauswilke.com \u0026quot;) + theme_map(12, font_family = \u0026quot;Myriad Pro\u0026quot;) + theme( legend.title.align = 0.5, legend.text.align = 0.5, legend.justification = c(0, 0), legend.position = c(0.02, 0.1), plot.caption = element_markdown() )  Figure 1: Median annual income in Texas counties. Figure redrawn from: Wilke (2019) Fundamentals of Data Visualization, Chapter 4.  Next I’ll provide the exact recipe I follow to capture the output from such code.\nAt the top of your .Rmd file, add an R chunk containing the following:\n```{r echo = FALSE} knitr::opts_chunk$set(fig.retina = 2) ``` This will ensure that figures are rendered in high quality. Set echo = FALSE for this chunk so the code isn’t included in the rendered output.\n Stop the blogdown server with blogdown::stop_server(). We don’t want the server to try to create blog posts out of the intermediate files we’ll be creating.\n Add the following to the yaml section of your post:\noutput: \u0026nbsp;\u0026nbsp;html_document: \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;keep_md: yes  If you want to use bookdown-style automated figure references, use this snippet instead:\noutput: \u0026nbsp;\u0026nbsp;bookdown::html_document2: \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;keep_md: yes  This requires the bookdown package to be installed.\n Knit your post. You will end up with a new file index.md and a new folder called index_files. The former contains the markdown code that knitr has generated and the latter contains any generated figures.\n Now you want to copy the generated code and output chunks from index.md back into index.Rmd. For each code chunk in your .Rmd file, there will be one or more markdown chunks, which are fenced with ```r ...```. There will also be markdown or HTML code to include any generated figures. Place all of this material after the respective code chunk from which it originated, but do not delete the original code chunk. We want to keep the original code chunks around in case we do want to re-run some of the R code again in the future, e.g. if the post needs an update.\n Next, you need to move the generated figures into a safe location. This ensures that they won’t be deleted when blogdown rebuilds the site the next time. I simply move the folder index_files/figure-html to figure-html.\n Edit figure links to reflect the move from the previous step. Figure links may be included either as markdown links, such as ![](index_files/figure-html/map-Texas-income-1.png), or as html links, such as \u0026lt;img src=\"/blog/2020-09-08-a-blogdown-post-for-the-ages/index_files/figure-html/map-Texas-income-1.png\" .... Which is the case depends on the exact chunk options you used to generate the figure. In either case, delete index_files/ from all figure links.\n Delete the file index.md.\n Remove or comment out the output: block you added under step 3.\n Add the following line to the code chunk added under step 1:\nknitr::opts_chunk$set(echo = FALSE, eval = FALSE)  This turns off all the R Markdown chunks in your post.\n Restart the blogdown server with blogdown::serve_site().\n  This may seem like a lot of steps and a lot of fiddling, but it’s really not that bad once you get the hang of it. Most blog posts, even elaborate ones, don’t have that many code chunks or figures, and manually copying and adjusting the markdown code takes much less time than writing the blog post in the first place.\nIn the future, if you need to update your post, you can either re-run all code by commenting out the line you added in step 10, or you can selectively turn on individual R chunks by setting their echo and eval options to TRUE. Then you repeat steps 1 through 11, but copying only whichever output needs to be newly copied over. At the end make sure you disable all R chunks once again.\n This post has one figure, Figure 1. It also has one equation, \\(a^2 + b^2 = c^2\\). The equation serves no purpose here.↩︎\n Throughout, I’m assuming you’re using .Rmd files. Everything I say should be valid for .Rmarkdown as well, though I haven’t tested this.↩︎\n   ","date":1599523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599523200,"objectID":"12922c6dc39c9d5c8a150f9009ea4ca0","permalink":"/blog/2020/09/08/a-blogdown-post-for-the-ages/","publishdate":"2020-09-08T00:00:00Z","relpermalink":"/blog/2020/09/08/a-blogdown-post-for-the-ages/","section":"blog","summary":"How to write a blogdown post that will still render in a hundred years from now.","tags":["Blogdown","R","Blogging","Markdown","R Markdown"],"title":"Writing a blogdown post for the ages","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Data science"],"content":"  Doing a PCA in R is easy: Just run the function prcomp() on your matrix of scaled numeric predictor variables. There’s just one problem, however. The result is an object of class prcomp that doesn’t fit nicely into the tidyverse framework, e.g. for visualization. While it’s reasonably easy to extract the relevant info with some base-R manipulations, I’ve never been happy with this approach. But now, I’ve realized that all the necessary functions to do this tidyverse-style are available in the broom package.\nFor our PCA example, we’ll need the packages tidyverse and broom. Note that as of this writing, we need the current development version of broom because of a bug in tidy.prcomp(). We’ll also use the cowplot package for plot themes.\nlibrary(tidyverse) # ── Attaching packages ────────────────────────────────── tidyverse 1.3.0 ── # ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 # ✓ tibble 3.0.3 ✓ dplyr 1.0.2 # ✓ tidyr 1.1.2 ✓ stringr 1.4.0 # ✓ readr 1.3.1 ✓ forcats 0.5.0 # ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── # x dplyr::filter() masks stats::filter() # x dplyr::lag() masks stats::lag() library(broom) # devtools::install_github(\u0026quot;tidymodels/broom\u0026quot;) library(cowplot) We’ll be analyzing the biopsy dataset, which comes originally from the MASS package. It is a breast cancer dataset from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. He assessed biopsies of breast tumors for 699 patients; each of nine attributes was scored on a scale of 1 to 10. The true outcome (benign/malignant) is also known.\nbiopsy \u0026lt;- read_csv(\u0026quot;https://wilkelab.org/classes/SDS348/data_sets/biopsy.csv\u0026quot;) # Parsed with column specification: # cols( # clump_thickness = col_double(), # uniform_cell_size = col_double(), # uniform_cell_shape = col_double(), # marg_adhesion = col_double(), # epithelial_cell_size = col_double(), # bare_nuclei = col_double(), # bland_chromatin = col_double(), # normal_nucleoli = col_double(), # mitoses = col_double(), # outcome = col_character() # ) In general, when performing PCA, we’ll want to do (at least) three things:\nLook at the data in PC coordinates. Look at the rotation matrix. Look at the variance explained by each PC.  Let’s do these three things in turn.\nLook at the data in PC coordinates We start by running the PCA and storing the result in a variable pca_fit. There are two issues to consider here. First, the prcomp() function can only deal with numeric columns, so we need to remove all non-numeric columns from the data. This is straightforward using the where(is.numeric) tidyselect construct. Second, we normally want to scale the data values to unit variance before PCA. We do so by using the argument scale = TRUE in prcomp().\npca_fit \u0026lt;- biopsy %\u0026gt;% select(where(is.numeric)) %\u0026gt;% # retain only numeric columns prcomp(scale = TRUE) # do PCA on scaled data As an alternative to scale = TRUE, we could also have scaled the data by explicitly invoking the scale() function.\npca_fit \u0026lt;- biopsy %\u0026gt;% select(where(is.numeric)) %\u0026gt;% # retain only numeric columns scale() %\u0026gt;% # scale data prcomp() # do PCA Now, we want to plot the data in PC coordinates. In general, this means combining the PC coordinates with the original dataset, so we can color points by categorical variables present in the original data but removed for the PCA. We do this with the augment() function from broom, which takes as arguments the fitted model and the original data. The columns containing the fitted coordinates are called .fittedPC1, .fittedPC2, etc.\npca_fit %\u0026gt;% augment(biopsy) %\u0026gt;% # add original dataset back in ggplot(aes(.fittedPC1, .fittedPC2, color = outcome)) + geom_point(size = 1.5) + scale_color_manual( values = c(malignant = \u0026quot;#D55E00\u0026quot;, benign = \u0026quot;#0072B2\u0026quot;) ) + theme_half_open(12) + background_grid()  Look at the data in PC coordinates Next, we plot the rotation matrix. The rotation matrix is stored as pca_fit$rotation, but here we’ll extract it using the tidy() function from broom. When applied to prcomp objects, the tidy() function takes an additional argument matrix, which we set to matrix = \"rotation\" to extract the rotation matrix.\n# extract rotation matrix pca_fit %\u0026gt;% tidy(matrix = \u0026quot;rotation\u0026quot;) # # A tibble: 81 x 3 # column PC value # \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; # 1 clump_thickness 1 -0.302 # 2 clump_thickness 2 -0.141 # 3 clump_thickness 3 0.866 # 4 clump_thickness 4 -0.108 # 5 clump_thickness 5 0.0803 # 6 clump_thickness 6 -0.243 # 7 clump_thickness 7 -0.00852 # 8 clump_thickness 8 0.248 # 9 clump_thickness 9 -0.00275 # 10 uniform_cell_size 1 -0.381 # # … with 71 more rows Now in the context of a plot:\n# define arrow style for plotting arrow_style \u0026lt;- arrow( angle = 20, ends = \u0026quot;first\u0026quot;, type = \u0026quot;closed\u0026quot;, length = grid::unit(8, \u0026quot;pt\u0026quot;) ) # plot rotation matrix pca_fit %\u0026gt;% tidy(matrix = \u0026quot;rotation\u0026quot;) %\u0026gt;% pivot_wider(names_from = \u0026quot;PC\u0026quot;, names_prefix = \u0026quot;PC\u0026quot;, values_from = \u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(PC1, PC2)) + geom_segment(xend = 0, yend = 0, arrow = arrow_style) + geom_text( aes(label = column), hjust = 1, nudge_x = -0.02, color = \u0026quot;#904C2F\u0026quot; ) + xlim(-1.25, .5) + ylim(-.5, 1) + coord_fixed() + # fix aspect ratio to 1:1 theme_minimal_grid(12)  Look at the variance explained by each PC Finally, we’ll plot the variance explained by each PC. We can again extract this information using the tidy() function from broom, now by setting the matrix argument to matrix = \"eigenvalues\".\npca_fit %\u0026gt;% tidy(matrix = \u0026quot;eigenvalues\u0026quot;) # # A tibble: 9 x 4 # PC std.dev percent cumulative # \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; # 1 1 2.43 0.656 0.656 # 2 2 0.881 0.0862 0.742 # 3 3 0.734 0.0599 0.802 # 4 4 0.678 0.0511 0.853 # 5 5 0.617 0.0422 0.895 # 6 6 0.549 0.0335 0.928 # 7 7 0.543 0.0327 0.961 # 8 8 0.511 0.0290 0.990 # 9 9 0.297 0.00982 1 Now in the context of a plot.\npca_fit %\u0026gt;% tidy(matrix = \u0026quot;eigenvalues\u0026quot;) %\u0026gt;% ggplot(aes(PC, percent)) + geom_col(fill = \u0026quot;#56B4E9\u0026quot;, alpha = 0.8) + scale_x_continuous(breaks = 1:9) + scale_y_continuous( labels = scales::percent_format(), expand = expansion(mult = c(0, 0.01)) ) + theme_minimal_hgrid(12) The first component captures 65% of the variation in the data and, as we can see from the first plot in this post, nicely separates the benign samples from the malignant samples.\n ","date":1599436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599436800,"objectID":"d07d84b988fdfb0f663377dbf1c9475a","permalink":"/blog/2020/09/07/pca-tidyverse-style/","publishdate":"2020-09-07T00:00:00Z","relpermalink":"/blog/2020/09/07/pca-tidyverse-style/","section":"blog","summary":"I've finally figured out how to perform a PCA using the tidyverse.","tags":["Principal Components Analysis","R","tidyverse"],"title":"PCA tidyverse style","type":"blog"},{"authors":null,"categories":null,"content":"Read the book for free here: https://clauswilke.com/dataviz\nPurchase the book on Amazon here: https://www.amazon.com/gp/product/1492031089\nLook at the book source here: https://github.com/clauswilke/dataviz\n","date":1597795200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597795200,"objectID":"2492445c9ab6032360c9ba5a432741e3","permalink":"/project/fundamentals_dataviz/","publishdate":"2020-08-19T00:00:00Z","relpermalink":"/project/fundamentals_dataviz/","section":"project","summary":"An open-source book on data visualization, entirely written in R Markdown.","tags":[],"title":"Fundamentals of Data Visualization","type":"project"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  It was time for a redesign. The previous layout was five years old, and it was looking dated. More importantly, the framework I had used wasn’t working for me anymore. I needed something simpler, more elegant, and more powerful.\nMy previous redesign happened exactly five years ago, when I moved this site from Squarespace to GitHub Pages with Jekyll. The transition to the static site generator Jekyll served me well, as it allowed me to write sites in Markdown and made it easier (compared to Squarespace) to include code examples. However, in many ways it was still too cumbersome, and in the end I rarely blogged anymore. At the same time, I was increasingly using R Markdown, and I have now written an entire book using this technology. This made me realize that I needed an R Markdown-based blog as well. Thus, the latest iteration of this site is built with the blogdown package, using the widely popular Hugo theme Academic. With the redesign also comes a move of the site from serialmentor.com to clauswilke.com. This was actually the original site location, though it existed only for a few days in August 2013. Going forward, I see this more as a personal site than a blog dedicated to a specific topic, and thus hosting it under my name seems the most appropriate. All the old posts will remain up, though, and links should automatically be forwarded.\nHowever, for technical reasons, it doesn’t seem possible to forward links to the site for my dataviz book, now located at https://clauswilke.com/dataviz, formerly at https://serialmentor.com/dataviz. Thus, if you visit that site regularly, you’ll have to update your bookmarks.\n","date":1597795200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597795200,"objectID":"97ae7ac4b363c648d29c1b0849143b5f","permalink":"/blog/2020/08/19/new-site-design/","publishdate":"2020-08-19T00:00:00Z","relpermalink":"/blog/2020/08/19/new-site-design/","section":"blog","summary":"I have redesigned this site and moved it to a new location.","tags":["Blogdown","Blogging","Github","Serial Mentor","Web hosting"],"title":"New site design","type":"blog"},{"authors":null,"categories":null,"content":"Many of my blog posts can be considered sections in books that I might have written but probably never would have. So, I\u0026rsquo;ve assembled some of these books as they get written.\n","date":1597708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597708800,"objectID":"5a7924b54b544301f785868904c6ac80","permalink":"/project/virtual_books/","publishdate":"2020-08-18T00:00:00Z","relpermalink":"/project/virtual_books/","section":"project","summary":"Blog posts collected into book-like form.","tags":[],"title":"Virtual Books","type":"project"},{"authors":[],"categories":null,"content":"","date":1580390580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580390580,"objectID":"4decf3efa539d3d06b789e91414d02e0","permalink":"/talk/rstudio_conf_2020/","publishdate":"2020-02-04T00:00:00Z","relpermalink":"/talk/rstudio_conf_2020/","section":"talk","summary":"The ggtext package provides various functions to add formatted text to ggplot2 figures, both in the form of plot or axis labels and in the form of text labels or text boxes inside the plot panel. Text formatting can be achieved through a small subset of markdown, HTML, and CSS directives. Features currently supported include italics, bold, super- and sub-script, as well as changing font size, font family, and color. Basic support for adding images to formatted text is also available.","tags":[],"title":"Spruce up your ggplot2 visualizations with formatted text","type":"talk"},{"authors":[],"categories":null,"content":"","date":1547744400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547744400,"objectID":"30e9c66d9523f8b3f171ead46776f023","permalink":"/talk/rstudio_conf_2019/","publishdate":"2019-01-20T00:00:00Z","relpermalink":"/talk/rstudio_conf_2019/","section":"talk","summary":"Uncertainty is a key component of statistical inference. However, uncertainty is not easy to convey effectively in data visualizations. For example, viewers have a tendency to interpret visualizations of the most likely outcome as the only possible one. Viewers may also misjudge the likelihood of different possible outcomes or the extent to which moderately rare outcomes may deviate from the expectation. One way in which we can help the viewer grasp the amount of uncertainty present in a dataset is by showing a variety of different possible modeling outcomes at once. For example, in a linear regression, we could plot a number of different regression lines with slopes and intercepts drawn from the range of likely values, as determined by the variation in the data. Such visualizations are called Hypothetical Outcomes Plots (HOPs). HOPs can be made in static form, showing the various hypothetical outcomes all at once, or preferably in an animated form, where the display cycles between the different hypothetical outcomes. With recent progress in ggplot2-based animation, via gganimate, as well as packages such as tidybayes that make it easy to generate hypothetical outcomes, we can easily produce animated HOPs in a few lines of R code. This presentation will cover the key concepts, packages, and techniques to generate such visualizations.","tags":[],"title":"Visualizing uncertainty with hypothetical outcomes plots","type":"talk"},{"authors":["Claus O. Wilke"],"categories":["Visualization"],"content":"  I’m very excited to announce my latest project, a book on data visualization. The working title is “Fundamentals of Data Visualization”. The book will be published with O’Reilly, and a preview is available here. The entire book is written in R Markdown, and the figures are made with ggplot2. The source for the book is available on github.\nEven though the entire book is written in R Markdown, it is not a book on programming. The book is meant as a guide to making visualizations that accurately reflect the data, tell a story, and look professional. It has grown out of my experience of working with students and postdocs in my laboratory on thousands of data visualizations. Over the years, I have noticed that the same issues arise over and over. I have attempted to collect my accumulated knowledge from these interactions in the form of this book.\nAs of this writing, approximately half of the planned chapters are completed, and all completed chapters are available online. I will post future chapters as they become available. Since this is a work in progress, not everything may be completely finalized, and I may rewrite some of the posted chapters at a later date. I welcome feedback. If you see any errors or other problems, please open an issue on github. If you have suggestions for other topics to cover, or for datasets that would work well for certain chapters, please also feel free to record these suggestions as issues on github.\nWith very few exceptions, all figures in the book are generated straight from ggplot2, with no manual post-processing in photoshop or illustrator. (At present, the only exception is two figures in the chapter on image file formats.) Therefore, the book also serves as a showcase of what ggplot2 can do. I am using the bleeding edge of ggplot2 software development, though. To reproduce all the figures in the book, you may have to install current development versions of several R packages.\n","date":1516665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516665600,"objectID":"ebab5436ff2eec453a437ea3edbda17a","permalink":"/blog/2018/01/23/fundamentals-of-data-visualization/","publishdate":"2018-01-23T00:00:00Z","relpermalink":"/blog/2018/01/23/fundamentals-of-data-visualization/","section":"blog","summary":"I am writing a book on data visualization.","tags":["Books","Data visualization","ggplot2","O'Reilly","R Markdown"],"title":"Fundamentals of Data Visualization","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  “Read Strunk and White” is the near universal recommendation any student receives who needs to improve their writing. I have only two explanations for this frequent recommendation: 1. People have never actually read Strunk and White or don’t remember anything about it.1 2. People have never read any book on writing other than Strunk and White and hence have nothing better to recommend. To provide an alternative, here I would like to present my all-time favorite books on writing, covering three distinct topics: storytelling, copy editing, and writing productively. My recommendations are made from the perspective of the scientist as a writer. Nevertheless, the books I recommend are written for a broad audience and will likely be useful for anybody who is writing non-fiction documents.\nStorytelling Storytelling is probably the most important and least appreciated aspect of scientific writing. Every time you’re writing a scientific paper or a research grant, you need to tell a compelling story. Yet not many books on the market cover this aspect of writing. The one book that I’m aware of that does an outstanding job is Writing Science by Schimel:\n Joshua Schimel. Writing Science: How to Write Papers That Get Cited and Proposals That Get Funded. Oxford University Press, 2011.\n Schimel explains what makes a story exciting and interesting, how to turn your scientific findings into a compelling story without compromising scientific accuracy, and how to structure sentences, paragraphs, sections, and entire documents such that your readers remain interested and engaged.\n Copy editing The best story arc doesn’t get you very far if your individual sentences are incoherent, awkward, or confusing. There are many books on the market that teach you how to write grammatically correct and clear English sentences. Most of them are quite good. My all-time favorite among them is Line by Line by Cook:\n Claire Kehrwald Cook. Line by Line: How to Edit Your Own Writing. Houghton Mifflin Harcourt, 1985.\n This book does an amazing job of systematically covering the grammatical and stylistic issues every writer should be aware of, and all the while the book remains quite readable. Unlike most texts with an emphasis on grammar you can actually read the book cover to cover.\n Writing productively The last area where many writers struggle is productivity. Despite extensive knowledge of storytelling and grammar, your writing sessions may well consist of hours of staring at a blank piece of paper or an empty computer screen, with the occasional writing and subsequent deletion of a single awkward sentence. How to overcome this struggle is covered well in How to Write a Lot by Silvia:\n Paul J. Silvia. How to Write a Lot: A Practical Guide to Productive Academic Writing. American Psychological Association, 2007.\n It turns out that there isn’t that much to be said about how to write a lot, other than that you have to write a lot. Silvia’s book makes no pretense otherwise, and that’s why I like it. Silvia covers the key concepts in a few short and highly readable chapters.\n Bonus As a bonus book, I want to recommend:\n Richard L. Lanham. The Longman Guide to Revising Prose. Person Longman, 2006.\n I have previously blogged about this book. While everything it contains is in some form also covered in Cook 1985 and in Schimel 2011, Lanham’s book shines in its brevity. It will teach you some key writing skills by laying out a small number of highly effective editing techniques.\n  I’ll challenge anybody to read Strunk and White cover-to-cover without falling asleep, and to summarize afterwards what they have learned. The book is available online in its entirety, so feel free to take this challenge right now.↩︎\n   ","date":1510444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510444800,"objectID":"ae8216b5cc308e84e5de7f067d038b6a","permalink":"/blog/2017/11/12/move-over-strunk-and-white/","publishdate":"2017-11-12T00:00:00Z","relpermalink":"/blog/2017/11/12/move-over-strunk-and-white/","section":"blog","summary":"My all-time favorite books on storytelling, copy editing, and writing productively.","tags":["Academic writing","Copy editing","Story telling","Writer's block"],"title":"Move over Strunk and White","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Publishing"],"content":"  Today I posted a tweetstorm on publishing an article with F1000Research that was originally commissioned by Springer:\nWe just published this article in @F1000Research because of @SpringerNature's abusive licensing practices. https://t.co/Xx88jkA3ec — Claus Wilke (@ClausWilke) October 16, 2017    I received several requests to turn this into a blog post, so here we go. The blog post consists mostly of the text of the tweets, with some minor edits and clarifications.\nWe just published this article in F1000Research because of Springer’s abusive licensing practices. The article was originally written to become a chapter in a Springer book on methods in protein evolution, and it describes key protocols my lab uses to measure site-specific rates in proteins and correlate them with protein structure. We’ve published extensively on this topic in recent years, see e.g. Jack et al., PLOS Biology 2016.\nHowever, as a precondition of publishing, Springer wanted us to assign to them the exclusive, permanent copyright to the work (Figure 1). In essence, they wanted us to donate our work to them so they could lock it behind a paywall and make money off of it. I were an unpaid intern at Springer while writing the article, Springer’s request would violate US labor law. But since I’m an independent agent, I guess I’m allowed to make donations to a commercial entity.\n Figure 1: The copyright agreement I was asked to sign. Key phrases of the agreement are underlined in red. Most important is the word exclusive, which implies that the authors (us) lose any rights not explicitly enumerated in the remainder of the agreement.  You might ask me: “What exactly is it you are complaining about here? People sign these agreements all the time, as have you in the past. How is this case any different?” The difference is that in this case, there’s virtually no benefit, even non-monetary, that Springer provides to in return. I understand that people might be willing to sign away their copyright in return for Nature paper that gets them their next job or grant.1 But a chapter in a methods book? That isn’t even peer reviewed? It doesn’t bring me (or my trainees) any prestige, unless the article is widely available and people use it and cite it a lot. But Springer explicitly doesn’t want that, because they make money from people buying the book to read the method.\nI cannot let Springer own key protocols from my lab.\nAs if this alone weren’t enough, I also found my conversations with them disingenuous. In particular, when I asked for a non-exclusive agreement, they lied to me about what the agreement says (Figure 2). Note the phrasing “We don’t claim copyright or ownership of the content itself” in this is response by Springer. It is blatantly false. Remember the copyright agreement is exclusive. This means the authors lose all rights except those explicitly stated as retained.\n Figure 2: Statement by Springer representative. A Springer representative made this statement when I requested a non-exclusive copyright agreement.   Figure 3: Rights retained under the proposed copyright agreement.  Let’s take a look at the rights that we would have retained (Figure 3). Pay attention to the repeated occurrence of the word “content”. The person who drafted the copyright agreement knew very well that it would cover the contents of the contribution. That’s the point of copyright. So, according to Figure 1, we would have lost the right to communicate the content to non-scientists. This includes, for example, commercial entities that may want to use our protocols. We would also have lost the right to post a preprint of the work. And it is unclear whether we would have been allowed to post it on personal webpages. That depends on whether the visitors of our personal webpages can be considered to be scientists or not. We would certainly have lost the right to publish an updated version of the protocols at some future date with a different publisher. I wouldn’t even have been allowed to this paper in a future anthology of my most influential papers, assuming it would be distributed at some cost. (Unlikely that I’d want to, but that’s not the point.)\nFor all the above reasons, the paper is now with F1000Research, and you can read it free of charge, copy it, and build on it. Enjoy.\n Andrew Rambaut pointed out that Nature (the journal) does not require a permanent, exclusive copyright license anymore. This statement was later disputed by Daniel Himmelstein.↩︎\n   ","date":1508112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508112000,"objectID":"343e74c8529a087a3f607ce61cfee29e","permalink":"/blog/2017/10/16/Springers-abusive-licensing-demands/","publishdate":"2017-10-16T00:00:00Z","relpermalink":"/blog/2017/10/16/Springers-abusive-licensing-demands/","section":"blog","summary":"Springer wants to own the copyright to your research methods.","tags":["Academic publishing","Copyright","Licensing","Open access"],"title":"Springer's abusive licensing demands","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Visualization"],"content":"  Anybody who has been paying any attention to the data visualization scene knows that the summer of 2017 was the summer of joyplots. This type of visualization turned viral, probably not in small part fueled by the R package ggjoy that I wrote in July. However, I think it’s time to retire both the name “joyplot” and the ggjoy package, and as of today the ggjoy package is officially deprecated. A replacement package ggridges is in place and provides essentially the same functionality.\nThe term “joyplot” was coined by Jenny Bryan in a tweet on April 24, 2017:\nI hereby propose that we call these “joy plots” #rstats https://t.co/uuLGpQLAwY — Jenny Bryan (@JennyBryan) April 25, 2017   The idea was to honor the band Joy Division, whose 1979 album Unknown Pleasures features on its cover a visualization of radio waves as staggered lines, creating a 3D-like effect. This seemed like a good idea and the name caught on like wildfire.\nUnfortunately, when the name “joyplot” took off, nobody in the datascience community was aware of the origin of the name “Joy Division”. As described in the book House of Dolls, joy divisions were groups of Jewish women in Nazi concentration camps kept for the sexual pleasure of soldiers. The band Joy Division took their name directly from this book and even quoted from the book in one of their early songs.\nThus, as joyful as the name “joyplot” sounds to the uninformed, its history is rather dark, and we would do better using a different name. For this reason, I have decided to now call these plots “ridgeline plots”. Indeed, from day one, the ggjoy package contained a geom_ridgeline(), so I’m just keeping in this tradition. The new ggridges package uses this naming convention throughout, and all functions have been renamed accordingly. For example, geom_joy() is now called geom_density_ridges(). A complete list of all name replacements is provided here. Porting your code from ggjoy to ggridges should be as simple as a search-and-replace for all those functions in your code. If you run into any trouble, please let me know or open an issue on github.\n","date":1505433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505433600,"objectID":"f6085d157243e707dd3b11fd6741ff61","permalink":"/blog/2017/09/15/goodbye-joyplots/","publishdate":"2017-09-15T00:00:00Z","relpermalink":"/blog/2017/09/15/goodbye-joyplots/","section":"blog","summary":"It's time to find a better name for the plots formerly known as \"joyplots.\"","tags":["Data visualization","ggjoy","ggplot2","ggridges","R"],"title":"Goodbye joyplots","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  It is common for friction to arise between graduate students and their supervisors (PIs) over how many and what kind of papers the students need to publish before graduating. While on occasion the students’ complaint is that their PI keeps them from publishing,1 the much more common scenario is one where the PI wants the student to complete x papers in y journals while the student just wants to graduate and move on. When these conflicts come to a head, students usually start to inquire what the minimum requirements are before graduation.\nOf course there is only one correct answer to this question:\nA PhD thesis/dissertation does not in any way require papers be published from the work. https://t.co/AIGnIcDyY7 — Drug Monkey (@drugmonkeyblog) January 6, 2017   As much as PIs may want to impose a publication requirement, because it benefits them,2 they cannot require the students to do something that is entirely outside of the control of both student and PI. A PhD is defined as an independent body of research, performed by the student and assessed by the PhD committee. If the student has done the research proposed during the proposal defense and has written up the resulting work in the form of a thesis, then the committee needs to evaluate that work and, if it is of sufficient quality, grant the degree.\nThere are multiple reasons why requiring published papers as a condition of graduation is wrong. First, as all working scientists know, the peer review process can drag out months or even years, and it may take multiple submissions to multiple different journals before a paper is accepted. Much of this process is out of the hands of the author. Even a perfectly well executed and written paper can be held up forever, for all sorts of reasons that have nothing to do with the quality of the work. Thus, it is entirely unreasonable to ask a graduate student to wait until this process is over before being allowed to graduate.\nSecond, sometimes a reasonable effort at investigating a question simply doesn’t lead to important new insight. A student may have very carefully studied a system for many years, only to conclusively prove that the interesting results they saw in their first month in the lab were caused by temperature fluctuations in the incubator room. Such work would be appropriate for a PhD thesis but it would likely not be suitable for publication in a major research journal.\nThird, by requiring a published article, the PhD committee is skirting its responsibility to evaluate the student’s work. The committee is saying, in effect, that they cannot judge whether the work is PhD-worthy unless an external body (the editors and reviewers of a scientific journal) has judged the work to be worthy of publication.\nNow, having said all this, I am of course very much in favor of graduate students publishing their work. None of my past graduate students have graduated without at least one first-author paper, and I want all my graduate students to submit a paper as soon as possible, ideally in year one or two of their graduate career. Also, I generally expect a PhD thesis to consist of at least three distinct projects, which should have been developed to the point where they could be submitted as a journal article. But to the question of whether a publication is strictly required, the answer has to be “no.”\n There’s an inherent conflict of interest between students and PIs, in that minor, pedestrian papers will be of very little value to an established PI but can be of exceptional value to a graduate student who hasn’t published much and wants to apply for a fellowship or postdoc position. There’s a lesson here for prospective students or postdocs: If a lab publishes a steady stream of minor papers, it likely does so out of the PI’s sense of duty towards their mentees. A lab that only publishes in Nature, Science, and Cell will likely not be good for a significant chunk of its trainees, no matter how great it is for those that manage to be first author on one of the celebrated papers.↩︎\n What PIs will say is that any papers that haven’t been published by the time the student graduates will likely never be published. This statement is indeed true, in my experience. However, it also demonstrates that the paper is more important to the PI than to the student. In my opinion, any PI who cares so much about a given paper should just complete it themselves.↩︎\n   ","date":1483660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483660800,"objectID":"0d1d1f81ee89def98e2a2110e69eb1f0","permalink":"/blog/2017/01/06/do-you-have-to-publish-papers-for-a-phd/","publishdate":"2017-01-06T00:00:00Z","relpermalink":"/blog/2017/01/06/do-you-have-to-publish-papers-for-a-phd/","section":"blog","summary":"Universities cannot reasonably expect published papers as a requirement for graduation.","tags":["Academic publishing","Graduate school","PhD"],"title":"Do you have to publish papers to obtain a PhD?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  For a junior scientist, it can be a major blow when their manuscript is rejected. They have poured many months to years of their time into this project, have submitted the paper where they think it belongs, and the editor puts an end to their aspirations by rejecting the submission. However, more experienced scientists, in particular those with editorial roles at major journals, know very well that many a rejection is not final. Often, a rejection is only the first step in an ongoing negotiation with the journal, one that frequently ends with the eventual publication of the article. To level the playing field between the junior and the more senior scientists, here I’ll reveal this secret to the world: How to reject a rejection.\nThere are basically two strategies that you can pursue, appeal to the editor or resubmit anyways. In the following, I’ll briefly discuss the mechanics of each option and then give my opinion of which option should be used when.\nAppeal to the editor An appeal is a request to the editor to overturn the decision. Typically, a successful appeal will change the decision from “reject” to “major revision”, i.e., it will buy you the right to revise and resubmit. Some journals have complex and formal appeals processes while others handle appeals more informally. In all cases, you will initiate the appeal by contacting the editor and explaining why you believe the reviewer criticisms were either unwarranted or can be fully addressed in a revision. The initial contact to the editor could consist of just a brief email explaining the main issues, or it could be accompanied by a detailed point-by-point response to the reviewer comments.\nHow a journal handles an appeal depends on the journal’s policies and procedures as well as the specific appeal request you are making. The journal may send out your original manuscript to another reviewer, they may send your point-by-point response to the original reviewers, or they may involve one or more editors who didn’t handle the original submission. They may also ask you for more information, such as a detailed point-by-point response to the reviewer comments (if you haven’t sent one yet) or a revised manuscript draft.\nAn appeal can be a long, drawn-out procedure, in particular if you initiate it with just an email to the editor. The editor may take a week or two to respond to your original email, asking you for a detailed point-by-point response. Once you submit that, the editor may have it reviewed by multiple people (the original reviewers, new reviewers, or other editors), and this process may take as long as a typical review would take. After all this time has passed, the editor may then tell you that they need to see a revised manuscript before they can make any sort of decision. The revised manuscript will then again have to be re-reviewed, of course, and this review process will likely prompt further requests for revision, even in the best-case scenario that the appeal is ultimately successful.\n Resubmit anyways As an alternative to filing a formal appeal, you can also just go ahead, revise your manuscript, and resubmit. This will have to be under the guise that you have sufficiently revised the manuscript to the point where it can now be considered a new submission. The unethical way of doing this would be to change the title, change the abstract, and hope the editor won’t notice. I do not recommend this approach. The ethical way to proceed is to submit as a new submission but state clearly in the cover letter that an earlier version of this paper was previously reviewed and rejected. You should also submit a detailed response to the reviewer comments. The journal submission system may not have a special option to do so, since it thinks you’re submitting a new article, but you can always just upload your response as a supplemental file and point to it in the cover letter.\n Which option is preferable? Given the two options of either appealing or resubmitting anyways, most people would intuitively choose to appeal. Resubmitting without prior approval feels wrong and somewhat sneaky; most people need to know that they are welcome to resubmit before they feel comfortable doing it. Further, the act of appealing feels right: The reviewers were stupid, the editors didn’t get it, and I want to protest!\nHowever, if you consider the two options from the perspective of the editor, you’ll see that filing an appeal is almost always the worse option. The appeal, by its very nature, creates an adversarial relationship with the editor. You’re telling the editor they were wrong and need to change their decision. This adversarial relationship can make the editor negatively predisposed towards you. An appeal only makes sense, in my opinion, when the reviews were truly biased or otherwise off (e.g., contained unprofessional ad-hominem attacks), so that there is no way you can revise the manuscript to address the reviewer comments.\nIf you’re going the “submit as new manuscript” route, you’re putting the editor in a position where they are more likely to be positively predisposed towards you, even though it may not seem that way. First, note that you’re in effect asking the editor for a favor, namely the favor of connecting this new submission to the history of the previous submission and to use (some of) the previous reviewers. And asking somebody to do you a favor is a great way to get them to like you.1 Second, you’re providing the editor with a submission that is easy to handle. The editor already knows which reviewers to invite, which issues to look out for, and so on. So, as long as you appear to have made serious efforts to address the prior criticisms, the editor will likely be willing to go along and at least send the paper back out to review.\n How well does this work? What are the chances of success? After having read this post, will you now be able to publish all your work in Science and Nature? No, of course not. Appeals and uninvited resubmissions frequently are unsuccessful. However, they succeed often enough that you should at least consider going this route from time to time. If you never resubmit a rejected article you’re leaving money on the table. You can be certain that any PI who routinely publishes in high-profile journals does a lot of appealing and resubmitting of rejected articles.\nBut won’t the editors just get annoyed and put you on their blacklist? I think that’s unlikely, unless you become really obnoxious, e.g. by appealing a failed appeal or by not putting an honest effort into revising your manuscript. Remember that editors fundamentally want to work with you and want to give you a positive decision. They’re not editors because they enjoy handing out rejections all day. They are doing this thankless, poorly remunerated job primarily because they want to advance their field and their community.2 Thus, they’d much rather handle a good paper they can accept than a bad paper they have to reject.\nFinally, you should know that many editors reject papers that they expect to be resubmitted. My own rule is that if the reviewers have pointed out a potential major flaw in the work, one that may require a substantial rethinking of the entire paper, then I’d rather reject than ask for major revisions. I do this because to me calling for major revisions creates the expectation that the paper will be accepted after the revisions have been made. And I don’t want to string authors along, make them revise, and then reject at the very end of this long process.3\n  This is called the Ben Franklin effect, after Ben Franklin, who asked a rival legislator to lend him a rare book.↩︎\n Yes, this statement applies even to paid, professional editors.↩︎\n This doesn’t mean I never reject revised manuscripts. It just means I try to make my initial editorial decisions such that rejections after revision are rare.↩︎\n   ","date":1483315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483315200,"objectID":"f48f6007ad5d531f192c2d2e3f1769e4","permalink":"/blog/2017/01/02/how-to-reject-a-rejection/","publishdate":"2017-01-02T00:00:00Z","relpermalink":"/blog/2017/01/02/how-to-reject-a-rejection/","section":"blog","summary":"Just because a paper has been rejected doesn't mean the journal won't publish it.","tags":["Academic publishing","Peer review"],"title":"How to reject a rejection","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["R"],"content":"  Update June 16, 2019: This post is now three years old, and some of the advice given is now outdated. Most importantly, it is much better to use map_dfr() than map(...) %\u0026gt;% reduce(rbind).\nEverybody who is familiar with the R libraries for processing of tidy data, such as dplyr and ggplot, knows how powerful they are and how much one can get done with just a few lines of R code. However, similarly, everybody who has used them has probably spent more time bringing data into the appropriate tidy format than writing analysis and/or plotting code. In particular, one scenario that arises all the time is that even if data files are in tidy format, the entire dataset may be spread out over many individual files, and loading them all in and combining them into one large table can be cumbersome. Here, I want to demonstrate some neat tricks, using the relatively new package purrr and some recent additions to the package tidyr, that make loading and combining many data files a piece of cake.\nThe code shown here depends on the following R packages:\nrequire(readr) # for read_csv() require(dplyr) # for mutate() require(tidyr) # for unnest() require(purrr) # for map(), reduce() Reading in all files matching a given name As an example, we will consider a scenario where we have population census data for various cities, stored in individual csv files for each city. The data I’m using here comes from http://factfinder.census.gov/.\nThe first scenario we will consider is one where we want to read all csv files in the current working directory. To achieve this goal, we first list all *.csv files, using the function dir(). We find that there are three, for the cities Houston, Los Angeles, and New York:\n# find all file names ending in .csv files \u0026lt;- dir(pattern = \u0026quot;*.csv\u0026quot;) files ## [1] \u0026quot;Houston_TX.csv\u0026quot; \u0026quot;Los Angeles_CA.csv\u0026quot; \u0026quot;New York_NY.csv\u0026quot; We can then read in those files and combine them into one data frame using the purrr functions map() and reduce():\ndata \u0026lt;- files %\u0026gt;% map(read_csv) %\u0026gt;% # read in all the files individually, using # the function read_csv() from the readr package reduce(rbind) # reduce with rbind into one dataframe data ## Source: local data frame [15 x 3] ## ## location year population ## (chr) (int) (int) ## 1 Houston, TX 2011 2142221 ## 2 Houston, TX 2012 2177376 ## 3 Houston, TX 2013 2216460 ## 4 Houston, TX 2014 2256192 ## 5 Houston, TX 2015 2296224 ## 6 Los Angeles, CA 2011 3828604 ## 7 Los Angeles, CA 2012 3864724 ## 8 Los Angeles, CA 2013 3902005 ## 9 Los Angeles, CA 2014 3936940 ## 10 Los Angeles, CA 2015 3971883 ## 11 New York, NY 2011 8287000 ## 12 New York, NY 2012 8365069 ## 13 New York, NY 2013 8436047 ## 14 New York, NY 2014 8495194 ## 15 New York, NY 2015 8550405 Often, we want to read the data from a given directory rather than from the current working directory. The ability to define functions on-the-fly in purrr makes this easy:\ndata_path \u0026lt;- \u0026quot;city_data\u0026quot; # path to the data files \u0026lt;- dir(data_path, pattern = \u0026quot;*.csv\u0026quot;) # get file names data \u0026lt;- files %\u0026gt;% # read in all the files, appending the path before the filename map(~ read_csv(file.path(data_path, .))) %\u0026gt;% reduce(rbind) data ## Source: local data frame [15 x 3] ## ## location year population ## (chr) (int) (int) ## 1 Houston, TX 2011 2142221 ## 2 Houston, TX 2012 2177376 ## 3 Houston, TX 2013 2216460 ## 4 Houston, TX 2014 2256192 ## 5 Houston, TX 2015 2296224 ## 6 Los Angeles, CA 2011 3828604 ## 7 Los Angeles, CA 2012 3864724 ## 8 Los Angeles, CA 2013 3902005 ## 9 Los Angeles, CA 2014 3936940 ## 10 Los Angeles, CA 2015 3971883 ## 11 New York, NY 2011 8287000 ## 12 New York, NY 2012 8365069 ## 13 New York, NY 2013 8436047 ## 14 New York, NY 2014 8495194 ## 15 New York, NY 2015 8550405 Here, the expression ~ read_csv(file.path(data_path, .)) is a shortcut for the anonymous function definition function(x) read_csv(file.path(data_path, x)):\n# this code does the exact same thing as the previous code data \u0026lt;- files %\u0026gt;% map(function(x) read_csv(file.path(data_path, x))) %\u0026gt;% reduce(rbind) data ## Source: local data frame [15 x 3] ## ## location year population ## (chr) (int) (int) ## 1 Houston, TX 2011 2142221 ## 2 Houston, TX 2012 2177376 ## 3 Houston, TX 2013 2216460 ## 4 Houston, TX 2014 2256192 ## 5 Houston, TX 2015 2296224 ## 6 Los Angeles, CA 2011 3828604 ## 7 Los Angeles, CA 2012 3864724 ## 8 Los Angeles, CA 2013 3902005 ## 9 Los Angeles, CA 2014 3936940 ## 10 Los Angeles, CA 2015 3971883 ## 11 New York, NY 2011 8287000 ## 12 New York, NY 2012 8365069 ## 13 New York, NY 2013 8436047 ## 14 New York, NY 2014 8495194 ## 15 New York, NY 2015 8550405  Keeping auxilliary information about the files read One limitation of the previous approach is that we don’t keep any auxilliary information we may want to, such as the filenames of the files read. To keep the filename alongside the data, we can read the data into a nested dataframe rather than a list, using the mutate() function from dplyr. This gives us the following result:\ndata \u0026lt;- data_frame(filename = files) %\u0026gt;% # create a data frame # holding the file names mutate(file_contents = map(filename, # read files into ~ read_csv(file.path(data_path, .))) # a new data column ) data ## Source: local data frame [3 x 2] ## ## filename file_contents ## (chr) (chr) ## 1 Houston_TX.csv \u0026lt;tbl_df [5,3]\u0026gt; ## 2 Los Angeles_CA.csv \u0026lt;tbl_df [5,3]\u0026gt; ## 3 New York_NY.csv \u0026lt;tbl_df [5,3]\u0026gt; To turn this data frame into one useful for downstream analysis, we use the function unnest() from tidyr:\nunnest(data) ## Source: local data frame [15 x 4] ## ## filename location year population ## (chr) (chr) (int) (int) ## 1 Houston_TX.csv Houston, TX 2011 2142221 ## 2 Houston_TX.csv Houston, TX 2012 2177376 ## 3 Houston_TX.csv Houston, TX 2013 2216460 ## 4 Houston_TX.csv Houston, TX 2014 2256192 ## 5 Houston_TX.csv Houston, TX 2015 2296224 ## 6 Los Angeles_CA.csv Los Angeles, CA 2011 3828604 ## 7 Los Angeles_CA.csv Los Angeles, CA 2012 3864724 ## 8 Los Angeles_CA.csv Los Angeles, CA 2013 3902005 ## 9 Los Angeles_CA.csv Los Angeles, CA 2014 3936940 ## 10 Los Angeles_CA.csv Los Angeles, CA 2015 3971883 ## 11 New York_NY.csv New York, NY 2011 8287000 ## 12 New York_NY.csv New York, NY 2012 8365069 ## 13 New York_NY.csv New York, NY 2013 8436047 ## 14 New York_NY.csv New York, NY 2014 8495194 ## 15 New York_NY.csv New York, NY 2015 8550405  Creating filenames from data In the previous examples, we have read in all the data files in a given directory. Often, however, we would rather read in specific files based on other data we have. For example, let’s assume we have the following data table:\ncities \u0026lt;- data_frame(city = c(\u0026quot;New York\u0026quot;, \u0026quot;Houston\u0026quot;), state = c(\u0026quot;NY\u0026quot;, \u0026quot;TX\u0026quot;), area = c(305, 599.6)) cities ## Source: local data frame [2 x 3] ## ## city state area ## (chr) (chr) (dbl) ## 1 New York NY 305.0 ## 2 Houston TX 599.6 We want to use the city and state columns to create appropriate filenames and then load in the corresponding files. The code in its entirety looks as follows:\ndata \u0026lt;- cities %\u0026gt;% # start with the cities table # create filenames mutate(filename = paste(city, \u0026quot;_\u0026quot;, state, \u0026quot;.csv\u0026quot;, sep=\u0026quot;\u0026quot;)) %\u0026gt;% # read in data mutate(file_contents = map(filename, ~ read_csv(file.path(data_path, .))) ) %\u0026gt;% select(-filename) %\u0026gt;% # remove filenames, not needed anynmore unnest() %\u0026gt;% # unnest select(-location) # remove location column, not needed # since we have city and state columns data ## Source: local data frame [10 x 5] ## ## city state area year population ## (chr) (chr) (dbl) (int) (int) ## 1 New York NY 305.0 2011 8287000 ## 2 New York NY 305.0 2012 8365069 ## 3 New York NY 305.0 2013 8436047 ## 4 New York NY 305.0 2014 8495194 ## 5 New York NY 305.0 2015 8550405 ## 6 Houston TX 599.6 2011 2142221 ## 7 Houston TX 599.6 2012 2177376 ## 8 Houston TX 599.6 2013 2216460 ## 9 Houston TX 599.6 2014 2256192 ## 10 Houston TX 599.6 2015 2296224 I hope you have found these examples useful, and you will start loading files into nested data frames.\n ","date":1465776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560643200,"objectID":"a52346640724e1f3f5596c422528fd2f","permalink":"/blog/2016/06/13/reading-and-combining-many-tidy-data-files-in-r/","publishdate":"2016-06-13T00:00:00Z","relpermalink":"/blog/2016/06/13/reading-and-combining-many-tidy-data-files-in-r/","section":"blog","summary":"We commonly need to read many separate data files and combine them into one data frame. Here I show how this can be done with the tidyverse.","tags":["Data wrangling","dplyr","purrr","R","tidyverse"],"title":"Reading and combining many tidy data files in R","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Science","Nutrition"],"content":"  As regular readers of this blog probably know, I’m the paragon of a research parasite. I’m a computational biologist, and all I ever do is publish my own analyses of other people’s data. Except that one time, a few years back, when a senior clinical researcher stopped me in my tracks. Thanks to his careful and guarded stewardship of his data, I have been saved from drawing incorrect conclusions from his data and from publicly embarrassing myself by claiming his analysis is complete nonsense.\nThe story happened a few years back, when a senior clinical researcher (let’s call him X) published a paper claiming that egg-yolk consumption is nearly as bad for cardiovascular disease (CVD) as is smoking. As an avid egg lover, I wondered whether I should be concerned. Unfortunately, the manuscript was opaque and used statistical techniques I don’t trust (quantiling), so I contacted X and asked to see the raw data. He made me state that I did not have any ties, financial or otherwise, to the egg industry (I don’t), and then he shared his raw data with me under the condition that I would keep the data confidential and that he would be a co-author on any resulting publications. I accepted these conditions and took a look at the data.\nI quickly realized that X and his colleagues had made several statistical mistakes, and that in fact the data exonerated eggs as a culprit for CVD. I analyzed the data using a variety of different approaches, just to be sure, but the simplest and most obvious one was a principal components analysis (PCA). It showed clearly that the egg-consumption axis was orthogonal to the age/smoking/CVD axis. (To this day, it’s one of the cleanest examples I’ve ever seen of a PCA revealing distinct underlying trends in the data.)\nI wrote a brief report and shared it with X, who forwarded it to a colleague of his in the biostatistics department. Let’s call him Y. The response I received was quite astonishing. (I’m paraphrasing from memory here.) First, Y said that “Claus Wilke is a strong student.” I was a tenured professor at the time. Second, Y said that “we don’t use PCA in clinical research.” Never mind that simple correlation tests, ordinary regressions, and regularized regressions all supported the results I had found with the PCA.\nNow, since X and Y thought I was a good student who however didn’t understand how statistics work in the clinical practice, and since I thought X’s paper was a bunch of nonsense, writing a joint paper on this topic was out of the question. That’s alright by me. I don’t need to publish in nutrition, and I’m fine with not having to worry about being assassinated by the egg-substitutes industry. However, X’s paper is still out there, receiving almost 20 citations a year. And, more importantly, this paper and its associated data would serve as an ideal teaching tool for the dangers (and power) of multivariate statistics. Alas, I’ll have to let it go. I should probably just start collecting my own data set of carotid plaque thickness in patients that have or have not eaten eggs for many years.\nNote: If you’re wondering what all of this is about, read this editorial in the New England Journal of Medicine. You may also want to read this translation into English.\n","date":1453593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453593600,"objectID":"f6eefbbfe85eae580d0df70cebe88005","permalink":"/blog/2016/01/24/i-failed-to-parasitize-an-established-clinical-researcher/","publishdate":"2016-01-24T00:00:00Z","relpermalink":"/blog/2016/01/24/i-failed-to-parasitize-an-established-clinical-researcher/","section":"blog","summary":"Eating eggs is not as bad for you as smoking.","tags":["Eggs","Heart disease","Research parasite","Smoking"],"title":"The one time I failed to parasitize an established clinical researcher","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  No matter how experienced you are as a writer, how many papers you have written, you’ll likely never fully overcome this obstacle: Writing papers takes time. A lot of it. To get a paper submission-ready always takes longer than one would want, and it frequently takes longer than even the worst-case scenario prior projection. As writers, we need to understand what causes these delays, so that we can mitigate them (where possible) and also to simply be prepared for what lies ahead. Here I present three observations I’ve made over the years that explain why most papers take so long until they’re finally completed.\n\n1. Every senior co-author extends the writing process by at least a month, and often by much more There are multiple factors at work that cause this delay. First, you need to have a decent draft before you can even show it to your senior co-authors, as they will probably not want to fix typos or logical flow, correct grammar, look at shoddy figures, etc. Preparing this draft takes time. Then, once you finally send them the paper draft, they’re too busy to even look at it. Then, when they’ve finally read it, they question some of your most basic assumptions, ask for additional analyses, or argue the story is wrong. Either way, they send you back to the drawing board. And then the cycle repeats, potentially for each senior author on the paper.\nMaybe the best strategy here is to limit the number of senior co-authors on your paper.1 The second-best strategy, and the one you’ll have to pursue in many cases, is to simply accept that each additional co-author needs extra time and to plan accordingly.\n 2. Everything always takes at least 3 times longer than expected If you think something can be done in a week it will probably take a month, and if you think it can be done in a month it will probably take three. I have supervised a fair number of students and postdocs, sat on numerous PhD committees, and worked with many colleagues on a wide range on different projects, and I can’t think of many cases where things were completed in the projected time frame. Research is difficult, and there are always unexpected issues that crop up. Things break, the data look different than expected and require a change in approach, you get the flu, something else comes up that needs to get done immediately, etc.\nNote that I’m a bit more optimistic here than Hofstadter’s law is, but I’ve definitely seen things take way longer than originally expected, even when the original time estimate seemed already overly generous.\nThere’s one critical issue here, though, that you need to keep in mind: Don’t let this observation make you complacent and think “whatever, it’s going to take longer anyways, so I can take it easy.” If you plan to get something done in one week, it will likely take three, but if you accept three weeks from the outset it will likely take six. So plan to get things done quickly and at the same time accept that there will be delays, possibly major ones.\n 3. The real work starts once you have a first draft Students often think that their main work goal is the first complete draft. Once that goal is achieved, they assume, their work is basically done. In reality, the exact opposite is the case. Only once a first complete draft exists does the real work start. The first draft almost always reveals flaws in the work. Maybe there’s a gap in the logic. Or once everything is written up and put into figures and tables, the results look weak. Or your co-authors finally get to see how everything fits together and don’t like it (see Observation #1). Or maybe different parts of the work were done inconsistently. (I see this often in simulation studies, where the code evolves as the work progresses. These kinds of studies almost always require a complete re-run of everything, from start to finish, once the paper is basically done.)\nTo give just one anecdote, I once wrote a paper with two co-authors, A and B. Me and A had done most of the writing and fleshing out the details of the paper, while B had provided the initial idea and general conceptual thought. We were all copied on all emails regarding this manuscript, and we went through at least 20 different drafts. At a point when I thought we finally had a draft ready for submission, author B suddenly said that he read the entire paper carefully the previous day and thought there was a major hole in our argument. Author A and I disagreed, but author B insisted and we spent another month fixing this perceived hole.\nIn my experience, it frequently takes 3-6 months from first complete draft to submission, and I have seen longer delays as well. For this reason, I advocate writing things up as early as possible. The first draft is not the goal, it’s just the beginning!\n  The fastest I’ve ever gone from initial idea to paper submission was two weeks. That was a single-author paper.↩︎\n   ","date":1451260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451260800,"objectID":"797bef9b470837d1240e7b2de9ecea04","permalink":"/blog/2015/12/28/when-will-that-paper-be-ready/","publishdate":"2015-12-28T00:00:00Z","relpermalink":"/blog/2015/12/28/when-will-that-paper-be-ready/","section":"blog","summary":"Finishing a paper always takes longer than you think.","tags":["Academic writing","Writer's block"],"title":"When will that paper be ready?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  I came across a talk by Steven Pinker on “Linguistics, Style and Writing in the 21st Century.” The talk is excellent and covers several important areas of writing advice. One of them is the topic of active and passive voice. I was pleased to see Pinker give the same advice I have been teaching for a while: The adage “don’t use the passive voice” is nonsensical. Clearly, passive voice cannot be categorically the wrong choice. If it were, then why should it even exist in the English language? There must be a valid use for this grammatical construct. Pinker provides one, and I agree with him. Here I’ll present this perspective in my own words.\nTo fully understand when to use active or passive voice, we need to first grasp the concepts of the topic and the stress position. I have previously written a blog post about this topic. Please go ahead and read it now. I’ll wait.\nNow that we’re all on the same page, let’s proceed. The simple rule is this: Topic and stress trump active and passive. If the topic is the actor, use active voice. If the topic is being acted upon, use passive voice. Examples:\n Maria read a book.\nThe book was read by Maria.\n The first is a story about Maria. The second is a story about a book.\nAs we construct a story, it is natural to move back and forth between active and passive while keeping the story focused on one protagonist:\n John woke up with a splitting headache. Grudgingly, he got out of bed, brushed his teeth, and put on some clothes. As he walked down the stairs, he dreaded another boring day at the office. Yet, as he opened the door, he was greeted with the most amazing sight he’d ever seen.\n Notice how everything is active voice until we reach “he was greeted” in the last sentence. This sentence needs to be in passive voice, so that John can remain in the topic position and “the most amazing sight he’d ever seen” takes on the stress position. Any attempt to use active voice here would result in a much weaker sentence.\nThus, it is best not to worry too much about active or passive voice. Instead, focus on telling a clear story by placing the the correct elements into the topic and stress positions of each sentence.\nWhat’s the problem with passive voice, then? If things are so simple, why do we keep hearing the advice to avoid passive voice? Because there are concrete issues that can arise when passive voice is used to excess, and I’ll briefly highlight the most important ones.\nFirst, passive voice doesn’t convey action as strongly as active voice does. For example, consider these two sentences:\n Thomas baked a cake.\nThe cake was baked.\n The first evokes the image of a person being active in the kitchen, mixing ingredients together, putting serious effort into the creation of a cake. The second evokes the image of a cake sitting in the oven.\nSecond, passive voice makes it easy to hide the actor. For example, compare:\n I made a mistake.\nMistakes were made.\n The first clearly assigns blame, the second doesn’t. Some writers deliberately use passive voice to hide the actor.\nIn scientific writing, though, I think it’s more common that the actor is omitted not with ill intentions but merely due to a lack of writing skills, or maybe because of a false sense of modesty. The result, however, can be rather confusing. In particular, whenever I read an abstract written in the passive voice, I start to wonder whether the authors are providing background information from earlier work or telling me what they have done. For a recent example, consider the beginning of the abstract from this paper:\n A fluorinated silyl functionalized zirconia was synthesized by the sol-gel method to fabricate an extremely durable superhydrophobic coating on cotton fabrics by simple immersion technique. The fabric surfaces firmly attached with the coating material through covalent bonding, possessed superhydrophobicity with high water contact angle ≈163 ± 1°, low hysteresis ≈3.5° and superoleophilicity. The coated fabrics were effective to separate oil/water mixture with a considerably high separation efficiency of 98.8 wt% through ordinary filtering. [. . .]\n Finally, passive voice encourages complex sentences with low content-to-word ratio, with long prepositional phrases, and with nouns attempting to carry the action—in a word, the official style.\nIn summary, pay more attention to topic and stress positions than to active and passive voice. However, in case of doubt, choose active over passive constructs.\n ","date":1450483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450483200,"objectID":"290024b6ce1958c0c741cd49225625a0","permalink":"/blog/2015/12/19/dont-use-the-passive-voice/","publishdate":"2015-12-19T00:00:00Z","relpermalink":"/blog/2015/12/19/dont-use-the-passive-voice/","section":"blog","summary":"There's a place for passive voice in properly crafted narratives.","tags":["Academic writing","Active voice","Copy editing","Passive voice","Story telling"],"title":"Don’t use the passive voice?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  Michael Eisen recently announced his new website, which features a new publication list that doesn’t mention journal names anywhere:\nmade a new lab website - completely scrubbed any mention of journal titles - https://t.co/iTwYvWDwqX — Michⓐel Eisen (@mbeisen) December 6, 2015   This idea was quickly picked up by others, e.g.:\nFollowing @mbeisen, removed journal names from website. But also links to cites, almetrics, \u0026amp; preprints. https://t.co/bPqZgrr2iA — Jeffrey Ross-Ibarra (@jrossibarra) December 7, 2015   I spoke out against this idea, since I immediately had the gut-feeling response that something was wrong with it:\n@yanivbrandvain Yeah, I'm not on board with hiding journal names. That's @mbeisen's thing, and now also @jrossibarra, I guess. @jaimedash — Claus Wilke (@ClausWilke) December 7, 2015   However, at the time, I couldn’t quite formulate what I thought the key issue was. I have now given this more thought, and I’ve found various reasons why I think it’s a bad idea to hide journal names. However, I’ve also realized that most of these arguments don’t even matter. As I’ll argue here, hiding journal names from the publication list is directly at odds with the principles of openness and egalitarianism that people like Michael Eisen so strongly promote. Therefore, to put it bluntly, I think this practice stinks.\nWe need to realize that in the current world of scientific publishing, removing journal names from the publication list has cause and effect reversed. If we had reached a point where nobody cared about journal names,1 then removing them from the publication list and listing papers simply by author, title, and DOI would be the logical next step. But since, as of today, there are plenty of people in this world who do care about journal names, hiding them is counterproductive. We can state all we want that “people shouldn’t care about journal names,” but hiding these names from publication lists won’t make it so.\nThink about it this way: If you want to move towards a world where people care more about article content than journal name, who do you need to convince? Those who already agree with you, or those who disagree? Obviously the latter. What would be a meaningful action towards that goal? In my mind, the most important action is to demonstrate that the publication venue doesn’t matter that much, by publishing your best work in journals such as PLOS ONE, PeerJ, or F1000Research, or even by just posting studies on bioRxiv without submitting them to any journal at all. These actions would demonstrate to the world that you’re putting your money where your mouth is and that you don’t care about perceived journal impact. How would the world notice that you’re doing this? They might go to your website and see that you, the esteemed scholar and noted expert in your field, publish in “low-impact” journals and on preprint servers, validating these publication venues in the process.\nBy contrast, if you’re hiding the journal names from your website, this important message is not conveyed. At best, people will not notice where you publish. At worst, they may wonder what you’re hiding. And that’s where things are really getting counter-productive. Because, if you are an outspoken proponent of open access, of preprints, of post-publication peer review, of publishing in non-selective journals, then any paper you publish that violates these principles will weaken your message. And if you’re not even stating on your website where you’re publishing, you may be perceived as being dishonest. For example, on Michael Eisen’s publication list, over the last 3 years, I count one pay-walled Elsevier paper (!), two papers in the highly selective journal eLife, and several papers in the fairly selective journals Genome Research, PLOS Genetics, and PLOS Computational Biology. (These papers are easier to find on his Google Scholar page, since it lists journal names, but they’re all on his web site as well, I checked.) So clearly the Eisen lab does not publish everything they do as post-pub review on F1000Research or as eternal preprint on bioRxiv.\nTo be clear: I have no problems with publishing at venues such as eLife, Genome Research, PLOS Computational Biology, or even Science or Nature. I think that the NIH Open Access mandate solves the majority of the access issues.2 What I have a problem with is publishing in such journals and hiding that fact from your website while blogging about the evils of peer review. As long as you participate in the traditional peer-review system, as author, reviewer, or editor, you should be honest and transparent about where you publish.\nThere are other reasons why I think hiding journal names is a bad idea, and I may go into them in a future blog post. For now, I’ll just present to you, without further comment, this Google Scholar profile. In summary, hide journal names once everybody agrees that they don’t matter, but not one day earlier.\nUpdate 12/11/2015: This discussion was featured in a Nature News article.\n I doubt that time will ever come, but let’s assume it will.↩︎\n To the extent possible, I make sure that my own papers get submitted to PubMed Central. The most recent papers on my publication list may not have PMC numbers yet, because it always takes a while until papers make their way into PubMed Central. Also, for papers for which I’m not the corresponding author, I cannot always ensure that they get submitted there.↩︎\n   ","date":1449532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449532800,"objectID":"625f2a5d88f5d76fc07fec1752278406","permalink":"/blog/2015/12/08/hiding-journal-names-from-your-publication-list-stinks/","publishdate":"2015-12-08T00:00:00Z","relpermalink":"/blog/2015/12/08/hiding-journal-names-from-your-publication-list-stinks/","section":"blog","summary":"You can't convince people of your cause by hiding your publication venues from them.","tags":["Academic publishing","Open access"],"title":"Hiding journal names from your publication list stinks","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  Every scientist should know how to properly write and format figure captions and tables, yet this topic is rarely taught properly. We just hope that students and postdocs pick up this skill by osmosis. However, in my experience, this doesn’t necessarily happen or it may take a long time. To speed up this process, I gave a brief lecture on this topic in my graduate class today. Here are the slides I used. I hope you will find them useful.\nIf anything is unclear, please ask questions in the comments!\n Writing and formatting figure captions and tables – Claus Wilke, Nov. 2015\n","date":1448323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448323200,"objectID":"19a56562e9d5428b9f72227b989d6e58","permalink":"/blog/2015/11/24/formatting-figure-captions-and-tables/","publishdate":"2015-11-24T00:00:00Z","relpermalink":"/blog/2015/11/24/formatting-figure-captions-and-tables/","section":"blog","summary":"I provide the slides from a talk about how to format figure captions and tables.","tags":["Academic writing","Copy editing","Figure captions","Tables"],"title":"Formatting figure captions and tables","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  Regular readers of my blog will know that I regularly complain about Google Scholar’s handling of preprints, see e.g. here or here. Well, this week, I had the opportunity to raise my concerns to Anurag Acharya, the co-founder of Google Scholar. His initial response and the subsequent discussion have clarified several things. We now know:\nThe bug exists The Scholar team is aware of it They don’t know how to fix it They don’t think it’s a particularly pressing problem For any given paper, the problem will go away eventually, after several months or more  So what is this bug you’re talking about? In a nutshell, for papers with a preprint, the bug will prevent the final, official journal publication to appear in the Scholar database, often for many months. If you search for the article by title, only the preprint version will show. If you search by DOI, nothing will show. Importantly, other articles from the same issue of the journal will all be properly indexed in Scholar, but the one article that happened to have a preprint will be missing.\n Why should I care if the problem will fix itself eventually? Anybody who would like to encourage more scientists to post preprints should care. And any junior scientist should care twice. This bug can have a very real effect on the career of junior scientists, by limiting their visibility or making them appear much less successful or competent than they actually are. Here are a few very real scenarios the bug can cause:\n You know that John Smith posted an interesting preprint 2 years ago, and you wonder if that work was ever published. You search Google Scholar and only find the preprint. So you conclude the paper never saw the light of day or maybe is embattled in review. In truth, the paper came out 8 months ago in PNAS, but Google Scholar will hide that version from you.\n You consider hiring a promising young scientist as a postdoc or maybe even a faculty member. However, as you pull up their Google Scholar profile, you notice that over the last two years they seem to have published only preprints. And several of the articles they list on their cv don’t show up in the Scholar database at all. You conclude the scientist is dishonest and you decline the application.\n You post a preprint that contains an error. Thankfully, the error gets noticed in review and you fix it for the final publication (and/or post a new version of the preprint). However, Google Scholar keeps showing the old, erroneous version of the preprint, many months after the fix has been made. People keep reading the erroneous version and keep giving you grief over it.\n An important paper in your field is published, and you would like to know about it. However, since the paper had a preprint, the official article is hidden from Scholar, and Scholar won’t notify you that it came out.\n   But it happens only very rarely, right? That’s the stance of the Scholar team. It doesn’t mesh with my experience, though. Everybody I know who regularly posts preprints has been bitten by the bug. I cross my fingers every time I post one. And whenever I bring up this issue, some random person mentions that they have experienced the same. Also, my colleague Chris Adami just posted the following:\n. @ClausWilke A cursory look at just the first page of my Google Scholar shows that about half of my articles are affected by this bug. — Christoph Adami (@ChristophAdami) October 8, 2015   While this bug may be rare in some sense of the word “rare,” it happens frequently enough to be a real issue for real scientists and every-day users of Google Scholar.\n Is there a workaround? Not really. You can add papers manually to your Google Scholar profile, but that won’t make them show up in the search results. And they will also not be linked to the actual journal publications, a major drawback in my opinion. If you know of a preprint and are wondering whether it has been published or not, don’t check with Scholar. Check with some other data base, such as PubMed. Or just do a regular Google search. The preprint bug does not affect regular Google, which will find the papers that Google Scholar doesn’t know about.\nI hope that the Google Scholar team will eventually realize that this is an important issue to get right. In the mean time, if you have been bitten by the bug, please let me know, so we can build a record of cases and demonstrate this is an important issue. And, if you’re looking for the official publications of long-standing preprints, look for them using regular Google, not Google Scholar.\n ","date":1444262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444262400,"objectID":"23f0a2fd5fe08027f17712e7c28965f7","permalink":"/blog/2015/10/08/google-scholar-bug-redux/","publishdate":"2015-10-08T00:00:00Z","relpermalink":"/blog/2015/10/08/google-scholar-bug-redux/","section":"blog","summary":"I don't expect Google Scholar to ever fix the preprint bug.","tags":["Academic publishing","Google Scholar","Preprints"],"title":"The Google Scholar preprint bug redux","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  Bibtex is the reference manager for Latex. I have used it for 20 years, I have written over 100 papers with it, and I think it works really well. I have also rarely met anybody who could use it without messing up their bibliography in some way. Bibtex is an archaic program, written 30 years ago by a graduate student and never substantively changed or updated since. It uses an awkward database format for storing bibliographic entries and an atrocious, poorly-documented programming language for describing how bibliographic entries should be formatted. In fact, the most complete description of bibtex’s inner workings is aptly called Tame the BeaST. (This document is well worth the read for anybody using bibtex with some regularity.) To help ordinary mortals succeed with using Bibtex, I’m providing here a set of best practices and useful guidelines that help you steer clear of the worst pitfalls of Bibtex.\nMy guidelines are shaped by the following two insights, which I call the first and second law of Bibtex:\nNobody really understands Bibtex. All bibliography managers that automatically generate Bibtex entries mess things up.  A corollary of the second law is that all Bibtex entries need to be hand-curated to work correctly.1 The following sections address some of the most common issues that I see in daily Bibtex use.\nIncorrectly capitalized article titles Article titles in a reference list should be capitalized in sentence case. In a nutshell, this means that all words except the first one, proper nouns, and acronyms are spelled in lower case (see e.g. here for more details). Bibtex enforces this capitalization rule by automatically converting everything in the article title field to lower-case. This convention has the unfortunate side effect that proper nouns or acronyms, which should be capitalized, will be converted into lower-case as well. For example, the title “A review of HIV biology” will be typeset as “A review of hiv biology”. This conversion can be switched off by enclosing the words not to be converted into an extra pair of braces, like so:\ntitle = {A review of {HIV} biology} Many reference managers simply disable Bibtex’s conversion by enclosing the entire title in braces, like so:\ntitle = {{A review of HIV biology}} This seems like a smart idea, until you realize that the records that these reference managers pull are often capitalized in title case (all nouns capitalized), and this incorrect capitalization is then carried over to the bibliography. The only reliable solution is to manually curate all titles, enclose words with capital letters in braces, but otherwise do not use two pairs of braces around titles.\n Incorrectly abbreviated first names and missing middle initials Bibtex style files are inconsistent in how they handle author names. Most style files abbreviate author names, so that “John H. Smith” becomes “J. H. Smith” or “J H Smith” or “JH Smith”. However, some don’t. They leave the author names untouched and/or only add or remove periods. Yet we generally never want first names spelled out in a bibliography, they should always be abbreviated to initials only. Therefore, always abbreviate names in your Bibtex file, and leave a space between initials, like so:\nauthor = {J. H. Smith} or\nauthor = {Smith, J. H.} If you don’t leave a space between the initials, Bibtex will interpret the initials as a name and drop the second initial. For example, author = {JH Smith} will for many style files be typeset as “J. Smith”.2 I also recommend to always add periods after initials, even if some styles don’t typeset periods in the final bibliography. In general, Bibtex style files are better at removing periods when they aren’t needed than at adding them when necessary.\n Mangled author lists In Bibtex’s author field, author names are separated by the key word and. It is a common mistake to use a comma instead. Bibtex will then think that all the names separated by commas are actually part of one long name, and will produce a mangled author list. Usually, what it will do is turn the entire author list into middle initials for one author, so that you end up with something like “Smith, D. M. B. K. F. L. E. O. S.” Fortunately, it will produce a warning as it does so (Too many commas in name...). Unfortunately, many Bibtex users ignore these warnings.\nIgnoring warnings comes particularly easy when you use an integrated latex environment that compiles the text as you type. An example would be the online editor https://www.overleaf.com/. However, all Latex editors do display errors and warnings when you look for them, so make it a habit to do so.\n Inconsistent journal names Bibtex will not abbreviate journal names for you. So you have to do this yourself, and do so consistently. I recommend to always add periods after abbreviated parts of journal names, even if the style you’re currently using doesn’t require periods there (i.e., write journal = {Mol. Biol. Evol.}, not journal = {Mol Biol Evol}). At some point you’ll use the Bibtex entry with a different style file that needs periods, and things will go wrong. Again, Bibtex is better at removing periods than it is at adding them.\nSome people define Bibtex string variables for journal names to keep them consistent. This is a reasonable practice, but I personally don’t use it. If you want to learn how this works, read the Tame the BeaST document, page 21.\n Superfluous issue numbers, publication months, or other elements Very few journals typeset issue numbers or publication months in their bibliographies. Yet reference managers like to populate the number or month fields that Bibtex provides. This leads to ugly and non-standard reference entries. Moreover, it’s rare that every entry in a Bibtex file has a completed number field, with the result that some entries in the final bibliography will have numbers listed and others won’t. Therefore, as a matter of principle, I always delete all number and month fields in every Bibtex entry. I also delete all other fields that I don’t explicitly want to show up in the typeset reference.\n Choosing good Bibtex reference keys Finally, I would like to provide some thoughts regarding how to choose keys to refer to Bibtex references. (I.e., how do you choose the identifiers you use in the \\cite{} command in your Latex file.) Most importantly, it is a good idea to have a systematic approach to choosing keys. Ideally, you should be able to guess the key from looking at the reference. This rule protects you from accidentally duplicating a reference in the Bibtex file and referring to it under two different keys. I personally use keys that mirror a traditional author-year citation style, e.g. SmithMiller2012 or Jonesetal2014. For papers with multiple authors, I would recommend against using just the first author name and the year, such as Jones2014, because in my experience it is not unusual to have multiple papers from the same year with the same first author, and at that point the keys become confusing. Which paper was Jones2014a again, and which one Jones2014b? By contrast, JonesSmith2014 and JonesMiller2014 are much easier to keep apart.\n Checklist Here is a final checklist you should go through every time you write a manuscript using Bibtex. (Some entries in the checklist also apply to Latex more broadly.) Most importantly, always read through the entire bibliography of your paper before submitting.\nCapitalization   Are all article titles typeset in sentence case, or do some remain in title case? Are any proper nouns or abbreviations typeset in lower case even though they should be capitalized?  Author initials   Are all author first names replaced by initials? Are all middle initials present? (This may be cumbersome to check, but a warning sign would be the presence of multiple references in which no authors have middle initials. Most authors do have middle initials.)  Author lists   Are author names showing up properly and completely? Warning signs would be papers that appear to be written by one or two people with way too many initials (four or more; few authors have four initials).  Journal names   Are all journal names properly abbreviated? Are journals named consistently throughout the bibliography?  Superfluous items in bibliography   Do any references contain items that shouldn’t be there, such as issue numbers, months, ISSN or ISBN numbers, or article URLs?  Compilation   Do Latex and Bibtex run on your document without raising any errors or warnings?    Actually, the second law applies more generally to pretty much any reference manager, including Zotero, Mendeley, Endnote, and so on, but that is a topic for another blog post. If you use one of them and don’t believe me, check if your article titles are properly capitalized, using sentence case. And if you don’t know what that means, re-read the section on incorrectly capitalized article titles.↩︎\n To add insult to injury, on occasion I have encountered Bibtex style files that actually require initials to be listed without space. Those style files would drop the second initial when there was a space. In the end, you’ll always have to check manually that everything is working as expected, and adjust Bibtex entries as necessary.↩︎\n   ","date":1443744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443744000,"objectID":"8fcebb1cc18e28d822e9b7e1c6692380","permalink":"/blog/2015/10/02/bibtex/","publishdate":"2015-10-02T00:00:00Z","relpermalink":"/blog/2015/10/02/bibtex/","section":"blog","summary":"Manual curation is the only reliable approach to reference management.","tags":["Academic writing","Bibtex","Copy editing","Latex","Reference manager"],"title":"How to not mess up your bibliographies with Bibtex","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  Nobody turns into a good writer over night. Writing well takes a lot of dedicated practice, as well as mastery of many different topics, including grammar, punctuation, word choice, and document organization. However, if I had to name one single skill that likely makes the biggest difference in a person’s ability to write well, I would point to recognizing and avoiding the official style. This style, named so by professor of rhetoric Richard Lanham, makes heavy use of passive voice, prepositional phrases, and complex, wordy expressions with little content. And it permeates the scientific literature.\nTo give you a concrete example of this style, consider the following excerpt. It comes from a paper describing the function of the gene exon0 in a baculovirus:1\n The TEM results provide evidence that EXON0 is required for the efficient egress of nucleocapsids from the nucleus to the cytoplasm. The conservation of EXON0 in all lepidopteran nucleopolyhedroviruses suggests that it may play a role in facilitating a common transport pathway for nucleocapsid egress for this group of baculoviruses. However, exon0 is not strictly essential for the production of BV, since a few nucleocapsids in the cells transfected with exon0 KO virus did pass through the nuclear membrane, followed by transport through the cytoplasm and budding at the plasma membrane. Two possible explanations are that the EXON0-facilitated nucleocapsid transport process can be bypassed and that other viral and cellular proteins can replace EXON0, although extremely inefficiently.\n In this excerpt, we can identify all the major elements of the official style. First, we see extensive use of passive voice, such as “EXON0 is required,” “exon0 is not . . . essential,” and “the . . . nucleocapsid transport process can be bypassed.” Second, we see long strings of prepositional phrases, as in “. . . required for the efficient egress of nucleocapsids from the nucleus to the cytoplasm.” Third, we see wordy expressions with little content, as in “. . . suggests that it may play a role in facilitating. . .”\nSo what can we do to avoid this style? A set of five simple editing guidelines provides a handy toolkit for writing more pleasant, less official-sounding prose:\nLocate prepositions and is forms. Identify the action and put it into a simple verb. Get to the point quickly. Read the passage aloud—does it flow? Vary the sentence length.  By following these guidelines, anyone can turn a dry, official-sounding document into a much more engaging piece of text. I have based these guidelines loosely on those presented in Lanham’s book,2 though none of them are particularly novel for experienced copy writers or editors.\n1. Locate prepositions and is forms The official style makes heavy use of long strings of prepositional phrases. Prepositions are short words such as in, on, or until that express relationships between objects, persons, times, or places (Figure 1). They are tremendously useful. But, when used in excess, they lead to boring, cumbersome, and frequently imprecise prose. Consider the following example. (I have highlighted the is form and the prepositions.)\n The cells were lysed with 1% Triton X-100 after 20 minutes incubation in rich media prepared under standard conditions with continuous stirring of the flask.\n I am sure you recognize this as a standard sentence you might find in the methods section of any molecular biology paper. If you have read many such papers, you may even find this sentence sufficiently clear. But is it really? Were the cells incubated or lysed in rich media? Were the cells incubated with continuous stirring of the flask, or was the stirring instead part of the media preparation? Or was maybe the flask stirred during the lysing of the cells? We don’t really know. The prepositions cannot precisely convey the relationships of the involved objects.\nThe above example contains six prepositions. In general, three prepositions in a row cause problems, and four or more prepositions usually guarantee disaster. As the first order of business, therefore, we shorten and/or remove, as much as possible, any strings of prepositional phrases.\nAt this point, some readers might want to defend the use of prepositional phrases. They might say:\n Prepositional phrases are perfectly clear. A preposition connects the object, time, or place that immediately precedes it with the one that immediately follows it. As long as all the prepositional phrases are in the right order, everything is perfectly clear.\n I disagree. Try to find the correct location for “with continuous stirring of the flask” if the flask was stirred during incubation. If you write “after 20 minutes incubation with continuous stirring of the flask in rich media,” then you are saying that the flask was in the media, when almost certainly the opposite was the case. If you write “after 20 minutes incubation in rich media with continuous stirring of the flask prepared under standard conditions,” then “prepared under standard conditions” seems to apply to the flask rather than the media. In addition, we often want to express that one thing is related to multiple others. In the above example, for instance, the authors might have meant to say that they carried out both lysing and incubation under standard conditions. The prepositions cannot unambiguously convey this meaning.\nWe can only eliminate strings of prepositional phrases if we can identify them. Therefore, Guideline 1 simply asks us to identify all prepositions and all is forms in each sentence.3 The subsequent guidelines will help us with rephrasing.\n\n across, after, at, behind, by, during, from, for, in, in front of, into, of, off, on, onto, out, out of, to, under, until\n Figure 1: Common prepositions in the English language.\n 2. Identify the action and put it into a simple verb With the exception of definitions—a chair is a piece of furniture to sit on—most sentences convey actions. Lots of them. Even the boring sentences in the methods sections of scientific papers. Actions are conveyed by verbs. Yet the most common verbs you will find in scientific texts are variants of to be. The actions instead hide behind nouns and in prepositions. Consider the cell-lysation example. This example contains the following actions:\n to lyse to incubate to stir to prepare  Yet none of these verbs actually occur in their active form in the example sentence. Instead they occur as participles or gerunds, that is, in the form of adjectives or nouns.\nLet’s consider a second example:\n Animals are housed on individually ventilated cages stacked in multiple layers with HEPA-filtered air provided to each cage.\n This example contains the following actions, again hidden in the form of participles or gerunds:\n to house to ventilate to stack to filter to provide  Once you have identified the relevant actions in a sentence, you can then express them in simple verbs. To provide you with some examples, Table 1 shows several long-winded is statements alongside their shorter, verb-based form.\n\nTable 1: Equivalent long and short expressions of the same action.\n  Long expression  Short and simple form    is causing the removal of  removes  is causing the modification of   modifies/alters  results in the elimination of  eliminates  effects the increase of  increases  is 57 words in length  contains 57 words  is 100 meters long  spans 100 meters  is greater than  exceeds  is resulting in  yields     3. Get to the point quickly Under Guideline 2, you have learned how to identify the action in a sentence and put it into a simple verb. Guideline 3 instructs you to get to the point quickly. Your readers have only so much attention—don’t squander it by writing long-winded phrases with little content. As an example of long-winded text, consider the following abstract of a paper investigating the inhibitory role of the protein NifL on the protein NifA:4\n . . . we localized inhibition by NifL to its carboxy (C)-terminal domain . . . The first line of evidence for this is that internal deletions of NifL containing an intact C-terminal domain were able to inhibit transcriptional activation by NifA in a coupled transcription-translation system. The second line of evidence is that the isolated C-terminal domain of NifL (assayed as a fusion to the soluble maltose-binding protein [MBP]) was sufficient to inhibit transcriptional activation by the central domain of NifA in a purified transcription system. The final line of evidence is that an MBP fusion to the C-terminal domain of NifL inhibited transcriptional activation by NifA in vivo. (104 words)\n This abstract contains the phrase “the . . . line of evidence . . . is that” three times, for a total of 23 words, 20% of the total text, with essentially no content. We can delete almost all these words without any loss of clarity or content:\n . . . we localized inhibition by NifL to its carboxy (C)-terminal domain . . . First, internal deletions of NifL containing an intact C-terminal domain were able to inhibit transcriptional activation by NifA in a coupled transcription-translation system. Second, the isolated C-terminal domain of NifL (assayed as a fusion to the soluble maltose-binding protein [MBP]) was sufficient to inhibit transcriptional activation by the central domain of NifA in a purified transcription system. Third, an MBP fusion to the C-terminal domain of NifL inhibited transcriptional activation by NifA in vivo. (84 words)\n As a simple editing rule, eliminate all phrases of the form “something something is that” (Figure 2). In most cases, these phrases don’t contain any content anyways. And even if they do, there will usually be better ways to provide this content. For example, consider the opening of this abstract:5\n Measurements of toxicity based on individuals . . . and effects on reproduction are used extensively in determining ecological risk . . . . An underlying assumption is that individual-based toxicity metrics for one species can be directly compared with that for another species. However, this assumption overlooks the fact that different species have different life-history strategies and variables, such as lifespan, time to first reproduction, and number of offspring produced over a lifetime. Using a simple model and laboratory-derived parameter values, we tested the impact of differences in life-history traits on predicted responses to stress. (89 words)\n This abstract contains the phrases “an underlying assumption is that” and “however, this assumption overlooks the fact that.” We would like to delete both. The resulting text might read:\n Measurements of toxicity based on individuals . . . and effects on reproduction are used extensively in determining ecological risk . . . . Such risk assessments directly compare individual-based toxicity metrics for different species. But species differ in life-history strategies and variables, such as lifespan, time to first reproduction, and number of offspring produced over a lifetime. Using a simple model and laboratory-derived parameter values, we tested the impact of differences in life-history traits on predicted responses to stress. (73 words)\n This version is quite a bit shorter, but it requires the reader to understand that life-history strategies and variables may affect the toxicity metrics and therefore may confound the comparison. This information was present in the original version of the abstract, if in a somewhat indirect way (“this assumption overlooks”). Therefore, in this particular case, I would opt for a slightly longer version. For example:\n Measurements of toxicity based on individuals . . . and effects on reproduction are used extensively in determining ecological risk . . . . Such risk assessments directly compare individual-based toxicity metrics for different species. But toxicity metrics may not be directly comparable, because species differ in life-history strategies and variables, such as lifespan, time to first reproduction, and number of offspring produced over a lifetime. Here, we tested the impact of differences in life-history traits on predicted responses to stress, using a simple model and laboratory-derived parameter values. (84 words)\n This version is almost as long as the original one. However, I believe it flows better and is easier to understand.\n\n The fact of the matter is that . . .\nThe reasoning behind this statement is that . . .\nThe general consensus is that . . .\nWhat most researchers believe is that . . .\nIt is this fact that is . . .\nThe conclusion is that . . .\nThe result of this experiment was that . . .\n Figure 2: Phrases of the form “something something is that.” These phrases generally convey no information and should be deleted.\n 4. Read the passage aloud—does it flow? When we are composing and/or editing a piece of text, we often spend so much time on small segments, inidividual sentences or phrases, that we lose track of the big picture. After half an hour of tinkering, we may have a paragraph whose every individual sentence is fine, but in combination the sentences don’t work. Fortunately, there is an easy way to identify these cases. Take a clean printout of your manuscript, sit down in a comfortable chair or sofa, and read the entire piece—aloud.6 (If you are working on a long manuscript, such as a book or a thesis, you may want to do this exercise separately for individual chapters or major sections.) While you are reading, pay special attention to the sound of your prose. Does it flow easily, or does it feel like a tongue-twister? Do the sentences connect nicely to each other? Do you always know where a sentence is going, or do you sometimes have to backtrack half a sentence because you thought it would finish differently than it actually did? Mark any issues that you see, but don’t fix them immediately. The purpose of this exercise is to get a sense of the larger structure of the text. If you immediately start tinkering with the text, you will lose that sense.\nAfter you have read your document carefully multiple times and marked all issues, go ahead and carry out the required edits.\n 5. Vary the sentence length The last guideline addresses sentence length. Consider the following paragraph from a paper on a new influenza treatment.7 Read this paragraph aloud, and note what you experience while doing so:\n Highly pathogenic avian influenza (HPAI) virus H5N1 strains are currently causing major morbidity and mortality in poultry populations across Asia, Europe, and Africa and have caused 385 confirmed human infections, with a fatality rate of 63.11%. Preventive and therapeutic measures against circulating H5N1 strains have received a lot of interest and effort globally to prevent another pandemic outbreak. Influenza A virus poses a challenge because it rapidly alters its appearance to the immune system by antigenic drift (mutating) and antigenic shift (exchanging its components). The current strategies to combat influenza include vaccination and antiviral drug treatment, with vaccination being the preferred option. The annual influenza vaccine aims to stimulate the generation of anti-hemagglutinin (anti-HA) neutralizing antibodies, which confer protection against homologous strains. Current vaccines have met with various degrees of success. The facts that these strategies target the highly variable HA determinant and that predicting the major HA types that pose the next epidemic threat is difficult are significant limitations to the current antiviral strategy. In the absence of an effective vaccine, therapy is the mainstay of control of influenza virus infection.\n To me, the paragraph feels monotone. Only towards the end does it become a bit more lively. The feeling of monotonicity is created by two factors. First, most sentences contain approximately the same number of words. Second, none is very short. The one exception is sentence six, which contains only nine words:\n  Sentence Number of words    Highly pathogenic avian influenza (HPAI) virus . . . 36  Preventive and therapeutic measures . . . 22  Influenza A virus poses a challenge . . . 26  The current strategies to combat influenza . . . 18  The annual influenza vaccine aims . . . 20  Current vaccines have met with . . . 9  The facts that these strategies target . . . 34  In the absence of an effective vaccine, . . . 17    As an alternative, consider this excerpt from an article on the effect of human activity on species diversity:8\n No one denies that population size influences speciation rate. However, the direction of its effect is in doubt. At one time, many evolutionists, led by Ernst Mayr, believed that small isolated populations provide the crucible for evolution. They believed that getting speciation started is a matter of breaking up coadapted complexes of genes in geographical isolates. If that is correct, small populations would speed up speciation by enhancing statistical sampling accidents. But an alternative view exists. Called “centrifugal speciation,” it claims that large populations speed up speciation. Centrifugal speciation also begins with geographical separation of sister populations. But after separation, the larger isolates—not the smaller ones—do the changing. The small ones remain as evolutionary relicts.\n We notice immediately that sentences in this paragraph are much shorter than they are in the previous example. And sentence length is also more varied. The shortest sentence has only five words. The third and fourth sentences are the longest. But with 19 words, they are still not overly long. And there is a good mix of short, medium, and long sentences in this paragraph. For example, after three moderately long sentences of 19, 19, and 15 words, the author placed a very short sentence of only five words:\n  Sentence Number of words    No one denies that population size influences . . . 9  However, the direction of its effect is in doubt. 9  At one time, many evolutionists, led by Ernst . . . 19  They believed that getting speciation started . . . 19  If that is correct, small populations would . . . 15  But an alternative view exists. 5  Called “centrifugal speciation,” it claims that . . . 11  Centrifugal speciation also begins with . . . 10  But after separation, the larger isolates . . . 13  The small ones remain as evolutionary relicts. 7    Thus we arrive at our take-home message, both for this section and for the entire blog post: Be bold. Write short sentences. And then vary the sentence length. Your readers won’t mind a somewhat lengthy sentence, with multiple dependent clauses, if you wrote a few very short sentences just beforehand.\n  M. Fang, X. Dai, and D. A. Theilmann. Autographa californica multiple nucleopolyhedrovirus EXON0 (ORF141) is required for efficient egress of nucleocapsids from the nucleus. J. Virol., 81:9859–9869, 2007.↩︎\n R. L. Lanham. The Longman Guide to Revising Prose. Person Longman, New York, 2006.↩︎\n We identify the is forms because prepositions and is forms go hand in hand. Sentences with long strings of prepositional phrases almost invariably sport an is form as the main verb.↩︎\n F. Narberhaus, H. S. Lee, R. A. Schmitz, L. He, and S. Kustu. The C-terminal domain of NifL is sufficient to inhibit NifA activity. J. Bacteriol., 177:5078–5087, 1995.↩︎\n J. D. Stark, J. E. Banks, and R. Vargas. How risky is risk assessment: The role that life history strategies play in susceptibility of species to stress. Proc. Natl. Acad. Sci. USA, 101:732–736, 2004.↩︎\n For a more systematic approach to text flow, take a look at my blog post on the topic and stress positions. However, this approach doesn’t eliminate the need for careful reading.↩︎\n N. Prabhu, M. Prabakaran, H.-T. Ho, S. Velumani, J. Qiang, M. Goutama, and J. Kwang. Monoclonal antibodies against the fusion peptide of hemagglutinin protect mice from lethal influenza A virus H5N1 infection. J. Virol., 83:2553–2562, 2009.↩︎\n M. L. Rosenzweig. Loss of speciation rate will impoverish future diversity. Proc. Natl. Acad. Sci. USA, 98:5404–5410, 2001.↩︎\n   ","date":1440547200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440547200,"objectID":"8982cccced87166fa7bb4d3ee776ab74","permalink":"/blog/2015/08/26/avoiding-the-official-style/","publishdate":"2015-08-26T00:00:00Z","relpermalink":"/blog/2015/08/26/avoiding-the-official-style/","section":"blog","summary":"A few simple writing rules make your prose much simpler and easier to understand.","tags":["Academic writing","Copy editing","Official style"],"title":"Avoiding the official style","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  After having hosted my blog on Squarespace for about two years, I have decided to move it over to Github pages. Squarespace was a reasonable and easy solution for me two years ago when I knew nothing about web hosting and web design, but I’ve increasingly grown frustrated and feel that I’m constantly having to fight with Squarespace to get it to do what I want it to do. I originally chose Squarespace because I didn’t want to maintain my own article database and I didn’t like the design and feature set of most popular blogging platforms such as WordPress or Blogger. In the mean time, I have learned about static page generators, and I now think that they are superior to most other options for basic blogs and other simple web pages. So I’ve redesigned my site using Jekyll for page generation, Bootstrap as CSS and JS framework, Google fonts and Font Awesome for typograpy and icons, and Disqus for comments.\nAs of this writing, the Squarespace site is still visible at http://clauswilke.com, but I’ll probably take it offline soon. In porting my site over, I have made sure that the direct links to posts remain the same, so that any bookmarks or direct links to posts should continue to work as before. The only difference may be the RSS feed, so if you’re subscribing through an RSS reader you may have to resubscribe to the new page. I have also ported all the comments, so the comments that were made on the Squarespace site are still visible on the new site.\nSo what were the things that bugged me about Squarespace? Most importantly, it felt like a huge black box, and I was worried that at some point all the work I was putting into my blog might just go up in flames if I wasn’t moving my data out in time. More specifically, here are six concrete issues I had:\nAll the site data are in a big, proprietary database. While Squarespace has an export function, that function exports only text. Any images or other files uploaded to Squarespace cannot easily be exported.\n Related to the previous point, there is no way to manage all the media files that one uploads to Squarespace. They live in some mysterious data store that Squarespace customers are not given access to. As a corollary of this set up, if one wants to use the same image in multiple posts one has to upload the image multiple times.\n While Squarespace posts can in principle be written in Markdown, Squarespace’s Markdown capabilities are limited and buggy. In particular:\n Code blocks are buggy. Specifically, Squarespace doesn’t properly escape special characters in code blocks. This can make embedding code into Markdown posts a big headache.\n Images cannot be inserted directly from the Markdown.\n To insert images, one has to break the Markdown into two parts and insert an image block in between. As one does so, Squarespace rewrites the Markdown and turns all inline links into reference-style links. While this doesn’t alter the page output in any way, I prefer to use software that doesn’t randomly rewrite my source code.\n The online Markdown editor Squarespace provides is slow and buggy. For longer pieces of text, the cursor is often displayed at the wrong location, so that it becomes difficult to edit the text at all.\n  It is not possible to extract excerpts of articles automatically. They need to be manually retyped. And excerpts cannot be entered in Markdown. And the formatting options for excerpts are limited. Excerpts simply don’t work very well in Squarespace at all.\n The Squarespace user interface seems slow and cumbersome to me. Anything I want to do requires a lot of clicks.\n Modifying the page design with Squarespace can be difficult. Certain superficial changes, such as colors or spacings, are generally easy. But other changes are difficult or even impossible. I frequently wanted to modify aspects of the design that I couldn’t. In theory, one can always inject custom CSS and modify the page that way. However, in practice it is often not clear how exactly the CSS would have to look, and which classes would need to be modified.\n  It took me about a day to set up the new web page on Github, and another two days to port all the posts over and fine-tune the page design. Since I had already written all my Squarespace posts in Markdown, copying them over to the new site was relatively straightforward. However, I took the opportunity to clean up some issues in most posts, so every post required 5-10 minutes of manual editing until it was properly ported.\nPorting comments was a little more difficult, but by following this guide I more or less made it work. It’s not perfect, and in particular the formatting is sometimes mangled, but at least the text is there. In general, I’m not too excited about having to use Disqus, since their business model relies on tracking users and selling ads, but the reality is that currently there is no viable competitor offering a comparable service, even for a fee. I have switched on guest posting in Disqus, so you can post comments here without having to sign up for a Disqus account.\nI am still fiddling with the page design on the new blog. I feel the current design is Ok but not great. However, now that everything is collected in simple Markdown files, I feel I’m operating from a much more robust base and can work on the page design as I go forward. Also, the entire blog source is now openly available at https://github.com/clauswilke/clauswilke.github.io. Feel free to check it out or use as the base for your own page. Also feel free to share or re-host any of my posts. All code (CSS, HTML, JS) is licensed under the MIT license, and all posts are licensed (individually) under the CC BY-ND license.\n","date":1438819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438819200,"objectID":"fe7ff0fda5001cdd20eb2c28cb31f585","permalink":"/blog/2015/08/06/goodbye-squarespace/","publishdate":"2015-08-06T00:00:00Z","relpermalink":"/blog/2015/08/06/goodbye-squarespace/","section":"blog","summary":"I have converted my blog into a static site hosted on Github.","tags":["Github","Jekyll","Squarespace","Web hosting"],"title":"Goodbye Squarespace, Hello Github","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  If you’ve been in science long enough, eventually you’ll have reached a point where you needed a safety project, either for yourself or for a student. A safety project is a project whose success is all but guaranteed, that doesn’t require much in terms of critical thinking or properly aligned stars. All that is required to complete a safety project is proper execution of the work.\nThe most common example I see is the graduate student in year four or five who doesn’t have a single completed project but needs to graduate in a year. Alternatively, maybe tenure is looming and your cv looks thin, you need some papers on a given topic before you can submit a grant on that topic, or you’re a postdoc looking for a job and you don’t have that many papers yet. In all these cases, it’s a good idea to pursue a safety project. More generally, it’s a good idea to have a portfolio of different projects where some are high-risk, high-reward and some are low-risk safety projects that you know will give you some sort of publication at the end. So let’s take a look at a couple of generic types of safety projects that can be pursued in almost any research field you may be working in.\nRepeat previous study with larger sample size or expanded conditions It is always possible to just redo an earlier study but to increase the scope somewhat. Choose a larger sample size, add experimental conditions, or use more recent raw data (if you’re doing bioinformatics). As long as your lab has the technical capability to carry out the study in the first place, there is really nothing that can go wrong here.\n Benchmark or compare competing methods For virtually any problem one might want to investigate, there are competing approaches to carry out the analysis. And it is rarely the case that we completely understand which approach is better, and under which conditions. So compare a couple of competing approaches in your area. Test them under a couple of different, carefully controlled conditions, and see how they perform.\n Write a methods or software paper If you have been working on some research topic for a while, chances are you have found some new ways of doing certain experiments, or you have written some software to do certain analyses. Thus, even if the actual experiments you have done don’t tell an interesting story, you may be able to just flesh out the methods or software you have developed and publish those.\n Review the literature on a topic Literature reviews are often overlooked as serious scholarly contributions, in particular by graduate students and postdocs. And while scientists who only ever write reviews will likely develop the reputation of never having an original thought, there’s nothing wrong with writing the occasional review to bolster your resume, in particular early in your career. If you’re a graduate student or postdoc and your original research hasn’t been that successful lately, you can at least write a review on the area you’re working on. Publishing a review demonstrates both your understanding of the field and your ability to complete a project. I’d rather hire a scientist who has published one original research article and one review than one who has published only one original research article.\nCan you think of other types of projects that are generally safe and rely only on careful execution? If so, please let me know in the comments.\n ","date":1435708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435708800,"objectID":"83e6db37b1879b5787149d38b3178730","permalink":"/blog/2015/07/01/safety-projects/","publishdate":"2015-07-01T00:00:00Z","relpermalink":"/blog/2015/07/01/safety-projects/","section":"blog","summary":"Sometimes you need to go after low-risk projects that may not be that exciting but are guaranteed to work.","tags":["Research","Graduate school","Postdocs"],"title":"Safety projects","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["R"],"content":"  This week, I finally took the time to clean up the code for my cowplot R package and submit it to CRAN. While the code had been up on github for a while, and I had blogged about it previously, nobody had really taken notice as far as I can tell. However, this time, with an official release and better documentation, people seem to like it a lot. The response on Twitter was overwhelming.\n@ClausWilke Thank you! Thank you! — Shaun Jackman (@sjackman) June 3, 2015  @ClausWilke @hadleywickham thank you, and goodbye illustrator, Photoshop, imagemagick, etc. — Stephen Turner (@genetics_blog) June 3, 2015  @ClausWilke @hadleywickham awesome !!! This makes making figures so easy !! — sahil seth (@sethsa) June 4, 2015  I love that the name cowplot is based on @ClausWilke's initials. New goal: create a package named madplot some day. :) — Meghan Duffy (@duffy_ma) June 4, 2015  New R pkg makes it easy to custom arrange, label ggplots on a canvas http://t.co/EQGjq9rOAE By @ClausWilke #rstats pic.twitter.com/Wi2kL3RnIw — Sharon Machlis (@sharon000) June 4, 2015  This looks awesome… I've been struggling with this issue a lot the last week or so. https://t.co/8YxNdocqMd — Andrew Kniss (@WyoWeeds) June 4, 2015  (A big thank you to @ClausWilke for developing the cowplot package so I could make this 2-panel figure.) #Rstats #ggplot — Andrew Kniss (@WyoWeeds) June 4, 2015   ","date":1433376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433376000,"objectID":"2e445654014df41c20d7aea3be772f3a","permalink":"/blog/2015/06/04/cowplot-r-package-now-available-on-cran/","publishdate":"2015-06-04T00:00:00Z","relpermalink":"/blog/2015/06/04/cowplot-r-package-now-available-on-cran/","section":"blog","summary":"It's the first time I've published an R package on CRAN.","tags":["cowplot","CRAN","Data visualization","ggplot2","R"],"title":"cowplot R package now available on CRAN","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Science"],"content":"  PLOS Biology recently published a nice article on data visualization:\n Weissgerber TL, Milic NM, Winham SJ, Garovic VD (2015) Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm. PLOS Biol 13(4): e1002128. doi:10.1371/journal.pbio.1002128\n It argues that we can do better than showing data as bars of mean height with error bars indicating standard deviations. In my lab, we use many of the proposed techniques already, see e.g. Fig. 4 in this paper. However, I’m glad that I now have a simple reference I can point people to when I want them to reconsider their figures.\n","date":1430265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430265600,"objectID":"4142be2a047fb037d34ba72118f2e076","permalink":"/blog/2015/04/29/beyond-bar-and-line-graphs/","publishdate":"2015-04-29T00:00:00Z","relpermalink":"/blog/2015/04/29/beyond-bar-and-line-graphs/","section":"blog","summary":"A new paper argues that scientists need to improve their data visualization skills.","tags":["Data analysis","Data visualization","Scientific writing"],"title":"Beyond bar and line graphs","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  PLOS ONE just published an article providing a cost-benefit analysis of grant writing:\n von Hippel T, von Hippel C (2015) To Apply or Not to Apply: A Survey Analysis of Grant Writing Costs and Benefits. PLoS ONE 10(3): e0118494.\n One of the main take-home messages: If you write more grants you will get more funding. Also, at current funding rates, unless you’re writing 2-3 proposals a year, you have a reasonable chance of going unfunded over a three-year period. The authors suggest that investigators should avoid programs with funding rates at 20% or less unless they are willing to write multiple proposals a year and/or have a particularly compelling research program. However, in biology practically all funding rates are 20% or less these days, so that advice isn’t very helpful. Instead, we just need to keep writing proposals. If you’re after NIH funding, you should probably write at least one proposal per cycle, unless you’ve been recently funded. If you’re primarily after NSF funding, with yearly cycles, you’ll have to diversify and find at least two programs to which you can send your proposals.\n","date":1427155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427155200,"objectID":"0e7bf42c0823b6b44f6d6204f3d0cd1b","permalink":"/blog/2015/03/24/plos-one-publishes-analysis-of-grant-writing-costs-and-benefitssafety-projects/","publishdate":"2015-03-24T00:00:00Z","relpermalink":"/blog/2015/03/24/plos-one-publishes-analysis-of-grant-writing-costs-and-benefitssafety-projects/","section":"blog","summary":"If you write more grants you will get more funding.","tags":["Grants","Funding","NIH","NSF"],"title":"PLOS ONE publishes analysis of grant writing costs and benefits","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  This semester, I’m teaching a new introductory class in computational biology and bioinformatics. The class is primarily targeted at undergraduates, and it is split approximately 50:50 between R and python. The R component emphasizes effective data analysis and visualization, using packages such as ggplot2 and dplyr. The python component will introduce students to basic programming concepts, and it will also cover some typical bioinformatics applications.\nDeveloping a new class is a lot of work, so I’ll probably have much less time for posting here on my blog. However, on the flip side, the entire course content will be posted online, and you can follow along here. The core of each lecture is an in-class exercise worksheet, and I’m posting the worksheets and the solutions online. Many lectures also have a brief traditional lecture component with slides as well as additional reading materials. I’m developing the course as I go, so there will be new material posted twice a week throughout the spring.\n","date":1423008000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1423008000,"objectID":"a0b5808734fac431fc27e988ba220e1e","permalink":"/blog/2015/02/04/teaching-a-new-introductory-class-in-computational-biology-and-bioinformatics/","publishdate":"2015-02-04T00:00:00Z","relpermalink":"/blog/2015/02/04/teaching-a-new-introductory-class-in-computational-biology-and-bioinformatics/","section":"blog","summary":"Undergraduates will learn basic data wrangling, plotting, and programming with R and python.","tags":["dplyr","ggplot2","python","R","Undergraduate education"],"title":"Teaching a new introductory class in computational biology and bioinformatics","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  There was a lively discussion on Twitter the other day regarding what constitutes a citable piece of scientific work. In particular, Matthew Hahn was concerned about where to draw the line, and he felt that unless something is traditionally published there’s no need to cite it. When reading this dicussion, I felt it was muddled by the lack of clear criteria separating citable works from other forms of scientific communication. In my mind, there is a clear distinction between preprints, which I consider to be citable works, and presentation slides or tweets, which are not. To formalize this distinction, I would like to propose four conditions that need to be satisfied for a document to be considered a citable piece of scientific work. The document needs to be: (i) uniquely and unambiguously citable; (ii) available in perpetuity, in unchanged form; (iii) accessible to the public; (iv) self-contained and complete.\n1. Uniquely and unambiguously citable It must be possible to uniquely and unambiguously refer to the particular work in question. This condition may seem trivial, but that’s not necessarily the case. For example, during the aforementioned Twitter conversation, Matthew Hahn brought up the case where somebody might tweet an entire paper or talk. Such a series of tweets would not be unambigously citable: One can cite an individual tweet but not a collection of tweets. While one could cite the first tweet in a series, assuming subsequent tweets were posted as replies, it would still remain ambiguous which specific tweets should be considered to comprise the entirety of the work. What if other users replied to the first tweet as well? And what if the original author then responded to them? The very nature of Twitter is such that the unique, citable unit is a single tweet, 140 characters or less, and that is not sufficient to convey a self-contained and complete scientific work. (Note that tweets also fail condition 2, since they can be deleted.)\n 2. Available in perpetuity, in unchanged form There needs to be some guarantee that the referenced document will not change and will be available in perpetuity. While nothing is truly forever, and works tend to get lost over time, documents hosted according to industry standards by large and established non-profit or for-profit publishing operations are not likely to disappear any time soon. This certainly includes documents posted on the preprint server arxiv.org, and probably also on the biorxiv server. Moreover, professional publishing operations generally do not allow changes to once-published documents, though they may allow for the publication of updates or revised article versions.\nImportantly, most privately hosted web sites and blogs do not satisfy this requirement.1 If I stop paying my web-hosting bill, this blog will disappear rather quickly. Similarly, any day I could decide that I didn’t like a particular post and rewrite or delete it, or I could delete the entire blog. And the same is true for institutionally hosted pages or lab web pages. Only those publishing platforms that are built with the express purpose of allowing perpetual access provide some amount of certainty that documents won’t just disappear or change.\n 3. Accessible to the public The document needs to be accessible to the public. This condition doesn’t necessarily require that access be free (though I personally would prefer it to be this way), since we have traditionally accepted that certain scientific works are only available after payment of a fee. However, anybody willing to pay the fee must be able to access the work, without any other conditions imposed. Also, libraries must be allowed to carry the work, and any library patrons must be able to peruse the work for free.\nThe point of this condition is to exclude internal technical documents of companies or other organizations, in particular, documents that might require signing a non-disclosure agreement. Such documents may be useful but they do not belong into the scientific record.\n 4. Self-contained and complete The document needs to be self-contained and complete. In other words, whatever the novel contribution is of a given piece of work, that contribution needs to be fully and clearly explained within the document. Many forms of scientific communication violate this condition. Consider for example the slides of a scientific presentation. They are meant merely as support to the oral presentation, and usually they cannot be fully understood without the accompanying talk. Now, if one wanted to, one could certainly write slides that are self-contained and complete. However, those slides would make for a poor talk and also would be nothing more than an awkwardly formatted preprint.\nEven if a recording of the talk is provided alongside the slides, the completeness condition will usually remain violated. For example, methodological details are frequently glossed over in presentations, as are parts of mathematical derivations in theoretical talks. However, this doesn’t mean that only written works can be scientific documents. For example, the Journal of Visualized Experiments (JoVE) publishes self-contained and complete video articles.\n But if it hasn’t been reviewed? I am a strong proponent of pre-publication review. I have said so before. At the same time, I am wary of what I’d like to call “the review fetish,” the attitude that scientific works can’t be trusted until they have been reviewed, at which point they become valid contributions to the scientific literature. Whether something has been reviewed has no bearing on its validity. A work is valid or it is not, period. We all know that flawed works pass peer review and valid works get rejected. In fact, the most influential and highly cited articles often get rejected initially.2 As working scientists, we need to personally judge the validity of each and every article we read, regardless of the article’s origin or review status.\nAlso, the only logical reason to require citable works to be peer reviewed would be as a means of quality control, so that bad science doesn’t get cited. However, it then immediately follows that we would have to assess the quality of peer review at each journal. What if some journals carry out sub-standard review and basically print everything? Should they be put on a blacklist of journals we can’t cite? What about contributed papers to PNAS, many of which likely haven’t received the same kind of scrutiny as articles that get edited by independent third parties? What about journals that employ professional editors, who may make decisions that aren’t always entirely driven by scientific considerations? Should we put those journals on the blacklist? In my mind, insisting on peer review for quality control reasons opens a can of worms that simply can’t be dealt with in any reasonable manner.\nFurther, while the current scientific culture expects that we submit all our articles to journals for review, I think scientists should be allowed to choose not to be subjected to this process. If some scientists prefer to skip peer review and simply post their work on a preprint server, it should be their prerogative to do so. And we should take their work seriously as long as it is worthwhile and of high quality. Clearly mathematicians do so. Consider the case of Grigori Perelman, who was awarded a Fields Medal, the highest honor bestowed upon mathematicians, for work he had posted on a preprint server but never formally published.\nFinally, I would like to point out that there are document types that have traditionally been considered part of the scholarly literature, such as monographs or dissertations, that are not necessarily reviewed. Journals that forbid citations to preprints do not usually impose similar restrictions on the citation of books or theses.\n Concluding thoughts With the four conditions I have outlined, we can easily test whether specific documents or works should be considered to be citable resources or not. Strings of tweets clearly fail the test, as do slides, recordings of talks, posters, tweets of photos of posters, or blog posts. Documents that pass the test are articles in traditional print journals, articles in most professionally operated online journals, books, book chapters, dissertations, and preprints deposited on professionally operated preprint servers. Interestingly, websites hosting scientific software will usually fail at least conditions 2 and 3, and thus would not be citable by my criteria. In fact, it is my opinion that scientific software should always be accompanied by an article introducing and explaining the software, and what we should cite is the article, not the website where the software is housed.\nImportantly, I can think of no principled test that would cleanly separate preprints from the rest of the scientific literature. The only such test I can think of is “has it been posted on a preprint server,” but it would be difficult to provide a logical reason for why this test should be applied to determine the citability of a document,3 other than personal preference. I might just as well not cite articles published in journals that don’t use at least 3 reviewers, or in journals where editorial decisions are made by professional editors and not by working scientists, or in journals that typeset their articles in a sans-serif font.\nUpdate 01/02/2015: Rafael Najmanovich suggested an additional condition: Attributable authorship. It should be clear who has written a specific document. While I agree with this condition in principle, I’m not sure yet whether I would go so far as arguing that anonymous documents should never be cited. If a document is anonymous but otherwise a valid contribution to science, should we ignore it? Probably not.\n  Klein et al. (2014) Scholarly context not found: One in five articles suffers from reference rot. PLoS ONE 9: e115253. doi:10.1371/journal.pone.0115253↩︎\n Siler et al. (2014) Measuring the effectiveness of scientific gatekeeping. PNAS, in press. doi:10.1073/pnas.1418218112↩︎\n Keep in mind that this entire post is about the conditions that make a document a citable contribution to the scientific literature. This is different from the question of whether a document is a preprint or a formally published article. The main services that journals provide are (i) quality control, in the form of editorial and peer review, (ii) prestige, in proportion to how selective they are, and (iii) professional typesetting, though the quality of this service has declined in recent years. In return, journals demand exclusivity. Thus, it is natural for a journal to determine whether a document has been previously published by asking whether the document has previously undergone editorial and peer review and has been professionally typeset. Importantly, when journals make this assessment, they are not concerned with the quality of peer review. Any document that has been reviewed and accepted for publication elsewhere, no matter how low the standards, would violate the exclusivity clause and hence is going to be considered published.↩︎\n   ","date":1420156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420156800,"objectID":"9c37a47716bb345640dd38a5f98f3500","permalink":"/blog/2015/01/02/what-constitutes-a-citable-scientific-work/","publishdate":"2015-01-02T00:00:00Z","relpermalink":"/blog/2015/01/02/what-constitutes-a-citable-scientific-work/","section":"blog","summary":"A paper does not have to be peer-reviewed to be citable.","tags":["Peer review","Preprints","Pre-publication review"],"title":"What constitutes a citable scientific work?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  PLOS ONE just published a paper comparing MS Word with LaTeX, which argues that LaTeX has little benefits over MS Word and should not be allowed by scientific journals:\n Knauff M, Nejasmic J (2014) An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development. PLoS ONE 9(12): e115069.\n In my mind, this paper makes extremely strong claims based on a rather flawed and thin analysis. I am sure there are useful things to be said about MS Word vs. LaTeX. However, this paper does not make much of a contribution to this question.\nTo give you some background: I have been using LaTeX for over 20 years, I have written tens of thousands of pages with LaTeX, and I am extremely familiar with its pros and cons. I am also using MS Word on a regular basis, and I regularly make the choice between using LaTeX or MS Word, on a document-by-document case. There are documents I’d rather write in LaTeX, and there are other documents I’d rather write in MS Word. There are also documents (increasingly many, in fact) for which I prefer entirely different approaches, such as Markdown. With that said, let me list the main objections I have to the Knauff and Nejasmic paper.\nApples and oranges The entire premise of the paper is flawed: MS Word is a text editor, LaTeX is a file format. Those two things are inherently not comparable. There is no technical reason why MS Word cannot save documents to LaTeX, only the creators of MS Word chose not to implement this option. A simple work-around exists, however: Save the document as .docx and convert it to LaTeX with pandoc. Incidentally, you can also go the other way round, write the document in LaTeX and convert to .docx. Fundamentally, file formats describing the same kind of data can be converted into each other. Therefore, people should be allowed to use the software and file formats they prefer (within reason, and preferably non-proprietary ones). Computers can sort out the differences.\n A rigged comparison The comparison the authors set up, the reproduction of three relatively simple, one-page documents, is entirely artificial and rigged to favor MS Word. This is particularly the case (and this is not really explained well in the paper) if the LaTeX users were tasked to reproduce the visual layout of the documents. LaTeX is meant to separate contents from layout, and the people who use it regularly tend to value that separation. However, this separation implies that it can sometimes be a bit difficult to achieve a particular physical layout. The correct, LaTeX way to solve this problem would be to prepare an appropriate style file. Yet I doubt the users in this test were given such a style file for the continuous text example (which poses some tricky formatting issues with the title, author list, and address line).\nFor anybody who has experience with both systems, it would be trivial to set up examples where MS Word utterly fails and LaTeX shines:\n Set up 50 numbered equations, refer to them throughout the text, then change the equation order.\n Have figures and their captions float to appropriate locations at the top or bottom of pages.\n Change the order of figures in a document and fix all references to those figures.\n   It’s not surprising that LaTeX users are highly satisfied Throughout the paper, the authors state (somewhat surprised, it seems to me) that LaTeX users are highly satisfied with their document preparation software. The authors seem to have no explanation for this observation, other than cognitive dissonance. In effect, the authors are saying that LaTeX is so awful that the only way to use it regularly is to convince yourself it is great even though it is not.\nThere’s a simple alternative explanation, though: Even though LaTeX can be cumbersome and has its quirks, LaTeX is highly predictable. Once you have figured out how something works, it always works that way. LaTeX never crashes. Documents don’t suddenly change layout or font. Tables don’t jump around. By contrast, none of this can be said about MS Word. Everybody who uses MS Word knows that it sometimes does things that simply can’t be explained. Things that should work don’t. Formatting changes randomly.\nIn my own experience, to produce a final document, I fiddle around about as much with MS Word as I do with LaTeX, only that the issues with LaTeX are usually the same three predictable things (proper formatting of the cover page, some table issues, getting all the references into BibTeX). By contrast, with MS Word I always fight against some random, unexplainable stuff.\n State of the art in document preparation What I find most amazing about the Knauff and Nejasmic paper, considering that it is a study on document preparation, is that the authors seem to be completely out of touch with the state-of-the-art developments in that field. The authors barely even mention the important distinction between document structure and document layout, and they don’t discuss at all why one might want to separate the two. They also don’t consider automatic document conversions for different media (e.g. web versus print). Finally, they don’t discuss the increasingly important issue, at least for scientific documents, of integrating the text of a paper with the code used for data analysis and figure generation.\nIn fact, there is plenty of room for improvement over LaTeX when it comes to document preparation. Most heavy LaTeX users would agree that the language can be cumbersome, and I haven’t met anybody who wouldn’t rather not type out all the LaTeX commands required to prepare a finished document. Extensive efforts are currently underway to address these and other issues, but these efforts are not happening in the world of MS Word.\nThe most exciting current developments, in my mind, are happening with Markdown. Markdown is an extremely simplified markup language that can be learned in half an hour or less. Markdown documents can be read easily in their source form (unlike LaTeX documents), and they can also be converted into HTML or PDF documents. (The PDF conversion usually goes via LaTeX as intermediate.) Moreover, through extensions such as R Markdown, one can easily combine the document text, the code for data analysis and figure preparation, and the final figures, all in a single file. The result is a publication-quality document that is easy to produce, self contained, and allows for complete reproducibility of the analysis and figure generation. I bet that if the comparison in the PLOS ONE paper had been MS Word vs. LaTeX vs. Markdown, Markdown would have won hands down.\n Does any of this matter? Why quibble over file formats and editors at all? As I said in the beginning, I use various tools, depending on the task at hand. As long as we can all agree that there are different use cases and that people can make informed decisions on which tool to use when, I’m fine. However, this is where the authors of the PLOS ONE paper go off the deep end. After presenting their relatively thin, somewhat rigged, and definitely not comprehensive comparison of one text editor to one file format, they then make incredibly strong claims, including that LaTeX users may be suffering from cognitive dissonance and that vast amounts of money could be saved if people were forced to switch over from LaTeX to MS Word. These statements are simply not warranted, they do not follow logically from the analysis presented, and they entirely disregard that the future of scientific document preparation may lay elsewhere (e.g., Markdown). If there is one thing this paper doesn’t make is a strong argument in favor of MS Word, and we must be careful not to allow journal editors or other policy makers to use arguments such as the ones made in this paper to force us into a single mode of document preparation.\n ","date":1419638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1419638400,"objectID":"a2642a66c77f8dc76dec25d09c6ac999","permalink":"/blog/2014/12/27/post-publication-review-of-the-plos-one-paper-comparing-ms-word-and-latex-how-not-to-compare-document-preparation/","publishdate":"2014-12-27T00:00:00Z","relpermalink":"/blog/2014/12/27/post-publication-review-of-the-plos-one-paper-comparing-ms-word-and-latex-how-not-to-compare-document-preparation/","section":"blog","summary":"It doesn't make sense to compare a text editor to a file format.","tags":["Latex","Markdown","MS Word","Post-publication review"],"title":"Post-publication review of the PLOS ONE paper comparing MS Word and LaTeX: How not to compare document preparation","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  The last couple of days I have been working on a new webpage. In doing so, I wanted to create a design where the menu bar initially resides at the bottom of the page and moves upwards as the user scrolls down. However, once the menu bar hits the top edge of the viewport, it should remain fixed there. A bit of googling quickly revealed a solution for this problem, using a combination of CSS and Javascript. However, I wasn’t happy with the solution, because it created a visible jump in the layout every time the menu bar hit the top edge of the screen. In fact, this jump is quite common among most web pages that use this design trick. For example, check out a profile page on Google Scholar: As you scroll down, the heading above the publication list stays fixed as soon as it hits the top edge of the screen. And if you scroll slowly, you’ll see that the layout jumps the moment the element hits the top edge. I didn’t like this effect at all, so I devised a way to work around it.\nLet’s first discuss how we implement this kind of effect in general. They key idea is to use a little bit of Javascript to monitor where on the screen the element of interest resides. The moment it hits the top edge of the viewport, we set it’s position property to fixed so it can’t move any further. If we scroll back down, we revert the setting so the element can move downwards again.\nThe following code will generate this effect:\nHTML:\n\u0026lt;div id=\u0026quot;content-anchor\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;sticky\u0026quot;\u0026gt;This turns sticky\u0026lt;/div\u0026gt; (The content-anchor id is needed so the Javascript code can monitor where the sticky element should be on the page relative to the rest of the document. See the code below.)\nCSS:\n#sticky { } #sticky.stick { position: fixed; top: 0; width: 100%; } Javascript (using the jQuery framework):\nfunction sticky_relocate() { var window_top = $(window).scrollTop(); var div_top = $(\u0026#39;#content-anchor\u0026#39;).offset().top; if (window_top \u0026gt; div_top) { $(\u0026#39;#sticky\u0026#39;).addClass(\u0026#39;stick\u0026#39;); } else { $(\u0026#39;#sticky\u0026#39;).removeClass(\u0026#39;stick\u0026#39;); } } $(function () { $(window).scroll(sticky_relocate); sticky_relocate(); }); You can check out a working example of this idea here. What you will notice, if you scroll slowly, is that just as the sticky element hits the top edge of the viewport, the bottom element (“Main document”) jumps upwards. In fact, at the moment at which the sticky property is turned on, the sticky element covers most of the heading of the main document. This is exactly the same effect that you can see on the Google Scholar page and on countless other pages around the web.\nWhat is going on here? What is happening is that as the sticky property is turned on, the sticky box is removed from the layout and displayed on top of the rest of the document. Hence, the height of that box is now missing from the layout, causing the visible jump. The solution is simple, of course: As we take out an element from the layout, we need to insert an alternative one of exactly the same size. The simple solution is to add a copy of the sticky element that we can show or hide as needed. The corresponding code looks as follows:\nHTML:\n\u0026lt;div id=\u0026quot;content-anchor\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;sticky-phantom\u0026quot;\u0026gt;This turns sticky\u0026lt;/div\u0026gt; \u0026lt;div id=\u0026quot;sticky\u0026quot;\u0026gt;This turns sticky\u0026lt;/div\u0026gt; CSS:\n#sticky { } #sticky-phantom { visibility: hidden; } #sticky.stick { position: fixed; top: 0; width: 100%; } Javascript:\nfunction sticky_relocate() { var window_top = $(window).scrollTop(); var div_top = $(\u0026#39;#content-anchor\u0026#39;).offset().top; if (window_top \u0026gt; div_top) { $(\u0026#39;#sticky\u0026#39;).addClass(\u0026#39;stick\u0026#39;); $(\u0026#39;#sticky-phantom\u0026#39;).show(); } else { $(\u0026#39;#sticky\u0026#39;).removeClass(\u0026#39;stick\u0026#39;); $(\u0026#39;#sticky-phantom\u0026#39;).hide(); } } $(function () { $(window).scroll(sticky_relocate); sticky_relocate(); }); I have provided a working implementation of this idea here. As you can see, in this example the layout doesn’t jump at all. The scrolling is smooth the whole time.\nThis is such a simple trick that I’m surprised it is not used more often. Maybe now that I have posted it here, more people will use it, and we’ll see fewer jarring layout jumps.\n","date":1419292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1419292800,"objectID":"d49b71e1f8793b53b5dbc330791fd30a","permalink":"/blog/2014/12/23/perfectly-smooth-transition-between-fixed-and-variable-positioning-of-html-elements-using-css-and-javascript/","publishdate":"2014-12-23T00:00:00Z","relpermalink":"/blog/2014/12/23/perfectly-smooth-transition-between-fixed-and-variable-positioning-of-html-elements-using-css-and-javascript/","section":"blog","summary":"A little excursion into CSS and Javascript.","tags":["CSS","HTML","Javascript","Web design"],"title":"Perfectly smooth transition between fixed and variable positioning of HTML elements using CSS and Javascript","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  In my previous post on how to prepare an article for resubmission, I failed to mention one important point: In your response to the reviewers, quote the entire referee report, even the introductory sentences. Don’t just quote the specific comments to which you are replying. This may seem unnecessary but it is in fact crucial, in particular if the introductory sentences were largely positive. (If they were highly critical, you may want to omit them, even though in this case you probably should provide a response.)\nKeep in mind that when the revised manuscript goes back to the editor and the previous reviewers, neither will remember the exact thoughts they had when they previously looked at your manuscript. In addition, the reviewers may never actually have seen the comments of the other reviewers. And finally, most editors and reviewers will look at your response to the reviewer comments before they look at anything else related to your manuscript. Thus, this is your opportunity to remind the editor and the reviewers that your manuscript overall was judged to be interesting and valuable, even if there were some issues to be addressed. By not quoting these comments, you only highlight the critical aspects of the previous reviews. For the same reasons, it is often a good idea to start the response with a brief summary of the overall reviewer sentiments, such as: “Reviewers 1 and 2 thought the manuscript addressed an important topic and had only minor comments. Reviewer 3 was more critical but also acknowledged the timeliness of our work.”\n","date":1418860800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1418860800,"objectID":"488ab0013f2cfe982db64153cfd0d253","permalink":"/blog/2014/12/18/how-to-prepare-an-article-for-resubmission-part-ii/","publishdate":"2014-12-18T00:00:00Z","relpermalink":"/blog/2014/12/18/how-to-prepare-an-article-for-resubmission-part-ii/","section":"blog","summary":"You don't want the reviewers to even read your revised manuscript.","tags":["Academic publishing","Editor","Peer review","Revision"],"title":"How to prepare an article for resubmission, Part II","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  I came across an interesting paper1 that derives a mathematical relationship between the total number of citations a scientist has received, \\(N_\\text{tot}\\), and the scientist’s \\(h\\) index.2 The paper, written by Alexander Yong, argues that for typical scientists, \\(h\\) is given simply as 0.54 times the square-root of \\(N_\\text{tot}\\). The paper also derives confidence bounds on this estimate, and it shows that scientists who have written only a few highly-cited works will generally fall below this estimate. While the paper is set up as a critique of the \\(h\\) index, I think it shows that the \\(h\\) index works largely as intended. It measures the total amount of citations a researcher has received, but it adequately down-weighs the effect of a few extremely highly cited works in a researcher’s publication list.\nThe argument of the paper goes as follows: Let’s consider all the possible ways in which a researcher’s \\(N_\\text{tot}\\) citations may be distributed over a number of publications. On one extreme, the researcher could have written a single article, which has been cited \\(N_\\text{tot}\\) times. On the other extreme, the researcher could have written \\(N_\\text{tot}\\) articles, which all have been cited exactly once. And of course, there are many possibilities between those extremes, where some articles receive more citations and others fewer. The paper then assumes that all these different ways in which \\(N_\\text{tot}\\) citations can be distributed over one or more articles are equally likely, and calculates the expected \\(h\\) under that assumption. That value, it turns out, is approximately \\(0.54 \\times N_\\text{tot}^{1/2}.\\) The paper then tests this relationship for a number of famous mathematicians (Fields-medal winners and members of the National Academy of Sciences) and finds that it generally works quite well, though typically as an upper bound. It is rare for a scientist to have \\(h\\) exceed the predicted value of \\(0.54 \\times N_\\text{tot}^{1/2}.\\) On the flip side, many scientists who have written famous, highly cited books have an \\(h\\) quite a bit lower than the predicted value, because the books cause the total citation count to be overinflated.\nI wanted to know to what extent this formula worked in a different field. So I tested it on the members of my department. For each faculty member3 of the Department of Integrative Biology, I obtained their total number of citations and their \\(h\\) index from Google Scholar, and then I plotted the observed \\(h\\) against the predicted \\(h\\) using Yong’s formula (Figure 1). As you can see, the formula works remarkably well. Almost everybody falls right on top of the line. Importantly, this sample covers a wide range of different career stages.\n Figure 1: Observed vs. predicted \\(h\\) for 29 faculty members in Integrative Biology. Members of the National Academy are plotted in red.  Three faculty members are plotted in red in the figure: those are members of the National Academy, and they are the highest-cited scientists in the department. Interestingly, two have very high total citation counts but, in comparison, not that high of an \\(h\\) index, while one has the highest overall \\(h\\) index with comparatively fewer citations. The former two both have written famous books, and many of their citations are to these books. By contrast, the latter scientist stands out by having published a particularly large number of articles that all have been well cited. In fact, that scientist is performing slightly better than the \\(h = 0.54 \\times N_\\text{tot}^{1/2}\\) prediction, a truly remarkable result at that high of a total citation count.\nIn summary, I find that the predicted relationship between \\(h\\) and \\(N_\\text{tot}\\) works well in my field. However, since major deviations between this relationship can be observed for scientists with a few extremely highly cited works, I prefer using \\(h\\) instead of \\(N_\\text{tot}\\) to estimate a scientist’s total impact on their field.\n A. Yong (2014). Critique of Hirsch’s Citation Index: A Combinatorial Fermi Problem. Notices of the AMS 61:1040-1050.↩︎\n The \\(h\\) index is the number of papers a scientist has written that have received at least \\(h\\) citations. For example, if you have \\(h = 10\\), then you have written 10 papers that have been cited 10 or more times. You may have written more than 10 papers total, but none of the other papers you may have written has received more than 10 citations yet.↩︎\n To be precise, each faculty member with a Google Scholar profile. This covers almost but not exactly the entire department.↩︎\n   ","date":1417996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417996800,"objectID":"25584d362b967be8b4876cde8d995643","permalink":"/blog/2014/12/08/relationship-between-h-index-and-total-citations-count/","publishdate":"2014-12-08T00:00:00Z","relpermalink":"/blog/2014/12/08/relationship-between-h-index-and-total-citations-count/","section":"blog","summary":"For most scientists, the h index is approximately half times the square root of the total number of citations.","tags":["Academic publishing","Citation counts","h index"],"title":"Relationship between h index and total citations count","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  I have previously blogged about the issues that preprints can cause on Google Scholar. Today I was reminded that these issues have real-world implication for junior scientists, and that they may discourage junior scientists from posting preprints.\nI had the following conversation with one of my students (paraphrased):\nMe: So, do you want to post the paper we just submitted as a preprint?\nStudent: No, not really.\nMe: Are you concerned about keeping your competitive advantage, so you can finish a second paper on the topic before we reveal to the world what we’re up to?\n(With this particular paper, I had wondered whether we should submit it as a preprint or not. There are a number of obvious follow-up works we can do relatively quickly, and so could others.)\nStudent: No, I’m not particularly worried about that. I just don’t want Google Scholar to list my paper as bioRxiv for the next few years, way past the time the paper has actually come out. Several of my current papers are still listed as their preprint version even though they’ve appeared ages ago. Maybe once I have 100 papers and 10,000 citations I won’t care anymore, but at my current stage I can’t afford having Google Scholar obscure my record by listing all my papers in their preprint version only.\nUpdate #1, 12/03/2014: I’m getting a lot of comments to the effect that one can edit the Google Scholar profile. A couple to responses to that:\nYes, there are manual workarounds for most issues. That doesn’t mean the default behavior of Scholar is not discouraging.\n Merging of articles doesn’t work when the preprint shadows the final article, because the final article is simply not visible in the Scholar database.\n Even if you fix your own profile, that doesn’t fix how the article appears on your co-authors’ profile or in a general search for the article, e.g. by title.\n It is not clear what happens to citations of shadowed articles. Are they or are they not counted? We don’t know. There’s certainly the worry that they are not.\n The only way I know to fix shadowed articles on your own profile is to manually add the reference, then merge, and then undo all of that a year later when Scholar has finally caught up to the existence of your article. It’s cumbersome, prone to errors, and certainly discouraging.\n  I will not stop posting preprints. But I will also not pretend everything is fine with Google Scholar and preprints when there are some glaring issues. Google Scholar is being used increasingly by departments in hiring and promotion decisions. Scientists should rightfully worry about how their work does or does not appear on Scholar.\nUpdate #2, 12/03/2014: So it turns out manually editing entries doesn’t work as expected when articles are shadowed by their preprint. You can add the reference, but you cannot make it link to the correct article. Check out this entry. The title is not clickable, and the Scholar articles listed at the bottom do not include any links to the actual journal version of the article (or even the latest preprint version).1\n My statements are correct as of 12/03/2014. Eventually Google Scholar will catch up and the links will appear.↩︎\n   ","date":1417478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417478400,"objectID":"cce7c327ae4f51f29def3bc9abc19d01","permalink":"/blog/2014/12/02/how-google-scholar-discourages-young-scientists-from-posting-preprints/","publishdate":"2014-12-02T00:00:00Z","relpermalink":"/blog/2014/12/02/how-google-scholar-discourages-young-scientists-from-posting-preprints/","section":"blog","summary":"Junior scientists may suffer career consequences from the Google Scholar preprint bug.","tags":["Academic publishing","Google Scholar","Preprints"],"title":"How Google Scholar discourages young scientists from posting preprints","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  So your latest scientific masterpiece has come back from review with the most likely outcome other than rejection: major revision. The reviewers and the editor think that your work has merit, but they also have a long list of comments and criticism that they expect you to address before the article is acceptable for publication. You read the reviews and you feel like they lay out two years worth of work. How do you best deal with this situation?\nYour life will be easier if you understand everybody’s objectives Let’s first consider the perspective of the three groups of people involved: the editor, the reviewers, and the authors (i.e., you). The editor wants to make sure there are no major problems with your paper, in particular problems that would potentially embarrass her1 down the line. So the editor will pay close attention to any points the reviewers raise that look like your work might be flawed. She will generally be less worried about whether you actually do every additional analysis the reviewers suggest. A good editor knows that most reviewers will suggest more changes than are strictly necessary to get the paper publication ready.\nThe reviewers, primarily, will want to be recognized for their knowledge of the field. They want you to acknowledge that they noticed or knew something you didn’t. Even if it may not seem that way, most reviewer comments are written as constructive criticism, suggestions from the reviewers to you on how you could improve your work. As long as your revisions acknowledge the reviewers’ views, you should be fine. However, on occasion, a reviewer thinks that something you’re doing is fundamentally flawed. In those cases, you may have to put in some extra effort to appease the reviewer.\nI assume you know what your objective is in this interaction, but in case you had doubts I’ll tell you: You want to get the paper published with as little extra work as possible. You thought your paper was done when you first submitted, so any additional work you’re asked to do amounts to pointless busywork from your perspective.\nNow that we know what everybody’s objectives are in this game, let’s discuss some strategies for successful resubmission.\n 1. Start by drafting a response to the reviewers The absolute worst thing you can do after having received reviewer comments is to run back into the lab and start all the additional experiments the reviewers want you to do. This will drag you down a rabbit hole that you will find difficult to come out of, and you will waste a lot of time doing unnecessary work. You need a clear plan of what to do. The best way to develop that plan is to start drafting a response to the reviewers. Copy all the reviewer comments into a file, mark them in some color other than black (I like blue), and then start adding your responses in black.2 See how many reviewer points you can dispense with by writing a response that requires only very minor edits to your manuscript.\nFor the reviewer points that require more extensive rewriting or additional experiments, write out a plan of what you will do to address these points. I like to highlight the parts in the response that I still have to address in the manuscript, and I remove the highlights once I have done so. In this way, I don’t lose track of which edits I have or haven’t done.\nFrom what I have seen, the winning strategy employed by some of the most experienced and successful scientists is to write a very long, detailed response and keep the actual manuscript edits to a minimum. It’s not unusual to see a 5 page response to the reviewers accompanying very minor revisions in the actual paper, a few sentences added here and there, and a few additional references thrown in for good measure. These scientists have, over the years, developed a good sense of the minimum amount of work they can get away with and still have their revisions accepted.\n 2. Realize that the reviewer is always right Regardless of how inane a reviewer’s comments may seem, the reviewer is always right. You don’t gain anything from being upset about the reviewer’s incompetence or lack of knowledge in your area. Instead, think why the reviewer may have reacted the way he did. Maybe you didn’t explain something carefully enough, or you assumed something was widely known that actually isn’t. In your response to the reviewers, always acknowledge the validity of the reviewers’ comments, and then either try to explain the issue in the response or modify the manuscript appropriately.\n 3. Take the reviewer comments seriously It’s very easy to discount reviewer comments and say “the reviewer knows nothing about this topic.” Often the reviewer knows more than you may think, and you may simply not be understanding the reviewer’s point of view. (I’ve certainly reviewed more than one paper where I felt the authors were simply not getting what I was trying to tell them.) So make a serious effort and try to figure out what exactly it is the reviewer wants and how you can make it happen.\n 4. Cite every reference the reviewers mention Sometimes it’s very clear that a reviewer wants you to cite a given paper while at other times it may seem like citing certain papers is optional. (Example: “In this context, the authors could consider citing Jones et al. 1975.”) Either way, cite all mentioned papers unless they are totally inappropriate. Regardless of whether the reviewer actually is Jones himself, or only is good friends with Jones, or simply thinks that the Jones et al. paper was a breakthrough for the field, the reviewer clearly cares for Jones et al. 1975. Therefore, he will have a little more respect for you if you demonstrate that you care for Jones et al. 1975 as well.\n 5. Openly admit to your work’s limitations and shortcomings When reviewers point out that the research performed has certain shortcomings and limitations, junior scientists will often think they have to overcome these limitations before the work can be published. However, more often than not, all that is needed is a clear statement that these limitations exist and should be addressed in future work. Between this strategy and #4 (cite additional papers), you can probably handle at least 60-70% of all reviewer comments without doing any additional experiments or analysis.\n 6. Understand that reviewer comments are written as much for the editor as they are for you The reviewer doesn’t just want to criticize your work, he also wants to make a good impression in front of the editor, who may be a close colleague, former advisor, or general heavyweight in the reviewer’s field of research. For this reason, the reviewer will always come up with at least a handful of points to criticize, just so he doesn’t appear lazy or incompetent. You will have to figure out which of the comments actually address crucial limitations of your paper and which were written just to impress the editor. The latter ones can always be dispatched with a combination of strategies #4 and #5.\n 7. Say “No” to excessive requests Finally, be aware that it is perfectly acceptable to not do certain things the reviewers ask for. Unless the validity of your core findings is at doubt, you always have the option of saying something like “these additional analyses are beyond the scope of the current work: or”we agree that the reviewer’s suggestion should be pursued in future work, and we now say so in the Discussion.\" In case of doubt, don’t do the extra work, just say “No”.\nUpdate 12/18/2014: Also read my follow-up post on this topic.\n  In this story, the editor is female and the reviewers are male.↩︎\n There’s a reason for the specific color choices I suggest. Your goal is to visually separate the reviewer comments from the responses. You could do this by making either the reviewer comments or the responses bold or italics. However, extended sections in italics tend to be hard to read, and extended sections in bold tend to be jarring. So colors are the best option. In your color choice, keep in mind that your responses need to be more visually present than the reviewer comments, because you want the reviewers and the editor to focus on your responses, not the reviewer comments, when they evaluate your revision. So your responses need to be in black, and the reviewer comments need to be in a color that doesn’t stand out relative to black. Blue is a good choice. Maybe green or gray would also work. Red or yellow would probably be bad choices.↩︎\n   ","date":1416096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1416096000,"objectID":"a0f802bb88d0b787c2b14e37b76d56b1","permalink":"/blog/2014/11/16/how-to-prepare-an-article-for-resubmission/","publishdate":"2014-11-16T00:00:00Z","relpermalink":"/blog/2014/11/16/how-to-prepare-an-article-for-resubmission/","section":"blog","summary":"There's a tried and true strategy to article revision.","tags":["Academic publishing","Editor","Peer review","Revision"],"title":"How to prepare an article for resubmission","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  Google Scholar has a serious bug when it comes to preprints. If you have published a preprint of your paper, the later journal publication can be completely invisible to Google Scholar, seemingly absent from their entire database. Even a search for the exact article title will not find the article. And this condition remains for months. (It will eventually fix itself, though. After about a year.) I have now seen this bug in action for several of my papers, and I am confident it’s a reproducible flaw and not a one-off. I reported the issue to the Google Scholar team about a year ago (or at least, I filled in some web form that seemed to be designed to send them feedback) but I have received no response and the bug clearly still exists. I hope that with this blog-post I can draw some attention to this serious issue, so we can have it fixed. Thousands of scientists rely on Google Scholar every day. For many recent articles, this bug will steer these scientists towards outdated, early versions and make the authoritative article versions completely inaccessible.\nAs far as I can tell, what triggers the bug for sure is the publication of an updated version of the same article with a changed title or author list. It is possible that the same bug occurs even when title or author list hasn’t changed, but I haven’t noticed it under those conditions. Here is an example of this bug in action. My lab published the following article on BioRxiv on April 24, 2014:\n Amir Shahmoradi, Dariya K. Sydykova, Stephanie J. Spielman, Eleisha L. Jackson, Eric T. Dawson, Austin G.Meyer, Claus O. Wilke. Predicting evolutionary site variability from structure in viral proteins: buriedness, flexibility, and design. doi:10.1101/004481\n If you click on the link, you’ll see that BioRxiv encourages you to check out the latest version of the article, with slightly different title, posted on July 21, 2014:\n Amir Shahmoradi, Dariya K. Sydykova, Stephanie J. Spielman, Eleisha L. Jackson, Eric T. Dawson, Austin G.Meyer, Claus O. Wilke. Predicting evolutionary site variability from structure in viral proteins: buriedness, packing, flexibility, and design. doi:10.1101/004481\n The doi is the same, so clearly those are two subsequent versions of the same article. BioRxiv also knows that the article was published in its final form by the Journal of Molecular Evolution under doi:10.1007/s00239-014-9644-x on September 13, 2014. Finally, the article has a PubMed entry (PMID: 25217382) and if you do a normal Google search using the complete, final article title the top three hits are two different preprint postings and the final journal article.\nNow that we have established that the article clearly exists, has been published in its final form for over three months (since July 21, 2014), and is known to regular Google, let’s try to find it on Google Scholar. First, we search for the exact title. Here is the result:\nYes, Google Scholar suggests to me that I misspelled the title and meant to type “busineses” instead of “buriedness.” Importantly, it doesn’t find the correct, latest article! It does find the preprint, though, as the second hit. If I click on “all 8 versions” for the preprint, I get all sorts of different versions of the preprint, but the final, published article is not found as of this writing (Nov. 1, 2014). The latest version also doesn’t show up among my 2014 publications in my Google Scholar profile, only the first preprint version is shown. For all intents and purposes, the July 21 and September 13 versions of the article are completely missing from the Scholar database. I cannot retrieve them in any way through Scholar. Let me say this one more time: We’re not simply talking about Google Scholar creating multiple redundant entries and not noticing that two articles are just different versions of the same article. We’re talking about an earlier article completely hiding all later versions. Note that, as I said at the beginning of the post, this issue will correct itself eventually. The paper for which I first noticed this is now, after a year, correctly indexed in Google Scholar.\nTo demonstrate that this is not a one-off, consider this article, posted in revised version on October 14. I’ll leave it as an exercise to the reader to verify that this article exists, is known to regular Google, and is completely invisible in Google Scholar.\nIn my mind, this is a serious bug that severely interferes with efficient scientific communication. It also is a huge embarrassment for a company that prides itself of being the world’s leading expert in information retrieval. I hope this post will give this bug more visibility, and will eventually lead the Scholar Team to fix the problem.\nUpdate: In case you’re wondering if this is just an issue of Google Scholar not having indexed the latest issues of J. Mol. Evol. and/or BiorRxiv yet, that is clearly not the case. Other articles from the same J. Mol. Evol. issue can be found by a search for their title, e.g. this one or this one or this one.\n","date":1414800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1414800000,"objectID":"120d7e1da43a881e32ba2f292b78c648","permalink":"/blog/2014/11/01/the-google-scholar-preprint-bug/","publishdate":"2014-11-01T00:00:00Z","relpermalink":"/blog/2014/11/01/the-google-scholar-preprint-bug/","section":"blog","summary":"Preprints can cause their corresponding published articles to be (temporarily) dropped from the Google Scholar database.","tags":["Academic publishing","Google Scholar","Preprints"],"title":"The Google Scholar preprint bug","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  As part of the recent discussion on anonymous peer review, several people spoke out in favor of double-blind peer review, where neither the authors nor the reviewers know who the others are. I have thought a lot about double-blind peer review, and I’m not entirely convinced, in particular when it comes to grant applications. While double-blind review might solve certain problems and remove certain biases, it would almost certainly amplify other issues, and whether the net effect would be good or bad is unclear. It would also give more power to people such as editors and program managers who operate outside the blinded process.\nSo let’s discuss. I’ll first cover journal articles and then grant proposals. The two are very different, and what applies to one does not necessarily apply to the other.\nJournal articles On the face of it, double-blind peer review for journal articles seems like a no-brainer. It allows junior scientists to be judged on the merit of their work alone, and it prevents senior scientists from coasting through peer review on the basis of their good name. However, as always, the devil is in the detail. There are at least three reasons I can think of why double-blind review may not be such a great idea after all.\nFirst, the real power is with the editors, not the reviewers. It’s the editors who make the final decisions. And this power tends to increase with the perceived rank of the journal; editors of more prestigious journals are more likely to reject papers without review or because of a perceived lack of interest. We all know that you won’t publish in Nature if the Nature editors don’t like your work. And we also know that you can survive quite harsh reviewer criticisms if the Nature editors really want to publish your work.1 Thus, one could make an argument that author names should be blinded to both reviewers and editors. But how would the editors invite unbiased reviewers if they don’t know who has a potential conflict of interest? The only practical way would be to have one editor invite the reviewers and another make the decision. This would be an interesting experiment, but I doubt any journal will go for it any time soon. Thus, as long as author names remain known to the handling editor, I doubt that double-blind review will make much of a difference.\nSecond, blinding the authors of an article is incredibly hard. Just removing the author names from the first page of a paper will frequently not do. If the authors work on a unique study system, or make extensive use of their prior work, or have developed a specific software package, or have posted their data on a public repository, reviewers will likely be able to find out who they are. I once reviewed a paper where the authors had not only removed their names from the title page but also from citations to their own work in the reference list. I’m still amazed that somebody would (i) go to these lengths to conceal their identity and (ii) not realize that this action completely obliterated any anonymity they might otherwise have had. Double-blinding may create an illusion of anonymity where none actually exists.\nThird, double-blind review gives more power to scientists who are intent on submitting fraudulent work, because it is going to be harder for reviewers to identify patterns in the perpetrators’ activities. For example, I have my list of crooks with a solid portfolio on Retraction Watch, and when I get to review one of their papers I’ll be extra careful. These are usually scientists whose activities slipped by me the first time I reviewed one of their papers, because everything looked fine on the surface. If I regularly had to review their papers in a double-blind fashion, they would probably manage to slip by me more frequently.\nOne benefit of double-blind peer review, however, could be that even if the reviewers have a sense of which lab(s) may have been involved in a given study, they still won’t be able to guess the exact author list. For example, I don’t know to what extent reviewers are biased by the gender of the first author if a paper comes from an established lab, but if they are, that bias would likely disappear in double-blind review. Reviewers may guess correctly that the paper comes out of my lab, but they won’t know which of my students wrote it. Evidence in favor of this notion comes from one experiment in which double-blind peer review increased the number of female first authors. Similarly, when junior PIs continue working on research they begun in an established person’s lab, reviewers won’t be able to tell whether the paper comes from the established lab or the junior PI. This could work to the advantage of junior PIs.\nIn summary, the positive and the negative aspects of double-blind review are about even, in my opinion. I have no major concerns about double-blind review, as long as I as an author am not expected to do anything more than remove my name from the author list. I’m not interested in going through my entire paper and making sure not a single sentence (e.g. “We have previously investigated…”) could give a hint at who I am. Also, we now frequently make all our data and code available in a github repository, and I’m not going to go through extra effort to conceal who I am there. Other than that, I’d be happy to support more experiments in double-blind peer review, and I’ll also be happy to support double-blind peer review more strongly if evidence in its favor continues to accumulate.\n Grant proposals Grant proposals are an entirely different beast than journal articles, and I do not think that double-blind proposal review is a good idea. There is a fundamental difference between a journal article and a proposal. An article is the finished product. A grant proposal, by contrast, is only the promise of a future product. If one scientist writes ten times more high-profile papers than another, then she should publish ten times more frequently in high-profile journals, without question. However, just because one scientist is ten times better at writing grant proposals than another doesn’t mean he deserves ten times the funds. In fact, only if that scientist can write ten times as many papers or write papers that are ten times as important (however measured) would he deserve ten times the grant funding.\nI strongly believe that the track record of past performance needs to be considered in proposal review. If you had to hand one person a check over a million dollars, would you rather give the money to somebody who consistently delivers interesting results, even if that person’s grant application doesn’t sound overly exciting, or would you prefer to give the money to somebody who can tell a great story but about whom you know nothing beyond that story. This thought is related to the idea (which is slowly sinking in with the NIH as well) that it is generally better to fund people than projects, or at least to have a healthy mix of people-based and project-based funding. By definition, if you’re evaluating people, you cannot blind the evaluators to their identity.\nNow you could argue that the scientific review should be done blinded and the final funding decision be made by the program officer, who can take into account all the other relevant factors, such as track record, current funding of the applicant, etc. However, this would simply put more power into the hands of program officers, who might or might not use that power wisely. It’s certainly not unheard of for program officers in some agencies to preferentially fund their good buddies. The more power a program officer has to override a panel decision the more likely those situations are going to arise.\nDouble-blind grant review is also open to several sorts of manipulation by applicants. First, it would be easier than it already is to base an application on dubious, sketchy, or even entirely made-up data, because nobody would ever know.2 Second, applicants could pack their proposals with prior results obtained by the biggest shot in the field, causing the reviewers to think they’re reviewing an application by that lab and rank it higher because of that. You might say that that’s exactly the point, only ideas matter, but I’ve seen too many scientists with great ideas and poor execution to feel comfortable with funding decisions based exclusively on ideas.3\nIn conclusion, I don’t think that double-blind grant applications are the way to go. There are other ways to minimize biases in the review process. For example, panels could be given statistics on how many women and junior scientists submitted applications to a given competition, and if the composition of the top-ranked applicants deviates substantially from the overall composition of applicants then the panel could be asked to reconsider their rankings. In general, just paying attention to these kinds of biases and monitoring whether certain groups of applicants are disproportionally affected by either positive or negative decisions should prevent the most egregious biases.\nUpdate (10/19/2014): The article I quoted claiming an increased number of female first authors under double-blind review has later been called into question, as comparable journals have similarly seen an increase in the number of female first authors during the same time period, without instituting double-blind review. Thanks to Matt Hodgkinson for pointing this out.\nUpdate #2 (10/19/2014): This paper, pointed out to me by Matt Hodgkinson, provides a thorough review of what is currently known about biases in peer review. It shows mixed evidence on gender bias. In particular with respect to journal articles, current evidence suggests bias isn’t that pronounced (female and male authors have comparable acceptance rates).\n  I certainly have reviewed papers for Nature that I thought should not be published there and the editors overruled me. And this is fine; editors should have the ultimate decision power. I’m an editor myself, and on occasion I accept papers that reviewers say should be rejected. The point remains, though, that an editor who really wants to publish a paper will rarely be deterred by negative reviews, in particular if the reviews don’t call out egregious errors in the work.↩︎\n Even under the current system of non-blinded review, grant applicants can include sketchy or made-up data with little risk to their career or reputation. While such activity is obviously fraudulent and will have severe consequences if discovered, the likelihood of discovery is low. First, only three to five other scientists ever see the application, and only for a short period of time. So if an applicant, for example, reuses the same data set in subsequent applications but labels the resulting figure differently, it’s very unlikely anybody would notice. Similarly, if an applicant claims preliminary data support one hypothesis and later publishes a paper supporting a different hypothesis, he could always argue that that is indeed how discovery went: first things looked one way but after more careful study it became clear the other way was right. Only the most blatantly obvious fraud, such as publishing fraudulent data in a paper and then using that paper as preliminary results in an application, has any likelihood of being discovered. For these reasons, a colleague of mine here at UT thinks that results that aren’t published or maybe at least deposited on a public archive should not be allowed in grant applications at all.↩︎\n As with everything in life, I think some balance is required here. Grant applicants should have to demonstrate some amount of prior expertise in the work they propose, but they should also be given the benefit of the doubt that some things can be worked out as the research is done.↩︎\n   ","date":1413590400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413590400,"objectID":"17168342809e0b6ef6b9ba8fb3a485e4","permalink":"/blog/2014/10/18/should-peer-review-be-double-blind/","publishdate":"2014-10-18T00:00:00Z","relpermalink":"/blog/2014/10/18/should-peer-review-be-double-blind/","section":"blog","summary":"Double-blind review sounds good in theory but runs into various obstacles in practice.","tags":["Academic publishing","Double-blind review","Grants","Peer review"],"title":"Should peer-review be double-blind?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  One of the key challenges in obtaining a PhD is scheduling a committee meeting. In fact, I think that anybody who has managed to successfully schedule three or four committee meetings probably deserves a PhD just for that feat. After all, getting five professors into the same room at the same time is a tall order. Since scheduling committee meetings is such an integral part of graduate education, there should probably be a class on how to do this successfully. However, I don’t think any such class exists. So maybe this blog post can serve as a substitute.\nWe faculty members understand that we have to do committee meetings, as a service to the department and to help the students. Nearly all faculty members I know are strongly committed to serving on thesis committees. At the same time, we don’t really want to be in these meetings. Committee meetings take up a lot of time. In fact, just fielding questions related to scheduling committee meetings takes up a lot of time. So please try to keep this in mind, and make things as easy on us as possible. We want to help you, but you need to help us in return.\nNow, how do you actually go about scheduling a meeting? First, let’s talk about some things that would best be avoided:\nDon’t ask me to list all my availabilities between March 15 and June 1st. I’m not going to replicate my entire calendar into an email to you. Don’t give me a list of 120 possible date/time combinations and ask me to check off all the ones that don’t work. See the previous point. Don’t assume my availabilities remain unchanged for more than a couple of days. I once had a student ask me if my afternoon was open on a given Monday. I said yes. Six weeks later, and about a week before that Monday, he informed me that the committee meeting was going to be at 3pm. By that time I had already scheduled something else into that time slot.  Now, I’d like to propose a scheduling strategy that generally works:\nFirst, discuss possible dates and times with your adviser. Any times your adviser can’t make are a no-go, obviously. Then, ask your committee members to outline broadly which days/times generally do or don’t work. You can do this in an email or in person. You can also try to figure this out for yourself, by checking their teaching schedule, office hours, lab-meeting schedule, and so on. But I think asking is better.1 Also, you should ask the committee members whether they are going to be out of town any specific days/weeks during the time window in which you’d like to hold your meeting.\nOnce you’ve got a rough sense of everybody’s availability, find a few times that seem to work for everybody and propose a few variants of those times. For example, if it looks like everybody is mostly free on Tuesday afternoons, propose 2pm, 3pm, and 4pm on three successive Tuesdays. At this stage, I would recommend using a system such as Doodle to quickly poll availability. The nice thing about Doodle is that I can see my colleagues’ answers, so if it looks like nobody can make Mon. afternoon then I don’t even have to check my calendar for that slot, I can just click “no” as well.\nImportantly, limit the number of options you propose. If you’re proposing more than about 10 options you’re doing it wrong. Remember from point 3 of the list of things best avoided that quick turn-around is key. You want your committee members to read your message, click on the Doodle link, and quickly answer the poll. You don’t want them to read your message, click on the Doodle link, then recoil in horror and move on to do something else. In a perfect scenario, if you’ve done your leg-work properly, you can propose three to five possible times and one will work.\nI strongly believe that proposing a small number of time slots is important even if you don’t have complete information about who is or is not available when. Quick turn-around always beats out having more complete information when it comes to scheduling. So, if you’re not sure what times would be good, just pick a few time slots at random and see what happens. Worst case scenario, none will work, and you do another round of Doodle. From your perspective, this may seem like an awful outcome, but it’s actually fine. Failed scheduling attempts happen all the time and we’re used to them. I’d rather complete two or even three Doodle polls with 10 options each than one with 100.\nFinally, even if you make things really easy on your committee members, some may not respond to your email requests. In this case, the best strategy is just to show up in their office unannounced and ask them whether they’re available for a meeting on Thurs May 7 at 3pm. And of course, I hope you didn’t put anybody onto your committee who is notoriously difficult to schedule. That would just be asking for trouble.\n You may wonder what the difference is between asking people about their general availability and asking them specifically when they can or cannot meet. The difference is efficiency. If you send me an email such as this one:\n Dear Claus,\nI’d like to schedule a committee meeting for late May or early June. Are there any days that you are out of town during that time? Also, are there days/times that generally do or do not work for you?\n I can respond:\n I’m around. MWF is usually bad, but I’m free most times TTH.\nClaus\n Writing this kind of a response will take me all of 2 minutes, and I’ll likely do it the moment I get your message. As a result, this exchange has saved you from proposing numerous times I would have declined, and it has saved me the time and effort it would have taken me to enter my entire calendar into Doodle.↩︎\n   ","date":1413244800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413244800,"objectID":"f730b01a151d4b723e34ba84a0c31ed5","permalink":"/blog/2014/10/14/how-to-schedule-a-committee-meeting/","publishdate":"2014-10-14T00:00:00Z","relpermalink":"/blog/2014/10/14/how-to-schedule-a-committee-meeting/","section":"blog","summary":"Don't send out a Doodle poll with 120 options.","tags":["Committee meeting","Graduate school","PhD committee"],"title":"How to schedule a committee meeting","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  In a recent blog post, Mick Watson argued that anonymous peer review is bad for science. The post makes a number of insightful and valid points. However, the one point I cannot agree with is that junior scientists don’t need anonymity so they can freely speak their mind without fear of retaliation. Mick Watson argues that retaliation should be a non-issue, and that in the cases where it is not we just have to make it so. Frankly, I think this is simplistic black-and-white thinking. There are so many ways in which a senior person can make a junior person’s life more difficult; I would always recommend my graduate students and postdocs that they review anonymously unless they can write a very positive review.\nA senior person can retaliate against a junior person in a million subtle ways, and all of them are entirely ethical unless they are done in bad faith. In fact, they are the exact same behaviors we engage in all the time to separate stronger science/scientists from weaker science/scientists. Let me just list a few examples:\n I don’t have to prominently cite Junior Person’s work in all of my papers if my papers don’t build directly on top of Junior Person’s work. When I give invited lectures, I don’t have to mention Junior Person’s work. I don’t have to invite Junior Person to give a Departmental Seminar at my institution. I am free to rank Junior Person’s grant as “very good” rather than “excellent.” If I’m on a grant panel and my colleagues are tearing apart Junior Person’s grant, I don’t have to speak up. I’m allowed to have no strong opinion. I don’t have to invite Junior Person to give a keynote lecture at the conference I’m organizing. In particular, if Junior Person is a man, I can always say “we needed more women speakers.” If Junior Person comes up for tenure, I don’t have to write a letter. I can claim I’m busy. Or, if I accept the assignment, I can weaken my statements of support, e.g., by saying “I think Junior Person would get tenure at my institution” instead of saying “Without doubt Junior Person would get tenure at my institution.” If I’m handling one of Junior Person’s papers as Associate Editor, I can invite reviewers who I suspect are going to be critical of Junior Person’s work. If I’m handling one of Junior Person’s papers as Section Editor, I can place little seeds of doubt in the mind of my Associate Editor, e.g. by forwarding the paper with a note that says “I’m not entirely sure this fits into the scope of Journal of Amazing Results. Feel free to reject without review if you have doubts yourself.” When I’m reviewing a paper by somebody else, I don’t have to tell the authors that they should cite Junior Person’s work. When I’m reviewing Junior Person’s paper, I can place little seeds of doubt in the handling editor’s mind, e.g. by placing the following in the confidential comments to the editor: “There’s nothing technically wrong with this work, but I don’t quite see it meeting the standards of Journal of Amazing Results.” When I speak informally with colleagues, I don’t have to mention how amazing Junior Person’s work is. In fact, I don’t have to mention Junior Person at all.  And of course, I can do the opposite of all these behaviors if I really want to promote a junior scientist. In fact, I strongly suspect that these kinds of behaviors (subtle promotion or demotion of individuals) are at the heart of observed differences in recognition of male vs. female scientists, but that’s a topic for another day. For now, it suffices to emphasize that all of these behaviors are entirely reasonable, ethical, and even desired if they are driven by an objective assessment of the quality of one person’s science over another’s, and not by personal biases, preferences, or desire for revenge.\nMick Watson argues that the scientific community should expel retaliating scientists. This suggestion sounds good in theory, but in practice it won’t work for any but the most egregious cases. And importantly, expelling retaliating scientists must not turn into a witch hunt. If I have to be concerned that any time I rank a grant proposal as “very good” or even just “good” somebody is going to accuse me of retaliation then I might as well stop reviewing grants or papers altogether.\nMind you, I’m strongly in favor of open peer review, where the entire review history is routinely published alongside the paper. It adds a lot of transparency to the process. And I think (though I have no data) that people will generally write more polite and factual reviews if they know that their reviews will become public eventually. In the end, though, science—like anything else in life—is always going to be somewhat unfair, open to manipulation, and subject to personal biases and opinion. As a minor protection against these mechanisms, in particular for junior people and women, scientists should be allowed to give anonymous feedback if they so choose.\n","date":1413072000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413072000,"objectID":"cb17de49d4a4e8f10d31edfb44e73811","permalink":"/blog/2014/10/12/in-defense-of-anonymous-peer-review/","publishdate":"2014-10-12T00:00:00Z","relpermalink":"/blog/2014/10/12/in-defense-of-anonymous-peer-review/","section":"blog","summary":"Junior scientists need protection from vindictive senior PIs.","tags":["Graduate students","Junior scientists","Peer review","Postdocs"],"title":"In defense of anonymous peer review","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Visualization"],"content":"  I had a twitter discussion with ggplot2 author Hadley Wickham on whether or not to include a grid background in plots. He thinks the default should have a grid, I think the opposite. I believe we both agree that grids make sense for some plots and not for others, so this is just a question about defaults. On that issue, we remain in disagreement.\n@ClausWilke I think removing the grid lines is a bad idea. It hampers your ability to make accurate comparisons — Hadley Wickham (@hadleywickham) October 7, 2014  @ClausWilke but see (e.g.) fig 3 of http://t.co/m3A1XgPpCK - the grid is the right default, but may make sense to remove in some cases — Hadley Wickham (@hadleywickham) October 7, 2014   One of my preferred methods of data visualization is to take two variables that measure the same quantity in different ways or different systems and then plot one versus the other. As an example, see this figure from a paper my lab published last year. In this kind of a plot, a grid would be highly distracting. In general, I like to add guiding lines that highlight specific features of the data. For example, if the most important feature in the data is whether y values fall above or below one, then placing a horizontal line at y = 1 would be a good idea, and it would likely be more helpful than a generic grid covering the entire plot. However, I do agree that if one does a lot of faceting, a grid may be necessary. In fact, yesterday I played around with faceted plots without background grid, and I noticed that they had a tendency to fall apart and not look very convincing. Without grid, the eye has little to go by in these plots.\nSo, if I can see the value of a background grid in some cases, why am I not convinced that it is the right default? When it comes to constructing plots, I fundamentally believe in an additive rather than a subtractive model. That is, start with a plot that is as empty as possible, and then add everything you need until you have a clear and informative graph. In a subtractive model, you would start with all sorts of additional visual elements of which you remove those you don’t need. While both approaches can lead to the same end result, it is my experience from ~15 years of supervising students, and from reviewing oodles of papers with poor-quality figures, that most people don’t remove visual noise from a graph unless explicitly prompted to do so. If ggplot2 places a gray background grid, then a gray background grid it is. Therefore, in my own personal plotting package, whose intended purpose is internal use in my lab, the default is no background grid. I’d rather say on occasion “please add a background grid to this figure” than having to repeat over and over “please remove the background grid.”\n","date":1412640000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412640000,"objectID":"bf55109d26083d11e4940cb8c9649709","permalink":"/blog/2014/10/07/to-grid-or-not-to-grid/","publishdate":"2014-10-07T00:00:00Z","relpermalink":"/blog/2014/10/07/to-grid-or-not-to-grid/","section":"blog","summary":"Defaults are difficult.","tags":["Data visualization","ggplot2","R","Visual noise"],"title":"To grid or not to grid","type":"blog"},{"authors":null,"categories":["Writing"],"content":"This weekend, I finally spent some time learning R Markdown. I had been aware of its existence for a while, but I had never bothered to check it out. What a mistake. R Markdown rocks! It\u0026rsquo;s hands down the easiest and most elegant method to creating rich documents that contain data analysis, figures, mathematical formulas, and text. And it\u0026rsquo;s super easy to learn. I wager that anybody who has RStudio installed can create a useful document in 30 minutes or less. So if you use R, and you\u0026rsquo;ve never used R Markdown, give it a try.\nR Markdown provides a literate programming platform for the R language. Literate programming, invented by Donald Knuth, allows users to write both a program and a document describing the program, at the same time. In the case of R, this means that you can write a document that contains R code, the output that is generated when the R code is run (including graphs), and prose describing the R code and its output. To give you an example, I started writing a tutorial for R\u0026rsquo;s ggplot2 library this weekend, and the original R Markdown file as well as the HTML output generated from that file are available here.\nWhat does the word Markdown stand for? Markdown is a minimalist approach to writing strutured documents. It consists of plain text with a few simple directives to mark sections, turn text bold or italics, or insert quotes. If you have ever edited a wikipedia article, you have used Markdown.\nTo give you an example, this is Markdown text:\nWe can make text **bold**, *italics*, or `look like code.` We can also insert links, [e.g. to wikipedia,](http://www.wikipedia.org/) we can quote things: \u0026gt; It is time to eat \u0026amp;#8212; Hungry John or make lists: 1. Item 1 2. Item 2 3. Item 3  It will be rendered like this:\nWe can make text bold, italics, or look like code. We can also insert links, e.g. to wikipedia, we can quote things:\n It is time to eat \u0026#8212; Hungry John\n or make lists:\n Item 1 Item 2 Item 3  R Markdown works the same, only that it adds the option to insert R code blocks. An R code block could look something like this:\n```{r} # place R code here, e.g. to make a plot: library(ggplot2) x \u0026lt;- 1:10; y \u0026lt;- x^2 qplot(x, y) ```  When you convert the R Markdown file to HTML, the R code gets executed, the R output captured and inserted into the document, and you\u0026rsquo;ve got everything nicely together, with very little work.\nTo create an R Markdown document in RStudio, all you have to do is go to File, New File, and then select R Markdown. Accept the default settings, and R Studio will generate a new R Markdown file with a few lines of example content. To convert the file into HTML, simply click on the \u0026ldquo;Knit HTML\u0026rdquo; button. If you have previously stored your R Markdown file somewhere on your harddisk (with suffix .Rmd), RStudio will automatically save the generated HTML file in the same location, with the same name and suffix .html. The HTML file is self-contained, including all images, so it\u0026rsquo;s easy to publish it on a web page or share it with people. RStudio also provides you with the option to publish the document online on the RPubs website. Just click on the \u0026ldquo;Publish\u0026rdquo; button in the HTML view.\nTo learn more about R Markdown, go to: https://rmarkdown.rstudio.com\n","date":1412380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412380800,"objectID":"daaff3f1a3a23a40c37853a0d7bd893c","permalink":"/blog/2014/10/04/r-markdown-the-easiest-and-most-elegant-approach-to-writing-about-data-analysis-with-r/","publishdate":"2014-10-04T00:00:00Z","relpermalink":"/blog/2014/10/04/r-markdown-the-easiest-and-most-elegant-approach-to-writing-about-data-analysis-with-r/","section":"blog","summary":"It's time to learn R Markdown.","tags":["Markdown","R","R Markdown","Statistics","Writing"],"title":"R Markdown, the easiest and most elegant approach to writing about data analysis with R","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Science"],"content":"  A paper published by PLOS Comp. Biol. this month, Chatterjee et al., The Time Scale of Evolutionary Innovation, espouses ideas that are quite similar in spirit to long-standing creationist arguments. I said as much in a few tweets. After having made these comments, I have spent quite some time thinking this paper over. And I simply cannot convince myself that it makes an important contribution to evolutionary biology. It is possible that there’s something I’m missing, but to me the paper looks like a very convoluted and mathematically dense way of making a few tired, trivial, and maybe even tautological arguments.\nThe paper, written by Krishnendu Chatterjee and Andreas Pavlogiannis of IST Austria and Ben Adlam and Martin Nowak from Harvard University, makes two fundamental claims: 1. Evolutionary adaptation needs exponential time to discover novel phenotypes. 2. An alternative process, the “regeneration process,” can discover novel phenotypes in polynomial time. Further, the paper claims that the regeneration process provides fundamental new insight into the process of evolutionary adaptation.\nI will break down my discussion of this paper into three parts: First, I’ll discuss the claim that evolutionary adaptation needs exponential time. Second, I’ll discuss the regeneration process. Third, I’ll ask whether this paper provides any novel biological insight. Let me also state upfront that this paper contains many pages of dense math, and I have not checked every equation in detail. In fact, I don’t think that’s necessary. I am happy to take the authors’ mathematical derivations at face value. What I’m discussing here are the assumptions the authors make going into their derivations and the conclusions they draw coming out.\nDoes evolutionary adaptation need exponential time? Whether or not evolutionary adaptation needs exponential time has been discussed since forever, because, in fact, this is one of the favorite topics of intelligent design creationists. Apparently, Chatterjee et al. are not aware of this discussion, because they cite neither the creationist arguments nor the counter-arguments by evolutionary biologists. I don’t really want to delve into the depths of this long-standing dispute. I’ll just point out the some of the key players and arguments. Then I’ll give a brief argument for why papers such as the current Chatterjee paper make no useful contribution to the question of whether or not evolution has had sufficient time to generate the life forms we see today.\nThe exponential-time argument in its essence goes back to the “junkyard tornado” metaphor originally coined by Hoyle:\n The chance that higher life forms might have emerged in this way is comparable to the chance that a tornado sweeping through a junkyard might assemble a Boeing 747 from the materials therein.\n The argument was subsequently made more sophisticated by Dembski in his book “No Free Lunch.” In this book, Dembski employs so-called “No-Free-Lunch” (NFL) theorems to argue that evolutionary search cannot be more efficient than just trying solutions at random. NFL theorems were discovered in the field of machine learning, and they state that all search algorithms perform equally poorly when averaged over all possible search spaces (i.e., fitness landscapes). When applied to evolution, the argument becomes that evolutionary adaptation is just as efficient (or rather, inefficient) at finding solutions as is the junkyard tornado. The main counter argument is that evolution does not operate on all possible fitness landscapes but specifically on biological ones, which tend to be sufficiently smooth. On a perfectly smooth, single-peaked fitness landscape, evolutionary adaptation finds the peak in logarithmic time (Wilf and Ewens, 2010). On a more rugged peak with some epistasis, search time can be slower, depending on the exact type and amount of epistasis (Ewert et al. 2012). Yet Covert et al. (2013) showed in simulations that certain types of epistasis can actually speed up evolution. (Disclaimer: I’m an author on the Covert paper.)\nI hope you can see where this is going. It is possible to construct mathematical models that produce any number of search times, from very rapid (logarithmic) to extremely slow (exponential or worse). The specific model that Chatterjee et al. propose is that of a fitness landscape in which peaks are surrounded by extended, flat valleys. On such a landscape, evolutionary search does indeed take exponentially long, because there are insufficient fitness gradients that can guide the population towards the fitness peaks. Instead, the population simply drifts randomly until it hits on a peak by accident.\nHowever, whether any of these mathematical models are actually relevant to the process of evolution as it happens in the natural world is ultimately an empirical question. No amount of mathematical theorizing can produce more insight than we already have. We have pretty good experimental evidence (e.g. Blount et al. 2012) and evidence from non-trivial computer simulations (e.g. Lenski et al. 2003) that evolution can produce quite sophisticated, non-obvious, and non-trivial novel functions within a few thousand generations. We also have increasingly good evidence that protein-coding genes can arise de-novo from non-coding DNA, through the accumulation of point mutations. For example, Knowles and McLysaght (2009) estimate that 18 such genes have arisen in humans since the human-chimpanzee divergence. Thus, in summary, the available empirical evidence is clearly at odds with the exponential-time argument.\n Is the proposed regeneration process a viable alternative? Now, Chatterjee et al. would argue (I assume) that the empirical evidence is at odds with the exponential-time argument because evolution is actually more accurately described by their “regeneration process.” They define the regeneration process as an iterated evolutionary search, where the search starts over and over in a relatively small sphere around the target solution. And, surprise surprise, under this assumption the search does not take exponentially long.\nWhat is the cause of the regeneration process? The authors mention gene duplications and recombination. Ok, I can see how these processes could keep producing sequences in a particular region of the sequence space, and this region might be within a small sphere of the target. But note that this argument assumes the target happens to be near where these processes produce new sequence variants in the first place. Further, point mutations can similarly be the cause of the regeneration process: If the population happens to sit on a local peak next to the sphere of interest, it will also feed the regeneration process. In other words, the regeneration process simply describes evolution on a fitness landscape that violates the assumptions made in the first part of Chatterjee et al.’s paper. In fact, the whole thing seems tautological. The paper basically says: Evolution can only succeed on fitness landscapes that are structured such that evolution can succeed.\nThere’s another issue I have with the way the authors present the regeneration process. They state that “evolution can be seen as a tinkerer playing around with small modifications of existing sequences rather than creating entirely new ones.” This phrasing makes me uncomfortable, because it reminds me of the discussion of “kinds” in the creationist literature. What exactly is an “entirely new sequence”? I’d argue that this concept is vague to the point of being useless. We know of examples where homologous protein sequences share less similarity (below 1%) than would be expected from two randomly chosen sequences (Kinch and Grishin, 2002). If a sequence has diverged so much that nearly every position has changed, is it entirely new relative to its ancestor? We also know of examples where protein sequences that are clearly evolutionarily related fold into entirely distinct structures, structures that seem to have absolutely no relationship with each other (Grishin 2001). Would this count as a case where an entirely new protein evolved? Finally, we know of cases where a functional, protein-coding sequence arose through a few point mutations from a non-coding sequence (Knowles and McLysaght, 2009). Again, is this an entirely new protein? Evolution, which proceeds by descent with modification, is necessarily a stepwise, local search process. Thus, anything that evolves can be traced back to something that previously existed, and nothing “entirely new” can ever evolve, if we define “entirely new” as “not connected by a number of small modifications to something that existed before.” If by contrast “entirely new” is simply to mean “something that doesn’t obviously, to the human eye, look like something that existed before,” then we have plenty of examples where entirely new things have evolved, and the papers I quote in this paragraph provide some of these examples.\n Does this paper provide novel biological insight? What are the biological insights we can draw from this study? There is no doubt that the authors have done a lot of math, and that this math deserves to be published somewhere. But for publication in PLOS Computational Biology, the stated requirement is that the paper “provide profound new biological insights.”\nTo be frank, there is little biology in this paper. However, one sentence drew my attention. In the first paragraph of the discussion, Chatterjee et al. state that their “process can also explain the emergence of orphan genes arising from non-coding regions [45].” This sentence got me excited. I’m quite interested in the origin of novel protein structures, and as I mentioned above, there is now pretty solid evidence that proteins can evolve from non-coding sequences. So I expected to find a section somewhere in the paper where they estimated the rate of such occurrences. Presumably, one could estimate the amount and sequence variation of non-coding DNA in a typical genome, and, assuming some model about the density of viable protein structures within that amount of random sequence, estimate the number of novel protein structures expected to evolve from non-coding DNA per genome and number of generations. Hopefully, that estimate would roughly agree with estimates from genomics data, such as the one provided by Knowles and McLysaght (2009).\nAlas, I was sorely disappointed. I searched both the main body of the text and the supporting materials for the word “orphan” and got a total of two hits, one in the sentence I just quoted and one in the title of their reference 45, a review of orphan genes (Tautz and Domazet-Lošo, 2011). To be absolutely sure I hadn’t missed any relevant passages, I also searched for the words “protein,” “peptide,” and “coding,” both in the main text and in the supplement, but couldn’t find any meaningful discussion about the evolution of novel coding sequences through these terms either. I don’t think there is a single piece of evidence in the entire paper to support Chatterjee et al.’s one claim of biological significance, that the proposed regeneration process can explain the origin of orphan genes.\n Conclusions In summary:\nChatterjee et al.’s exponential time calculation seems similar in spirit to long-standing arguments raised by intelligent-design creationists such as Dembski and colleagues. Considering that these arguments have been raised and rebutted since forever, I don’t see that Chatterjee et al. make a particularly novel or useful contribution. They also fail to place their work into the context of these earlier arguments.\n The primary open problem in evolutionary biology remains a detailed characterization of the genotype-phenotype map, and, in particular, the question of how close in genotype are distinct high-fitness phenotypes. The Chatterjee et al. paper makes no attempt at answering this question. Instead it offers the tautology that evolution succeeds on fitness landscapes that are structured such that evolution can succeed.\n The paper makes the bold claim that it can explain the origin of orphan genes, without actually providing any concrete evidence. I am puzzled how this entirely unsupported claim made it past review.\n   References Z. D. Blount, J. E. Barrick, C. J. Davidson, R. E. Lenski (2012). Genomic analysis of a key innovation in an experimental Escherichia coli population. Nature 489:513–518.\nA. W. Covert, R. E. Lenski, C. O. Wilke, C. Ofria (2013). Experiments on the role of deleterious mutations as stepping stones in adaptive evolution. PNAS 110:E3171–E3178.\nK. Chatterjee, A. Pavlogiannis, B. Adlam, M. A. Nowak (2014). The time scale of evolutionary innovation. PLoS Comput. Biol. 10:e1003818.\nW. A. Dembski (2007). No Free Lunch: Why Specified Complexity Cannot Be Purchased without Intelligence. Rowman \u0026amp; Littlefield.\nW. Ewert W, W. A. Dembski, A. K. Gauger, R. J. Marks II (2012). Time and information in evolution. BIO-Complexity 4:1–7.\nN. V. Grishin (2001). Fold change in evolution of protein structures. J. Struct. Biol. 134:167–185.\nL. N. Kinch and N. V. Grishin (2002). Expanding the nitrogen regulatory protein superfamily: Homology detection at below random sequence identity. Proteins: Structure, Function, and Bioinformatics 48:75–84.\nD. G. Knowles and A. McLysaght (2009). Recent de novo origin of human protein-coding genes. Genome Res. 19:1752–1759. R. E. Lenski, C. Ofria, R. T. Pennock, C. Adami (2003). The evolutionary origin of complex features. Nature 423:139–144.\nD. Tautz and T. Domazet-Lošo (2011). The evolutionary origin of orphan genes. Nature Reviews Genetics 12:692–702.\nH. S. Wilf and W. J. Ewens (2010). There’s plenty of time for evolution. PNAS 107:22454–22456.\n ","date":1411516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1411516800,"objectID":"20f5ae717ff7df9d0dfaeff6aaddd77a","permalink":"/blog/2014/09/24/a-critique-of-chatterjee-et-al-the-time-scale-of-evolutionary-innovation-plos-comp-biol-2014/","publishdate":"2014-09-24T00:00:00Z","relpermalink":"/blog/2014/09/24/a-critique-of-chatterjee-et-al-the-time-scale-of-evolutionary-innovation-plos-comp-biol-2014/","section":"blog","summary":"This paper uses lots of math to say little of consequence.","tags":["Evolution","Intelligent design","Orphan genes"],"title":"A critique of Chatterjee et al., The Time Scale of Evolutionary Innovation, PLOS Comp. Biol. 2014.","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Data science"],"content":"  It seems that Hadley Wickham, the author of the spectacular ggplot2 library for R, is not content with revolutionizing the world of computational data analysis just once. He keeps doing it. This spring, he released the dplyr package, a package that proposes a grammar of data manipulation. I predict that dplyr will become as important for large-scale data analysis and manipulation as ggplot2 has become for visualization. If you like ggplot2, you will love dplyr.1\ndplyr is the next iteration of the popular plyr package, only that it is 100 times faster and way more intuitive. It provides a clean interface to work with data sets that are “tidy.” (See also my previous two blog posts on tidy data here and here.) Let me whet your appetite by showing you a simple analysis I did the other day.\nI wanted to find out how much evolutionary divergence there is between human genes and the corresponding yeast (S. cerevisiae) orthologs. Specifically, I was interested in the range of sequence identities among genes, i.e., what are the most conserved genes, the most diverged genes, what is the mean divergence, and so on. The analysis has an additional twist in that there are different types of ortholog pairs. There are one-to-one orthologs, where the human gene has exactly one counter-part in the yeast genome, there are one-to-many orthologs, where the gene in one organism has multiple counter-parts in the other organism, and there are many-to-many orthologs, where there are multiple genes in both organisms that are orthologous to each other. Thus, I wanted to carry out my analysis by orthology type.\nI went to ensembl and downloaded all human-to-yeast orthologs with their respective sequence identities. The resulting csv file is available here. We can download this file directly into R, using the RCurl package. We’ll also load the dplyr package, since we’ll need it later:\nlibrary(RCurl) library(dplyr) url \u0026lt;- \u0026quot;https://dl.dropboxusercontent.com/u/97817736/human_yeast_divergence.csv\u0026quot; data \u0026lt;- read.csv(textConnection(getURL(url))) Let’s take a look at the data. There are five columns, the gene id for the human gene, the gene id for the corresponding yeast ortholog, the homology type (one-to-one, one-to-many, many-to-many), the percent identity with respect to both the human (perc.ident.human) and the yeast (perc.ident.yeast) gene, and a confidence score that tells us how confident we are that the two genes are actually orthologous.\nhead(data)  human.gene.ID yeast.gene.ID homology.type perc.ident.human 1 ENSG00000100077 YKL126W ortholog_many2many 19 2 ENSG00000100077 YHR205W ortholog_many2many 18 3 ENSG00000100077 YMR104C ortholog_many2many 18 4 ENSG00000196139 YHR104W ortholog_one2many 33 5 ENSG00000173213 YFL037W ortholog_one2many 71 6 ENSG00000154930 YLR153C ortholog_many2many 43 perc.identity.yeast confidence 1 19 1 2 15 1 3 18 1 4 33 1 5 69 1 6 44 1  Now we’re ready for some dplyr magic. Let’s assume we want to analyze the data by homology type, and we want to find the minimum, mean, median, and maximum sequence identity for each homology type, as well as the standard deviation of the identity distribution. All this can be achieved with the following code:\ndata %\u0026gt;% group_by(homology.type) %\u0026gt;% summarize( min=min(perc.ident.human), mean=mean(perc.ident.human), std.dev=sd(perc.ident.human), max=max(perc.ident.human)) Source: local data frame [3 x 5] homology.type min mean std.dev max 1 ortholog_many2many 1 26.36965 16.37955 92 2 ortholog_one2many 0 27.46243 15.18146 86 3 ortholog_one2one 1 33.04183 12.89296 80 The function group_by() states that we want to carry out the analysis separately for each homology type, and the function summarize() calculates the summary statistics (min, mean, etc.) for each group. The operator %\u0026gt;% is a chaining operator, like a pipe in the UNIX command line. It takes the output from the previous operation and feeds it into the subsequence operation.\nAs you can see, dplyr syntax focuses entirely on the logical flow of the data analysis. You don’t ever have to worry about bookkeeping, looping over cases, or details of the data storage.\nLet’s do another example. Let’s say we’re only interested in one-to-one orthologs, and we want to find the top 10 least diverged yeast genes and list them in descending order. The following lines achieve this:\ndata %\u0026gt;% filter(homology.type==\u0026#39;ortholog_one2one\u0026#39;) %\u0026gt;% select(yeast.gene.ID, human.gene.ID, perc.ident.human) %\u0026gt;% top_n(10) %\u0026gt;% arrange(desc(perc.ident.human)) Selecting by perc.ident.human yeast.gene.ID human.gene.ID perc.ident.human 1 YLR167W ENSG00000143947 80 2 YDR064W ENSG00000110700 77 3 YKL145W ENSG00000161057 75 4 YOR210W ENSG00000177700 75 5 YGL048C ENSG00000087191 74 6 YPL086C ENSG00000134014 74 7 YPR016C ENSG00000242372 72 8 YJR121W ENSG00000110955 72 9 YDL007W ENSG00000100764 71 10 YEL027W ENSG00000185883 70  The function filter() selects all rows of the given homology type, the function select() picks the specific columns we are interested in, the function top_n() selects the top n values in the last data column (i.e., column perc.ident.human in this example), and the function arrange() sorts the data.\nIf these examples have piqued your interest and you want to learn more, I recommend you start by reading the dplyr vignette, which you can find here: http://cran.r-project.org/web/packages/dplyr/vignettes/introduction.html\nThere is also an excellent introduction by Kevin Markham, with accompanying 40 minute video, available here: http://rpubs.com/justmarkham/dplyr-tutorial\nAnd have I mentioned already that dplyr has a database backend, so you can now easily use all the statistical sophistication that R provides on arbitrarily large, remotely stored data sets.\n And if you aren’t familiar with ggplot2, spend some time with it. It is fantastic, though it may feel alien initially. If you’re used to traditional visualization approaches, you may think in terms of drawing points and lines onto a canvas. ggplot2 requires you to approach visualization in a completely different way, in terms of mapping features of the data onto aesthetic features of the graph. Once you get this way of thinking, it becomes rather powerful.↩︎\n   ","date":1410912000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410912000,"objectID":"af792b39c1b4f9920c5d244b72e4db04","permalink":"/blog/2014/09/17/a-grammar-of-data-manipulation/","publishdate":"2014-09-17T00:00:00Z","relpermalink":"/blog/2014/09/17/a-grammar-of-data-manipulation/","section":"blog","summary":"Wickham has published a new package, dplyr, that will revolutionize data wrangling.","tags":["Data wrangling","dplyr","R","Tidy data"],"title":"A grammar of data manipulation","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  Lately it keeps happening to me that I try to invite somebody to review a paper and they decline, giving as reason that they have reviewed the paper already for a different journal1 and reviewing the paper again would put the authors into a situation of double jeopardy. This got me thinking. Should reviewers really decline for that reason? As reviewer, I’ve always thought the opposite. For a paper I have reviewed already, if the authors have made a reasonable effort to address my comments and have now chosen a more adequate journal, I can keep my review short and recommend acceptance. Thus, I’m actually preventing a situation of double jeopardy. I keep the authors from facing yet another reviewer with new opinions and requests. So, which is right? Should reviewers recuse themselves if they are asked to review again for a different journal, or should they instead leap at the opportunity and give the authors a break? I’d be interested in your thoughts.\n Where the paper was rejected, presumably.↩︎\n   ","date":1410566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410566400,"objectID":"cf7a51e501dc334ee412f93330096ac3","permalink":"/blog/2014/09/13/double-jeopardy/","publishdate":"2014-09-13T00:00:00Z","relpermalink":"/blog/2014/09/13/double-jeopardy/","section":"blog","summary":"Should reviewers re-review the same article for a different journal?","tags":["Academic publishing","Peer review","Editing"],"title":"Double Jeopardy","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Data science"],"content":"  My previous post on tidy data didn’t at all touch on rule 3, “Each type of observational unit forms a table.” The example I gave had only one observational unit, the weekly temperature measurements. Frequently, however, we have data corresponding to multiple observational units. In this case, it is important that we store them in separate tables, and that we know how to combine these tables for useful analyses.\nFirst, we need to figure out when we’re dealing with multiple observational units and when we are not. An observational unit is the base unit on which measurements are done. Importantly, multiple measurements can be performed on the same unit. For example, if we’re studying a group of patients, and for each patient we measure height, weight, heart rate, and blood pressure, then the observational unit is the patient, and we are measuring four variables per observational unit. However, if we’re following the patients over time, and we make those four measurements once every month for a year, then the observational units are the patient-months, i.e., we have one observational unit per patient each month.\nIn what follows, I’m assuming you have read the previous post and you are familiar with the temperature example I made there. In this example, since we’re measuring temperature each week, we have one observational unit per city per week. If in addition to temperature we also measured humidity, then we’d have two measurements per observational unit but the number and type of observational units wouldn’t change. Now, however, assume that we’re also recording additional information about the cities that we’re studying, for example their altitude. The altitude will be the same every week. Therefore, altitude is a property of the city, not of the city-week that is the experimental unit for the temperature measurements. Thus, we now have two separate sets of experimental units, the city-weeks for which we measure temperature and the cities themselves for which we measure altitude.\nBy rule 3 for tidy data, the altitude measurements do not belong into the table that contains temperature data, they belong into a separate table. For example, this table could look like this:\n\u0026gt; alt.data city altitude 1 A 2300 2 B 400 3 C 250 Let’s assume that we want to know whether there is a relationship between the mean temperature for a city and the city’s altitude. How would we do this? First, we calculate the mean temperature, as before, and store it in a new data frame called mean.temp:\n\u0026gt; mean.temp \u0026lt;- ddply(temp.data, \u0026quot;city\u0026quot;, summarize, mean.temp=mean(temperature)) \u0026gt; mean.temp city mean.temp 1 A 13.50 2 B 20.25 3 C 23.75 Now, we need to merge the two data frames alt.data and mean.temp. This can be done with the function join() from the plyr package, or alternatively with the function merge from base R:\n\u0026gt; city.data \u0026lt;- join(mean.temp, alt.data) Joining by: city \u0026gt; city.data city mean.temp altitude 1 A 13.50 2300 2 B 20.25 400 3 C 23.75 250 Now we can investigate the relationship between the two variables, for example by fitting a linear model:\n\u0026gt; summary(lm(altitude ~ mean.temp, data = city.data)) Call: lm(formula = altitude ~ mean.temp, data = city.data) Residuals: 1 2 3 121.1 -354.8 233.6 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 5027.01 1177.01 4.271 0.146 mean.temp -210.97 59.95 -3.519 0.176 Residual standard error: 441.7 on 1 degrees of freedom Multiple R-squared: 0.9253, Adjusted R-squared: 0.8506 F-statistic: 12.38 on 1 and 1 DF, p-value: 0.1763 Both the join and the merge function can handle much more complicated situations. For example, by default, both functions merge on all shared variables. Further, you can specify how you want to handle the situation when cases are missing. A “left” join keeps all rows from the first data frame and matches the corresponding ones from the second, a “right” join keeps all rows from the second data frame and matches the corresponding ones from the first, an “inner” join only keeps rows that exist in both data frames, and a “full” join keeps all observations that exist in either data frame. For more details, read the documentation of either function.\n","date":1405900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405900800,"objectID":"3789c1b6de7084bd21d02aaa8f6fe92a","permalink":"/blog/2014/07/21/keep-your-data-tidy-part-ii/","publishdate":"2014-07-21T00:00:00Z","relpermalink":"/blog/2014/07/21/keep-your-data-tidy-part-ii/","section":"blog","summary":"Each type of observational unit forms a table.","tags":["Data wrangling","R","Tidy data"],"title":"Keep your data tidy, Part II","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Data science"],"content":"  I came across this nice preprint by Hadley Wickham:\n Hadley Wickham (2014). Tidy data. Submitted.\n In this preprint, Wickham describes a way of organizing data he calls “tidy.” He then argues that tidy data and tidy tools (that both input and output tidy data) make data analysis much more efficient than any alternative approach can.\nWhen are data tidy? When they satisfy these three conditions:\nEach variable forms a column. Each observation forms a row. Each type of observational unit forms a table.  Every other arrangement of data is called “messy.”\nLet’s look at an example. Assume you’re making temperature measurements once a week in three cities (city A, city B, and city C). Instinctively, most people would probably record the data like this:\nweek city_A city_B city_C 1 14 18 23 2 15 21 24 3 12 25 23 4 13 17 25 ... Or maybe even like this:\nweek 1 2 3 4 ... city_A 14 15 12 13 city_B 18 21 25 17 city_C 23 24 23 25 While both options may look quite organized, neither corresponds to tidy data. In both cases, Wickham’s rules 1 and 2 are violated. For example, in the first case, the variable temperature appears in three columns. Consequently, multiple observations appear in each row. In the second case, multiple variables appear in each column and multiple observations appear in each row.\nThe tidy version of this data set would look like this:\nweek city temperature 1 A 14 1 B 18 1 C 23 2 A 15 2 B 21 2 C 24 ...  I believe that most people have an instinctive dislike towards tidy data, because tidy data sets tend to have many rows and are difficult to read with the human eye. You can clearly see this in my made-up data set. The messy1 versions allow us to quickly compare cities’ temperatures in different weeks as well as identify trends over time. The tidy version does not. It also requires many more rows.\nNevertheless, for computational analysis, having tidy data makes things way more efficient, if you have the right set of tools. These tools need to consistently input and output tidy data. Fortunately, these tools exist in R. (And Wickham has greatly enhanced R’s capability to keep analyses tidy by writing the packages reshape2, plyr, and ggplot2.) With the appropriate tools, even quite complicated analyses can be expressed in just a few lines of code. And most importantly, there is no need for explicit loops or other bookkeeping code. You just express the semantics of your analysis and the programming language does the rest.\nHow does this work? In general, when we want to analyze data, we want to manipulate (specifically filter, transform, aggregate, and sort), model, and visualize. These steps require only a handful of generic tools, such as a generic data aggregation function. Let me show you a few examples, using the summarize() and ddply() functions from the plyr package. I assume we store the temperature data in tidy form in a data frame called temp.data:\n\u0026gt; temp.data week city temperature 1 1 A 14 2 1 B 18 3 1 C 23 4 2 A 15 5 2 B 21 6 2 C 24 7 3 A 12 8 3 B 25 9 3 C 23 10 4 A 13 11 4 B 17 12 4 C 25 Let’s calculate the mean temperature in each city:\n\u0026gt; ddply(temp.data, \u0026quot;city\u0026quot;, summarize, mean=mean(temperature)) city mean 1 A 13.50 2 B 20.25 3 C 23.75 Or in each week:\n\u0026gt; ddply(temp.data, \u0026quot;week\u0026quot;, summarize, mean=mean(temperature)) week mean 1 1 18.33333 2 2 20.00000 3 3 20.00000 4 4 18.33333 Or let’s find the city with the highest temperature each week:\n\u0026gt; ddply(temp.data, \u0026quot;week\u0026quot;, summarize, hottest.city=city[which.max(temperature)]) week hottest.city 1 1 C 2 2 C 3 3 B 4 4 C These are just a few simple examples. For more examples, read Wickham’s paper, and also read his paper on plyr.2\nDoes any of this matter? I’m sure somebody will tell me: Yeah, but R is an ugly and archaic programming language, and my python code will analyze the data tables that Wickham calls “messy” just fine. My answer is that it only matters if you care about how much time you spend analyzing your data. Read through the example analysis Wickham provides in his Section 5 (“Case study”). This analysis uses less than 30 lines of code, including the code for visualization, to identify and plot causes of death with unusual temporal patterns throughout the day (see his Fig. 4). How many lines of code would you have written to do a comparable analysis? And how long would it have taken you to write this code and debug it?\nAt some point, a quantitative advantage becomes a qualitative one. While one can do the exact same analyses with tidy and messy datasets/tools, the tidy approach will generally require much less code, and hence be faster to write, easier to debug, and easier to modify/maintain. In practice, this means that the person using the tidy approach will be able to analyze more data sets, try a larger number of different analysis approaches, and/or make fewer mistakes. Aggregated over the course of several months, this advantage can easily translate into some major new findings made only by the person using the tidy approach.\n Throughout this post, I’m following Wickham in using “messy” as a technical term, meaning “not tidy,” as in “not conforming to the definition of tidy data.”↩︎\n Hadley Wickham (2011) The split-apply-combine strategy for data analysis. Journal of Statistical Software 40:1–29.↩︎\n   ","date":1405814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405814400,"objectID":"5a43f1d6d9a62399c98b1645536d7cfc","permalink":"/blog/2014/07/20/keep-your-data-tidy/","publishdate":"2014-07-20T00:00:00Z","relpermalink":"/blog/2014/07/20/keep-your-data-tidy/","section":"blog","summary":"Each variable forms a column, and each observation forms a row.","tags":["Data wrangling","R","Tidy data"],"title":"Keep your data tidy","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  A few days ago, Pröf-like Substance asked for posts with suggestions on how to survive the pre-tenure years. I went over my blogging history and realized that I hadn’t really written anything on this topic yet. Most of my advice to date is targeted at more junior scientists. So here is my attempt at giving some suggestions on how to make the most out of your years on the tenure track.\nThe below applies to a tenure-track position at an R1 university, where your promotion will largely depend on your research productivity. I’m assuming that you’re teaching one course a semester or less, you have limited requirements in terms of departmental service, and you have access to a pool of capable graduate students.\nRelax, you’re not going to die Well, you are, but likely not any time soon. Being a fresh Assistant Professor on the tenure track is a pretty sweet deal. You have 5-7 years of guaranteed job security, during which nobody is going to tell you what to do. Your teaching load is pretty light. You get to spend most of your time doing stuff you really enjoy. Also, unless you’ve signed up with a place known for not tenuring their junior faculty members, such as Harvard, odds are in your favor. As long as you perform reasonably, you will probably get tenure. And, even if you are denied tenure, you’ll likely land on your feet and find a good job elsewhere. I can think of only a handful of people I know who were denied tenure, and all of them have done Ok. In fact, the vast majority of them are now in permanent academic positions at different (or even the same1) universities, or at national labs.\nStressing over tenure will only make you perform worse. To be successful, you need to be original, you need to be productive, and you need to inspire the students and postdocs in your lab to perform at their best. Worrying about tenure will interfere with all of this. So you might as well forget that there is such a thing as tenure, do your day-to-day job as best you can, and enjoy the ride.2\n Carefully evaluate any advice you receive You’ll receive tons of advice on how to get tenure, including this piece you’re reading right now. Chances are, some of the advice you hear will not jibe with you. Some of it may even conflict with other advice you’re hearing. If you try to follow all this advice to the letter, you may feel dragged back and forth, and you may be doing all sorts of things that aren’t really you. Being an academic is all about being original and independent, doing things differently than other people have done, swimming against the stream. For any piece of advice somebody gives you, I’ll be able to point to a person who ignored it and got tenure anyway.\nNow this shouldn’t be a license to behave like a complete idiot. You will need to show some productivity, you will likely need some external funding, and you need to behave reasonably towards your colleagues and your students. But beyond that, there’s many ways to skin a cat, and you’ll have to find your own.\n Write at least two papers a year A minimum of two papers a year will provide insurance against any potential claims of poor productivity somewhere up the chain in the promotion process. These claims are usually brought up when applicants have on their cv one or more years without any papers, in particular in succession. One paper a year might be sufficient, but two is safer. It protects against the vagaries of the review process, which may overly delay some of your papers.\nSince you’re working at a place that emphasizes research, writing two papers a year should be eminently doable, even if you’re doing difficult experimental work that progresses slowly. Let’s do the math. Over a five-year period, that’s about 10 papers. Three of them can be review papers, which you can write without needing any new data. Two of them should be major contributions. Let’s say one is a piece of work you started as a postdoc. That’s a paper for which you should have most or all of the data already, and you should be able to write that quickly. The other should be the first major, independent piece from your own lab, which you may submit late in year three or early in year four so it comes out in time for your tenure review. Surely your research isn’t so complicated that you can’t generate enough data for a solid paper in three years. (If it is, maybe you should reevaluate your research program.)\nThis leaves five more papers to write. Those can be small, “least publishable unit” (LPU) papers. You should be able to write one of those each year. Write something about a method you developed. Re-analyze a previously published data set. Publish some of the partial results that will eventually lead to your big paper, three years down the line. Honestly, if you can’t write at least one LPU paper a year, you have to take a hard look at your standards and ask yourself whether they’re too high.3\n Publish the same idea multiple times I’m not asking you to self-plagiarize, I’m just encouraging you to keep beating the horse even though you may think you have slain it already. If you’ve shown something once, show it again in a different way. Or in a different system. Or write a follow-up paper showing something that may be totally obvious to you given your earlier results. Then write a review paper about all of the above.\nFirst, this approach will help you with productivity. Second, and more importantly, it will associate your name with the particular effect you’re investigating. As part of the promotion process, letter writers will be asked whether you’re a leader in your field. One of the best ways to become known and recognized as a leader is to say the same thing, over and over, until it’s been heard in even the last corner of every ivory tower.\n Say “yes” to as many conference and seminar invitations as possible As I said in the previous point, being known helps tremendously with getting tenure. And traveling around the country giving talks at departmental seminars and conferences helps tremendously with being known. Thus, if you’re invited to speak somewhere, try to say “yes.” For some, this advice is a no-brainer. But if you don’t enjoy traveling, or if you have health concerns, or if you have teaching or family obligations that make it difficult to travel, you may be inclined to say “no.” Of course there are perfectly valid reasons to decline a travel invitation, and in the end you have to weigh the various priorities and make your own decision. My advice, if you have a tendency to say “no,” is to make an honest assessment of how much travel you can realistically accommodate into your life, and then plan accordingly. For example, you might decide that you can travel X times a year, or that you need at least Y weeks between trips, or that you can never travel in the spring. If you have a clear system like that, then it’ll be easy for you to take advantage of the opportunities that come your way. And you’ll also feel more comfortable saying “no” if you have a straightforward reason to decline, e.g.: “I’m sorry, this would be my second trip in August, and I never make more than one trip a month.”\n Apply for funding early, often, and widely You’ll probably need funding to receive tenure. Even if your university doesn’t make funding a requirement, you’ll probably need funding to keep your lab going/productive, and you’ll definitely need a productive lab to get tenure.\nCompared to publishing a paper, getting a grant is much harder. Most papers I write get published; most grants I write get rejected. However, the good thing about grants is that you don’t need to obtain that many. If you’re receiving one medium-sized grant every other year or so you’re doing pretty good. To maximize your chances of receiving funding, apply often and widely. You should probably write 3-5 grants a year. Most importantly, don’t just try one funding agency or one program. Even if you’re told you need the R01 to get tenure, I doubt your colleagues will be upset with you if you’re getting a nice grant from the Navy instead. Also, don’t write all of these grants entirely by yourself. Build some collaborations, and try to be part of some larger research teams. Again, even if you’re told you need the single-investigator grant, your promotion committee will certainly rank collaborative funding higher than no funding at all. And, any funding you manage to secure helps you to hire people and pay for experiments which may be preliminary results in your next single-investigator grant application.\n Make sure you recruit graduate students as soon as possible Graduate students are the lifeblood of a new lab. Attempt to recruit one or two good ones as early as possible. The moment you receive your offer letter, find out how graduate recruitment works, and make sure you’re in the system and prospective students know about you. If possible, attend events for prospective graduate students even if you haven’t actually started your position yet. Ask your (prospective) department to add you to their web site as soon as possible. If your department has a rotation system, make sure you’re on the rotation schedule.\nGraduate student recruitment happens only once a year, and if you miss the first year, you’ll risk sitting in an empty lab for a long time.\n Be careful with your postdoc hires Hiring a postdoc can be tricky for a young faculty member, unless you’re at Harvard or similar, where postdocs are willing to join any lab just for the overall reputation of the university. Most really good postdocs prefer to go to large, established labs with a proven track record. I’ve heard lots of stories from young faculty members about the postdoc woes they have gone through. This doesn’t mean you shouldn’t hire a postdoc at all. It just means you should focus on getting someone really good and vet them well. One option that may work is hiring a student from a past adviser, possibly somebody you worked with when you were a postdoc yourself. In case of doubt, recruit graduate students rather than postdocs.\n Teaching may hurt you but it is unlikely to help you If your teaching is atrocious, you may be denied tenure even if your research is stellar. However, if your teaching is stellar and your research weak, chances are nobody will care about your teaching performance. So plan accordingly. Put enough effort into your teaching so that nobody can say you are a bad teacher, but don’t sacrifice your research program for the goal of becoming the best teacher in the department.\n Do things that make you happy No matter how much you enjoy being an academic, there will be elements to your job that you don’t enjoy. It’s a job after all. Therefore, it is important that you find a balance between doing the things that you do enjoy and those that you don’t. When you’re under pressure to perform, such as with tenure looming, it is easy to get dragged down into doing mostly the things that you don’t enjoy but that must get done. You need to be aware of this dynamic and consciously work against it.\nFor example, assume you have successfully set up lab, and you now have a couple of grad students and a technician. They are all reasonably capable and they produce results. What your lab now needs is papers and grants. And you’re the only one in the lab who can write them. So, clearly, you should be spending all your time writing and none of your time doing experiments, right? This is only true if you really enjoy writing papers and grants. Let’s say you don’t. Let’s say what you really enjoy is standing at the bench doing experiments. In this case you need to find a balance such that you sometimes get to do the things that made you become an academic in the first place. Maybe you write in the morning and work at the bench in the afternoon. Or you work at the bench one day a week. Even though theoretically your productivity would be higher if you spent all your time doing the things only you can do, in practice your productivity will only stay high if you’re happy. If standing in front of a bench makes you happy, then absolutely do so, without any regrets.4\n  Not getting tenure the first time round but eventually getting it anyway seems to be somewhat common at UT. I can think of at least four cases since I’ve been here.↩︎\n See also: The Awesomest 7-Year Postdoc.↩︎\n On the topic of whether it is worth it to write low-impact papers, see also this post I wrote a while back.↩︎\n The same concept applies to balancing your job with the rest of your life. You need to do things that make you happy. Go exercise, watch a play, learn how to juggle, write a blog, write a novel. Anything that gives you joy deserves some of your time.↩︎\n   ","date":1405123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405123200,"objectID":"c18f726920ed6bdc49914784366722d4","permalink":"/blog/2014/07/12/surviving-the-pre-tenure-years-at-an-r1-university/","publishdate":"2014-07-12T00:00:00Z","relpermalink":"/blog/2014/07/12/surviving-the-pre-tenure-years-at-an-r1-university/","section":"blog","summary":"Relax, you’re not going to die.","tags":["Conference invitations","Graduate students","Grants","Postdocs","Teaching","Tenure","Tenure track"],"title":"Surviving the pre-tenure years at an R1 university","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Nutrition"],"content":"  A recent article in Time magazine argues that “gluten free” is a fad and should die. While the author makes a few good points, overall I think he misses the mark. I agree with the author that when it comes to products where the main ingredient is wheat (in particular bread, pasta, pizza base, cereals, cookies, cakes), gluten-free replacements usually aren’t that healthy. These replacement products are frequently made of rapidly digestible carbohydrates and tend to be nutrient poor. However, what the author fails to mention is that the products being replaced are also made of rapidly digestible carbohydrates and are nutrient poor. There’s really not that much of a difference between gluten-free bread made of tapioca flour and millet and regular gluten-containing bread made of wheat flour. Most people would be better off avoiding both.\nWhere the author is really off, though, is when he bemoans the marketing machine that sells stuff as gluten free that shouldn’t contain gluten in the first place, such as yoghurt or veggies. The sad truth is that we’re living in a world where everything that needs an ingredient label or is prepared in a restaurant kitchen may contain gluten. Unless you prepare your food yourself, from ingredients that can still be identified as living organisms, you don’t know. For example, salad shouldn’t contain gluten, but often does (croutons). Grated cheese gets dusted with flour. Yoghurt might contain flour as a thickening agent. Burgers and sausages may contain wheat as a filler. A steak with veggies should be gluten free but often isn’t (flour in the sauce for the steak or on the veggies). Go to a restaurant that carefully labels which items are gluten free and check out how many dishes that really should be gluten free are not labeled as such. It’s quite amazing. For celiacs, for whom avoiding gluten is crucial, anything that isn’t clearly labeled as “gluten free” is a risk, regardless of how logical it would seem that the item should be gluten free anyway.\nFinally, the author repeats the argument that always comes up in the context of gluten/wheat-free diets, that only 1–2% of the population really have severe, clinical problems with gluten. The other 98% should relax and not be so worried. The problem is that of the people who do have celiac, many don’t know and experience slowly deteriorating health without realizing what’s going on. Why should we expose ourselves to a risk, even if it is only about 1–2%, if it is so much easier to just not eat wheat in the first place?1\nI’m pretty sure I don’t have celiac, and I do eat wheat products on rare occasions. (I had a pizza on my birthday this year.) However, on the whole, I don’t see any good reason to eat wheat, and I just avoid it. While a little flour dusting on grated cheese is not going to kill me, I am disturbed by the fact that I can never be sure what I’m getting when I buy any sort of professionally prepared food, and as such I welcome that more attention is being paid to what kind of ingredients go into the food we eat. If a sausage is clearly labeled as “gluten free,” chances are it doesn’t contain bread crumbs, and that’s a good thing in my book.\n Also, keep in mind that gluten is not the only reason to avoid wheat. Other reasons are the presence of FODMAPs, lectins, and phytic acid. Wheat also has an excessively high carbohydrate density. I’m really not aware of any argument in favor of wheat.↩︎\n   ","date":1405036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405036800,"objectID":"ff7c6b3f3a103a0419d2f90d9bb2c63a","permalink":"/blog/2014/07/11/eat-more-gluten-maybe-not/","publishdate":"2014-07-11T00:00:00Z","relpermalink":"/blog/2014/07/11/eat-more-gluten-maybe-not/","section":"blog","summary":"Maybe arguments against gluten are overblown, but there aren't many good arguments in favor either.","tags":["Wheat","Gluten","Processed food","Fad diet"],"title":"Eat more gluten? Maybe not.","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development","Science"],"content":"  It’s quite common for me to have students tell me “the analysis didn’t work out” or “the figure looks bad” or “I don’t have any useful results.” And it’s also quite common for the students to be wrong. Sometimes, students have amazing results but are all disappointed because the results aren’t what they had expected. These students fail to see the data for what they are. More commonly, the students may be right in that the data aren’t that great, but usually I can see something in the data that the student didn’t. In either case, it is important that we look at the data together, because jointly we will see more than either of us individually would have seen.\nHowever, while some students are happy to show me their “failed” analyses and complain about how nothing works, others are more reserved, sometimes to the point of reluctance. The latter students don’t feel comfortable showing me their preliminary results, or sometimes any results at all, unless they think the work is completed.1 These students are probably under the mistaken impression that I will judge them for “failed” analyses, or that I expect a complete analysis, with proper interpretation of all data points, at all times, or that having remaining open questions means I’ll think the student did a poor job. On the contrary, I want to see all these preliminary, incomplete, and confusing results. The data are the data, and I want to be able to draw my own conclusions about them.\nFurthermore, I submit that unless you know for sure you made a mistake (say, your code has a bug and you know it), you will always be better off discussing your work with other people than silently deciding it’s not good enough. And if your results seem too trivial or wrong to talk about them with your advisor, then at least talk them through with a fellow student or postdoc.2 Think about it this way: every time you generate a result or make a figure, and then you delete it before you show it to somebody else, you’re preempting the possibility that somebody else might see something useful in your work. And while a lot of what you’re doing may indeed be worthless, I’d argue that unless you’re a complete disaster, you’ll probably do at least one thing every day that is actually worthwhile. So every day, you should produce some sort of result that you then discuss with somebody else.3\nImportantly, the necessity of sharing preliminary work with other people doesn’t stop once you graduate. Just because you have a PhD doesn’t mean that you’re suddenly able to always see the data exactly for what they are. Sometimes even the most experienced scientists are overly attached to a particular hypothesis or miss some critical detail in their data. That’s why many experienced scientists routinely talk to their colleagues about work in progress, why they present preliminary results at conferences or seminar talks, and why they request comments on manuscript drafts and preprints. In my mind, even traditional peer review serves primarily the purpose of having another set of eyes look over the data and check whether the authors are over- or underhyping their results.4\nThe only thing that really changes once you graduate and/or complete your postdoc is that suddenly there is no adviser anymore who makes you show him/her your latest work. Now it’s entirely on you to seek out the advice you need and to receive the feedback that will make your work better. And, if you are advising students yourself, it’s now your job to make them talk to you and show you what they’re doing, warts and all.\n If you’re my student and you think this blog post is about you, let me tell you: you’re not the only one.↩︎\n But realize that sometimes students talk each other down. Just because your fellow grad students say what you did was stupid doesn’t mean it actually was; they may just lack perspective.↩︎\n You might argue that you’re working in a field where results accumulate slowly, hence you can’t possibly discuss results from individual days. E.g., you’re collecting beetles in the field, and you need three field seasons before you have enough data to test your hypothesis. My response is that nevertheless there are tons of preliminary data that you should discuss with somebody. E.g., if you’re collecting beetles every day, you know how many you found each day, where you found them, what physical characteristics they had, etc., and how these quantities change over time. All of these are worthwhile preliminary results that you should look at, graph, and discuss with a third party.↩︎\n The second case, where reviewers see more in the data than the authors, is more common than you may think. Many papers get really good only after a solid round of peer review, and frequently the reviews in those cases are not “X is wrong” but rather “You have done X but you should also do Y, and in combination you could conclude Z which would be really cool.”↩︎\n   ","date":1404777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404777600,"objectID":"2e873960f199eb8a0f9e0186565cf31d","permalink":"/blog/2014/07/08/share-your-preliminary-work-with-other-people-even-if-you-think-its-crap/","publishdate":"2014-07-08T00:00:00Z","relpermalink":"/blog/2014/07/08/share-your-preliminary-work-with-other-people-even-if-you-think-its-crap/","section":"blog","summary":"It's important to get feedback, in particular on projects you think aren't going well.","tags":["Graduate school","Postdocs","Peer review"],"title":"Share your preliminary work with other people, even if you think it’s crap","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  After my last post discussing how to develop a research question, Sergey Kryazhimskiy asked me to write about how to find the rare good research idea among the many mediocre ones.\n@ClausWilke After 2 successful projects the problem shifts to choosing a rare good research idea among many mediocre ones. Next post? 2/2 — Sergey Kryazhimskiy (@skryazhi) June 16, 2014   The truth is that I don’t really know how to do this. If you do, please tell me. I’m sure I could strengthen my research program by picking better problems. Nevertheless, despite my ignorance, I’ve had a reasonably successful career to date. And it was probably not entirely due to sheer luck. So this should give you hope. Even if you don’t know how to pick good problems, you may succeed in science nonetheless. Just work on the problems that seem important to you and hope for the best.\nBecause I don’t know how to answer Sergey’s question, at first I thought that I wouldn’t have much to say on this topic. However, not knowing something hasn’t kept me from writing a 1500-word blog post about it. After some pondering, I thought it might be useful to review what other people have said on this topic. If you spend some time with Google, you’ll find expert advice on how to choose a good research problem. For example, in Uri Alon’s paper “How To Choose a Good Scientiﬁc Problem”,1 there is a nice graphic (here reproduced as Figure 1) ranking potential problems according to their difficulty (hard to easy) and according to the gain in knowledge their solution would provide (small to large). Easy problems with a small gain in knowledge are good beginner problems, hard problems with a large gain in knowledge are good long-term goals for an established researcher, and easy problems with a large gain in knowledge are perfect for a postdoc. And nobody should work on hard problems that lead to small gains in knowledge.\n Figure 1: Pareto front of worthwhile research questions. Research questions can be ranked according to difficulty (hard to easy) and gain in knowledge (small to large). The best problems are those that provide the maximum gain of knowledge for the chosen difficulty level. One should never work on hard problems that provide little gain in knowledge. After U. Alon (2009).  This is all nice and well, until you realize that it is basically impossible to rank problems a priori along either dimension. Uri Alon’s paper explains why. Science does not normally progress in a direct path from A to B. We may intend to work towards B, but on our way there we get stuck in “the cloud,” where every attempt to get closer to B fails, until eventually we give up and go for C, a problem that we hadn’t even considered beforehand (Figure 2). The two immediate consequences of this process are that (i) we don’t know how hard it will be to get from A to C, and (ii) we don’t know how much of a gain in knowledge C will provide, in both cases because we don’t even know C exists when we start. Thus, even though Uri Alon’s ranking of problems along difficulty and gain in knowledge is beautiful and convincing, it is also quite useless.\n Figure 2: How we would like to do science (left) and how it actually works (right). Here, A represents what we currently know and B represents what we would like to know. Our desire is to move from A to B in as direct a line as possible. However, we usually get stuck as we are approaching B, things don’t work out, and we keep taking detours and going in circles. Uri Alon calls this state the cloud. Eventually, we give up on reaching B and instead head for C, a new insight that we found while wandering in the cloud. Usually, C represents the solution to a problem we weren’t even aware of when we started. After U. Alon (2009).  So, what can be done? If we keep reading Uri Alon’s article, we find that he makes some useful suggestions on how to pick important problems. He writes:\n One of the fundamental aspects of science is that the interest of a problem is subjective and personal. (…) Ranking problems with consideration to the inner voice makes you more likely to choose problems that will satisfy you in the long term. (…) One way to help listening to the inner voice is to ask: ‘‘If I was the only person on earth, which of these problems would I work on?’’ (…) Another good sign of the inner voice are ideas and questions that come back again and again to your mind for months or years. (…) It is remarkable that listening to our own idiosyncratic voice leads to better science. It makes research self-motivated and the routine of research more rewarding. In science, the more you interest yourself, the larger the probability that you will interest your audience.\n So, if you’re not sure which problems to work on, work on the ones that excite you!2\nUri Alon is not the only one who has commented on this topic. The famous computer-science pioneer Richard Hamming (of the Hamming distance and Hamming codes) used to give a talk entitled “You and Your Research,” which touches on this issue among other things. You can read a transcript here.3 The whole thing is worth reading. Here, I’ll just cite a few relevant paragraphs. First this one:\n When you are famous it is hard to work on small problems. This is what did Shannon in. After information theory, what do you do for an encore? The great scientists often make this error. They fail to continue to plant the little acorns from which the mighty oak trees grow. They try to get the big thing right off. And that isn’t the way things go. So that is another reason why you find that when you get early recognition it seems to sterilize you. In fact I will give you my favorite quotation of many years. The Institute for Advanced Study in Princeton, in my opinion, has ruined more good scientists than any institution has created, judged by what they did before they came and judged by what they did after. Not that they weren’t good afterwards, but they were superb before they got there and were only good afterwards.\n In other words, don’t try too hard to make a big splash. Just keep working on a variety of problems and see which ones turn out to be useful. While you do so, take notice of things that repeatedly don’t work. Those may be hints that can lead to major insights:\n I think that if you look carefully you will see that often the great scientists, by turning the problem around a bit, changed a defect to an asset. For example, many scientists when they found they couldn’t do a problem finally began to study why not. They then turned it around the other way and said, “But of course, this is what it is” and got an important result.\n And finally, keep an eye out for great opportunities:\n The great scientists, when an opportunity opens up, get after it and they pursue it. They drop all other things. They get rid of other things and they get after an idea because they had already thought the thing through. Their minds are prepared; they see the opportunity and they go after it. Now of course lots of times it doesn’t work out, but you don’t have to hit many of them to do some great science. It’s kind of easy. One of the chief tricks is to live a long time!\n What can you do to increase the chance that opportunities come your way? Here is Feynman’s suggestion, as recounted by Gian-Carlo Rota:4\n You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did he do it? He must be a genius!”\n The goal is thus to wander around in the cloud and always keep an eye out for exciting opportunities that may open up. While you’re in the cloud, aiming for B, there may be many C’s that come your way that you could pursue, but most of them will not be worthwhile (Figure 3). However, on occasion, you stumble upon something that is really neat (C6 in the Figure), and when that happens you should drop everything else and pursue that opportunity. I would recommend applying the following test: Do you personally think you’ve stumbled upon an exciting opportunity? If yes, go for it. If no, keep looking for something else to work on.\n Figure 3: Scientific opportunities in the cloud. While we are stuck in the cloud, we encounter all sorts of new insights. Most of them are boring, however, and we shouldn’t pursue them further. But, on occasion, we stumble upon an exciting new insight. When this happens, great scientists drop everything else and seize the opportunity.  In this whole process, you might wonder what’s the point of B. If we never get to B, do we need it in the first place? I think we do. B gives us a broad sense of direction while we’re not sure where we’re going in the cloud. Until we have identified an exciting opportunity C, we might as well keep chasing B. Who knows, with luck, we might even manage to get to B at some point. It happens on occasion.\n U. Alon (2009) How To Choose a Good Scientiﬁc Problem. Mol. Cell 35:726-728.↩︎\n It should be noted here that the degree to which a problem is of interest to the broader scientific community depends also on how well it is marketed. You can pick problems you know the community finds interesting, or alternatively you can convince the community that they should find interesting what you are working on. Many of the very successful scientists do the latter. In fact, fame and recognition often go to the person who convinced the community that a problem was worthwhile, not to the person who actually solved the problem in the first place.↩︎\n Hamming gave this talk many times. The transcript available here is from March 7, 1986. There is also a video recording, from June 6, 1995. The transcript and the video are largely identical, but I found that the video added a few interesting points that weren’t in the transcript.↩︎\n G.-C. Rota (1997) Ten Lessons I Wish I Had Been Taught. Notices of the AMS 44:22-25.↩︎\n   ","date":1403049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1403049600,"objectID":"867052a04b4553dfb5d28ca1ae308653","permalink":"/blog/2014/06/18/how-to-develop-a-research-question-part-ii/","publishdate":"2014-06-18T00:00:00Z","relpermalink":"/blog/2014/06/18/how-to-develop-a-research-question-part-ii/","section":"blog","summary":"The real key to success is to formulate the question after you've found the answer.","tags":["Graduate school","Postdocs","Uri Alon"],"title":"How to develop a research question, Part II","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  One of the most daunting prospects for a fresh graduate student is having to develop a solid research question.1 In my experience, many graduate students feel like they don’t even know where to start. The literature can seem overwhelming, everything has already be done by somebody, and in any case it’s impossible to really know all the literature there is anyway. Making matters worse, almost every cohort or lab inevitably has one or two students who just seem to be fountains of good ideas, who constantly come up with new research ideas they want to pursue. As a result, students who are less inventive or less imaginative can feel like they’re not cut out for a career in research, they’re never going to have the necessary ideas to sustain a research program.\nI strongly believe that having good ideas is a skill that can be learned. There are simple strategies that almost always work. In the following, I describe one strategy in particular that I’ve found useful over the years.\nDefine a vision for your research Before you start doing any concrete work towards developing your specific research question, you need to know what broad topic you want to work on. I call this the research vision. It turns out that developing a research vision is not that hard, for two reasons: First, the vision doesn’t have to be that specific; it doesn’t have to come with specific ideas for projects you want to do or questions you want to pursue. It’s just a guiding idea that tells you where to start. For example, a vision could be “I want to do computational work in cancer genomics” or “I want to study experimentally how bacteria adapt to novel environments” or “I want to work in infectious disease epidemiology.” Second, choosing a particular vision over another one is generally a low-stakes decision. There is interesting and valuable research to be done in the context of nearly any reasonable research vision.\nThe one thing you should double-check though, in particular as graduate student or postdoc, is whether the vision you want to pursue fits broadly into the topics your lab is working on. If you’re in a molecular biology lab that studies cancer genetics but your research vision is to investigate the effects of climate change on future precipitation patterns then you have a problem. In this situation, either find a different research vision or consider switching labs.2\n Read the literature Once you have decided on your research vision, you need to start reading the relevant literature. There are two ways to proceed: First, if your research vision matches well with the work that is already going on in the lab you’re in, then start by reading the lab’s papers. Also, ask your PI for suggestions on which papers to read. Use all these papers as your starting point for a careful literature search.\nSecond, if your research vision deviates somewhat from the current direction of the lab,3 or if there are other reasons why you can’t ask anybody for relevant papers, then skip right ahead to the literature search.\nTo start your literature search, enter some key words or phrases into Google Scholar and see what comes up. Google Scholar tends to place the most highly cited papers at the top of its search results, so you’ll almost never go wrong by looking into the top hits. Using these papers as your starting point, expand your search by reading the papers that they cite (searching backwards in time), and also look up the more recent papers that cite them (searching forward in time).4 By alternating between backwards and forwards search you will develop a solid grasp of the field.\nIn addition to Google Scholar, the “related citations” function on PubMed is also an excellent way to deepen your knowledge of the field. Look up a paper on PubMed, and then read through the papers that PubMed flags as related to the paper you looked up.\n Stop reading the literature and start doing something It’s great to be a well-read scientist. Most students don’t read enough. There’s always something else to read. However, at some point, you have to stop reading and start doing. To give a concrete (but somewhat arbitrary) cutoff: If you’ve been reading for two months or more, or if you’re familiar with over 100 papers in your broad area, and you still feel like you don’t know enough of the literature to come up with your own project, then reading even more is likely not going to improve your situation much. At this point, it’s more important that you start doing actual research.\nHow do you start if you’re not sure what your project is? My recommendation is to always start by reproducing somebody else’s work. Among all the papers in your broad area that you have read, pick one or two that you liked the most, and simply try to repeat what they did.5 Very quickly, you will discover a few things: 1. It’s not that easy to reproduce existing work, and you can learn a lot in the process. 2. There are flaws, limitations, or pitfalls that weren’t really described in the paper. Maybe the paper’s methods work only under very specific conditions and fail the moment you try something slightly different. Or the methods are somewhat unreliable and fail at random times/under random conditions. 3. There are all sorts of things you’d like to know. Such as why the methods always fail when it’s raining outside. Or why there are certain strange trends you see in the raw data. 4. There are all sorts of things you’d like to have. Like a better way to prep your samples. Or some additional measurements no existing method can produce.\nVoilà, you have your research question. In fact, you probably have more than you bargained for.6 You may have so many questions that you still don’t know where to start.\n Keep it simple Now it’s important to keep things simple. Of the many open questions you have, pursue the one that requires the simplest possible extension to existing work but will still provide meaningful progress.\nI don’t think I’ve ever seen a student fail for trying to do something too simple. However, I’ve seen plenty of student fail for trying things that were too complicated. Most students overestimate the complexity that is required to do good science. It’s better to do something simple, write it up, and publish than to do something complicated, get stuck, and get discouraged.\n Conclusions You may think the whole process I propose is haphazard. I suggested you start with a random topic, do some reading, try to reproduce somebody’s work, and then pursue some extension to the work, an extension that will hopefully reveal itself to you as you work on the topic. The reason why this seems haphazard is because it is. Science doesn’t follow a simple A to B path. Albert Einstein famously said “If we knew what it was we were doing, it would not be called research.” Uri Alon calls it being stuck in the cloud. Donald Rumsfeld talked about the unknown unknowns. Even though Rumsfeld wasn’t talking about scientific research, he correctly described the world in which most scientists operate day to day. We usually don’t know what we’re doing, we don’t know where we’re going, and we don’t know what we don’t know. However, we do stuff anyway, and from time to time we stumble upon a useful and novel bit of knowledge.\n  And sometimes, postdocs or even young faculty members struggle with the same issue. It mostly depends on when you were asked for the first time to come up with your own project. If your graduate project was basically handed to you by your PI, and similarly during your postdoc you were working on somebody else’s project, then you may never have independently developed a project before becoming an assistant professor.↩︎\n I would almost always recommend against switching lab while in grad school, but that is a topic for a different post.↩︎\n It may seem strange that a graduate student would have her own research vision that differs from the lab’s vision. However, this scenario is often quite productive, both for the student and for the lab. The best PhD theses can take an entire lab into a new direction. PIs are generally aware of this and want their students to bring new ideas into the lab.↩︎\n Searching forward in time used to be a complicated undertaking but it is trivial with tools such as Google Scholar. Simply click on “cited by” and see which other papers cite the paper you’re interested in.↩︎\n Of course, you have to choose a paper that uses methods and/or materials that you have access to. If your favorite paper in the field uses a mass spec and you don’t have access to one then that’s a bad paper to try to reproduce.↩︎\n That’s one of the reasons why senior scientists usually have tons of research ideas. The longer you’ve been around in science, the more you’re aware of what we don’t know.↩︎\n   ","date":1402790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1402790400,"objectID":"356f3e60365fe29aa6f7e8cd423c1855","permalink":"/blog/2014/06/15/how-to-develop-a-research-question/","publishdate":"2014-06-15T00:00:00Z","relpermalink":"/blog/2014/06/15/how-to-develop-a-research-question/","section":"blog","summary":"\"If we knew what it was we were doing, it would not be called research.\"","tags":["Graduate school","Postdocs","Unknown unknowns","Uri Alon","Vision"],"title":"How to develop a research question","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  I just saw this nice TED Talk by Uri Alon about how new scientific insights are generated. Even though the talk is a year old I think it’s worth posting, so here you go.\nUri makes a number of points that I’ve been aware of for a long time but have never seen expressed quite so clearly:\nDiscovery is not linear. We usually don’t obtain the result we were aiming for. However, as we try, we make worthwhile discoveries that constitute the real scientific progress.\n It is not helpful to shoot down ideas before you’ve even tried them. Statements like “this is never going to work” “this is too complicated” “X, Y, and Z are going to go wrong” “nobody will believe me anyway” are all not useful. Accept the crazy ideas, try them out, and see what happens. Say “yes and …”\n Being worried about your research shuts down your creativity. Try to be more relaxed, even if things don’t go the way you think they should. Don’t try to obtain a particular goal, focus more on exploring the unknown.\n When things don’t go well, talk to other people, look for support. Science can be hard on your mental well being, and to keep going sometimes you just need people to cheer you on.\n  ","date":1402704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1402704000,"objectID":"8f4fa0ee66ea6c770c4900103425a00f","permalink":"/blog/2014/06/14/uri-alon-on-creativity-and-staying-sane-in-science-yes-and/","publishdate":"2014-06-14T00:00:00Z","relpermalink":"/blog/2014/06/14/uri-alon-on-creativity-and-staying-sane-in-science-yes-and/","section":"blog","summary":"Don't shoot down ideas before you've even tried them.","tags":["Anxiety","Creativity","Discovery","Graduate school","Postdocs","Uri Alon"],"title":"Uri Alon on creativity and staying sane in science: \"Yes and ...\"","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  I was asked the other day what factors to consider when picking a thesis committee. And I realized that this is not a question I have pondered a lot. Normally, when one of my students needs to pick a committee, I just recommend people that seem a good choice. I don’t have a properly thought out, systematic framework to steer the selection process. So with this post I’ll try to develop a more systematic approach to this question.\nLet’s first think about the purpose of the thesis committee. There are at least four distinct functions the committee should perform: 1. The committee should be your personal science advisory board. It should provide relevant expertise you or your adviser may lack. 2. The committee should review your research approach and verify that your data support your conclusions. 3. The committee should make sure you progress adequately and stay on track. 4. The committee should serve as advocates on your behalf in case your adviser develops unreasonable expectations.\nThe advisory-board function is probably the most straightforward to satisfy. Pick a group of people that, jointly, cover the topics relevant to your work. For example, if you work on the evolution of influenza virus, you might want to pick an expert in the molecular biology of influenza, an evolutionary biologist, an epidemiologist, and a computational biologist or biostatistician.1 Of course, to some extent the choice may depend on the expertise of the lab you’re in. If your lab is an influenza lab then your adviser may be the influenza expert and it might be more important to have another evolutionary biologist. By contrast, if your lab is an evolution lab, it might be more important to bring in more influenza expertise.\nFor the remaining three points, personality of your committee members matters more than expertise. You want people who will speak up, who won’t let you get away with BS, but also who care for you and won’t put you through any unnecessary difficulties. Basically, people who can give you tough love. I wouldn’t worry too much about picking people who have a reputation of speaking their mind. Once you’re past candidacy, it’s unlikely that you will be kicked out of graduate school, and in any case if there are issues with your performance or research approach you’d want to hear about them earlier rather than later. In my mind, the worst committees are those that let a student bumble along for six years and then say “Well, this work doesn’t quite rise to the level that we expected from a PhD.” I think the best committee members are those that push you to develop a clear plan on how to complete your work, that tell you exactly what they expect from you before you can graduate, and that reign you in when your plans get overly ambitious (which happens to almost every student).\nNext, consider possible inter-faculty dynamics. Don’t put two professors on your committee that are known to have issues with each other. You might end up as collateral damage in a fight between them.2 Also, make sure your committee has at least some members who could speak up against your adviser if necessary. If your adviser is a very senior scientist, choosing four assistant professors as committee members would be inadvisable. Have at least one, and better two or more, committee members of comparable rank and seniority.\nCommittee members to avoid are those that are overly passive, that like to talk just to hear themselves speak, and that tend to get lost in tangents or irrelevant minute details. Your adviser and your fellow graduate students should know who they are. Finally, it’s important that your committee members are actually available to you. The best committee doesn’t do you any good if you can never get them all into the same room at the same time. Therefore, I’d advise against any committee members who have a reputation for being difficult to schedule. It is generally known in the department who is never around, or who may rarely have more than one open time slot every few weeks. All else being equal, I would recommend against putting such a person on your committee.\n Every committee should have a computational biologist or biostatistician, to verify data is analyzed properly and results are statistically sound.↩︎\n I have never personally witnessed something of this sort happening, but I’m sure some poor graduate student somewhere is finding himself or herself in exactly this situation right now.↩︎\n   ","date":1390694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390694400,"objectID":"0af07853be2c13350e091560f7691d8e","permalink":"/blog/2014/01/26/how-to-pick-a-thesis-committee/","publishdate":"2014-01-26T00:00:00Z","relpermalink":"/blog/2014/01/26/how-to-pick-a-thesis-committee/","section":"blog","summary":"The thesis committee is all that stands between you and graduation, so choose wisely.","tags":["Graduate school","PhD committee"],"title":"How to pick a thesis committee","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  One of the eternal questions of graduate schools is whether you should work with a junior or a senior PI. I have commented on this question before and argued that either decision can be the right one. Here, I present a more comprehensive list of arguments for and against. As you’ll see, there are plenty of arguments going both ways. You may assign more weight to some than others and thus arrive at a decision that is best for you. Ultimately, I think it doesn’t matter too much; there are other factors that are more important, such as whether you enjoy and fit in with the lab’s culture and approach to research, collaboration, publication, and so on.\nSo here is my list. If you can think of something I forgot, please let me know in the comments.\n6 reasons to do your graduate work in the lab of a junior PI If you’re one of the early students in the lab of a rising star, you can rise to prominence with your PI. You may end up as the first author in one or more of your PI’s key publications, and this in turn may secure your own faculty position and seniority in the field.\n A junior PI may have more time to supervise you. The lab is likely relatively small and you’re not competing with 10 other lab members for your PI’s attention. Also, your PI may not yet be that involved with university service and other non-research obligations, and thus have more time to interact with the lab (i.e., you).\n A young lab may be doing some really novel, cutting-edge work. An older lab is more likely to work on the stuff they’ve always worked on, stuff that was real innovative 10 years ago but is an old hat now.\n If your PI is not that established, there’s less risk that once you graduate your adviser is such a towering influence in the field that you can’t establish yourself as distinct from him/her.\n In a large, established lab, you might find yourself working on a small part of a larger project. Even if you do excellent work, your name might in the end not get associated with the big paper that comes out of that work. (I’m not saying you won’t be a coauthor. I’m saying you might be one of 20 coauthors and nobody will think you were the person who made it happen.)\n The younger your adviser, the less likely it is that he or she come down with a debilitating disease or die a sudden death. For example, the risk of death of a 60-year old man is 10 times higher than that of a 35-year old man. Just avoid younger PIs with a passion for BASE jumping, cave diving, or motorcycle racing.\n   6 reasons to do your graduate work in the lab of a senior PI A junior PI is untested. It is less clear how sustainable the PI’s research program is, how likely the PI will be able to attract funding, and how good his/her research ideas are. If the junior PI is on a bad trajectory, it is likely that your PhD won’t be that great either. (Keep in mind, though, that your PI’s success depends to some extent on you!)\n A junior PI may not be that powerful or well-connected in the field. The two of you may find yourselves fighting uphill battles with reviewers, journal editors, and other labs in the field. The exact same work might be lauded as the world’s greatest invention since sliced bread when coming from an established, senior lab or derided as inconsequential, boring, or wrong when coming from a junior lab. Having a junior adviser can also make it harder to find an academic job after you graduate.\n A junior PI may not be that powerful or well-connected in the university. This may put you at a disadvantage when it comes to TA positions, university fellowships, and other dealings with university administration. In particular, if something unexpected happens, e.g. the class you were supposed to TA for gets cancelled, a senior PI is more likely going to have resources to deal with the situation.\n The lab of a junior PI may not have the resources you will need to carry out outstanding research. In particular, if you join a lab in its first or second year, you may find yourself spending a year or longer just setting up lab infrastructure. By contrast, a large, established lab will likely have everything you need to do ground-breaking work the moment you walk into the door.\n Since your PI is new, he or she still has to prove himself/herself. As a result, your PI might end up competing with you. For example, a junior PI might insist on being the one presenting your work at a conference where a senior PI might let you present your work yourself.\n If you join the lab of an untenured professor, you risk that your PI won’t get tenure while you’re in the lab. That experience is likely going to be as disruptive to you as it will be to your PI. The worst-case scenario is an upcoming tenure decision 2-4 years out from when you start your PhD. If you’re only in your first year when your PI doesn’t get tenure, you should be able to just join another lab, without having wasted much time and effort. And if you’re in your fifth year or later, you should be able to finish up your dissertation work even if your PI has to close down his/her lab and move on. But if you’re right in the middle of your thesis work, you may have to throw away 2-3 years of work and start from scratch.\n   ","date":1390608000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390608000,"objectID":"11ead509ea91034bb52c87de5efec235","permalink":"/blog/2014/01/25/6-reasons-to-do-your-graduate-work-in-the-lab-of-a-junior-pi-and-6-reasons-not-to/","publishdate":"2014-01-25T00:00:00Z","relpermalink":"/blog/2014/01/25/6-reasons-to-do-your-graduate-work-in-the-lab-of-a-junior-pi-and-6-reasons-not-to/","section":"blog","summary":"There's pros and cons to everything.","tags":["Academic career","Graduate school","Junior PI","Postdocs","Senior PI"],"title":"6 reasons to do your graduate work in the lab of a junior PI, and 6 reasons not to","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  It’s the beginning of the new year, and with it comes graduate admissions time. If you are currently applying for graduate programs in the sciences, you hopefully have received or will soon receive one or more invitations to interviews or recruitment events. If you’re wondering what such an invitation means, how these events work, and how to best prepare yourself, read on.\nFirst off, if you got invited, congratulations! You are well on your way to graduate school. For most programs, if you get invited to an interview, you have at least a 50% chance of getting admitted. Programs rarely invite more than twice the number of candidates they want to offer admission to, and frequently they plan to offer admission to nearly everybody they invite. Thus, a 50% chance of admission is actually a fairly conservative lower bound. Your chances may very well be substantially higher.1\nIn fact, it’s important for you to realize that most programs are probably more worried about you not accepting their offer than you should be worried about them not making you an offer. Most graduate programs lose approximately half their candidates at the acceptance stage, i.e., the programs offer admission to twice as many students as actually end up joining the program. Therefore, you may be surprised to what an extent an interview weekend can turn into an advertising event for the school rather than an evaluation of your abilities to join the program.\nHowever, since the recruitment event may nevertheless contain a genuine evaluation component, you’d do well to prepare yourself properly for that aspect of the event. Below follow a few suggestions.\nRelax. The stakes really aren’t that high, and if you just present yourself as a normal and reasonable person chances are good you’ll get admitted. In particular, if you try to sell yourself too hard or appear overly eager you may make a worse impression than if you present yourself simply as an average prospective student. Remember, at an acceptance rate above 50%, many of the average prospective students get accepted.\n Prepare for one-on-one interviews with faculty. If your program is selective, then the key action happens in one-on-one meetings with faculty members. You will probably be scheduled to meet with 3-5 different faculty members. Prepare yourself for these meetings. Figure out what the faculty members are working on and read some of their recent papers as well as some of the classic papers that made them famous.2 Keep in mind that stuff they have published three years ago may not be something they are working on today.\n  Make the faculty talk. Don’t assume you know what faculty members are interested in just because you have read some of their papers. Most active scientists are particularly excited about the work they are doing right now, or are planning to be doing next month. So, ask the faculty members what they are currently working on, what the main directions are for the lab, and for what projects they are currently recruiting students.3  Have broad interests. You will be asked what kinds of topics you are interested in. I would recommend a broad answer to this question, such as “I’m interested in host-pathogen interactions” or “I’m interested in microbial ecology” or “I’m interested in computational systems biology.” Most faculty members who recruit graduate students will have a specific project for which they are looking for a suitable candidate, and you are unlikely to guess what exactly they have in mind. If your answer is too specific (“I want to test this particular hypothesis, using methods A, B, and C in this particular experimental framework”) you risk giving the impression that you have little flexibility to adapt to the needs and interests of the lab. Of course, if you are asked explicitly to describe a particular study you might want to carry out, then describe one in detail.\n Have a clear vision. It’s important to strike a balance between having broad interests and having no focus. In general, students who know what they want and know what their strengths and weaknesses are appear more competitive. If you see yourself primarily as a computational person, say so. If you want or don’t want to work with particular model systems, say so. (E.g., saying something like “I really want to work with bacteria” or “I am not particularly interested in microbes” is perfectly fine.) If you have one or two labs you are most excited about, say so.\n Express a clear interest in one or a few labs. The best strategy here depends on the type of graduate program you’re interviewing with. If the program has a rotation system, then you need to be able to list a few labs that you could rotate in, otherwise you won’t look like a good fit for the program. If the program doesn’t have a rotation system and instead admits students directly into particular labs, then it’s Ok to be focused on one particular lab, or maybe two labs. For the latter types of programs, realize however that if you want to join lab A but they don’t have a slot for you then you may not get admitted, even if lab B would have been a perfectly reasonable choice for you and you for them.\n  And finally, if there’s a social event with alcohol involved, don’t get mindlessly drunk and start behaving inappropriately. Even though I’ve known students to do so and get admitted nevertheless.\nUpdate (01/15/2014): Several additional recommendations have been mentioned to me since I posted this. I’ll keep adding relevant information below.\nFor your one-on-one interviews, have answers for the following two questions: 1. Why do you want to get a PhD in …? 2. Why do you want to join this program/attend this university? Also, be prepared to give a 2-5 minute summary of your past research and be able to expand this to 20-40 minutes if prompted by an interviewing faculty member.\n Unfortunately, there is no way to know for sure, unless you have heard the inside scoop from a member of this year’s admissions committee. Just because a program admitted 80% of their candidates last year doesn’t mean they won’t reduce their admissions pool to 50% this year and vice versa.↩︎\n You find these papers by searching for the faculty member’s publications on Google Scholar or Web of Science, sorting by number of citations (Google Scholar does this automatically), and looking at the most highly cited papers on which the faculty member was either first or last author.↩︎\n The last question may not be applicable if it’s unlikely you would join that person’s lab. Some of your one-on-one interviews will likely be with members of the admissions committee or simply other faculty members that were willing to do a few interviews. When you interview with those faculty, don’t pretend you’d want to join their lab if you know you never would. Do, however, ask the questions about current work and main directions of the lab. Those questions are always appropriate.↩︎\n   ","date":1389657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1389657600,"objectID":"3a0d3ebd2db5a01e6c68713d2580f0b7","permalink":"/blog/2014/01/14/understanding-the-graduate-school-interview-or-recruitment-event/","publishdate":"2014-01-14T00:00:00Z","relpermalink":"/blog/2014/01/14/understanding-the-graduate-school-interview-or-recruitment-event/","section":"blog","summary":"The hardest part is to get invited in the first place.","tags":["Graduate admissions","Graduate school","Undergraduates","Recruitment weekend"],"title":"Understanding the graduate-school interview or recruitment event","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development","Science"],"content":"  I would like to talk about what it takes to be a computational biologist, specifically in comparison to being an experimental biologist. If you’re wondering whether instead of becoming a computational biologist you should become a race-car driver, fighter pilot, or ballet dancer, this post probably won’t help you. But if you’re wondering whether a computational biology lab is a better choice for you than an experimental biology lab, this post should provide you with some useful guidelines. To cut right to the chase, here is the take-home message: To become a computational biologist, you need to want to become a computational biologist.\nWhen I interview students who are potentially interested in joining my lab, the interviews inevitably take one of two routes, depending on the students’ background. The students with extensive computational experience usually make a point emphasizing all the techniques, systems, and languages they have learned, to showcase their technical expertise. By contrast, the students with little computational experience are usually rather timid. They say that they might be interested in computational biology but don’t really know much about it, and also that they don’t know if they would be any good at it.1\nThe truth is, I don’t really worry much about pre-existing expertise.2 Sure, I won’t be disappointed if a student knows a lot already, but it plays a rather minimal role in my decision of whether or not to take a particular student.3 I think that computation can be learned relatively easily, if you really want to learn it, so what matters much more than your current knowledge is your intention.4 For this reason, when students express any concern about their ability to be computational biologists, I usually ask them a simple question: Would you rather spend your day in front of a bench pipetting, or would you rather spend your day in front of a computer screen staring at symbols and numbers? Anybody who would rather stare at a computer screen is going to be fine in my lab, and anybody who would rather pipette is not going to have a good time.\nIn fact, too much pre-existing computational knowledge can be a disadvantage, when the students think they know things better than they actually do. At least the inexperienced students are a blank slate. They are willing to listen and they accept the conventions of the lab. The more experienced students may have idiosyncratic views on how things should be done, views that may make sense from their perspective but not from the perspective of the person running the lab (i.e., me). For example, a student who insists on using java for a project when the rest of the lab uses python is going to cause problems,5 even if he has lots of experience with java and none with python. With some experienced students, I spend as much time re-training them as I would have spent with less experienced students training them from scratch.\nSo, if you don’t have a lot of computational experience but you would like to do computational work, ask yourself whether you have the patience to hack away for hours in front of a computer screen, until you have solved a problem. If the answer is yes, you’ll be fine. And if you do already have a lot of computational experience, keep an open mind, realize that there is probably still a lot you can learn, and accept that some things are just conventions. Even if you don’t like a particular convention (such as “we use python”) you should accept it if you want to be successful in your lab.6\n Actually, more recently there is also a third type, students who think they have computational experience but they really don’t. MS Word, Excel, or Facebook do not count as computational experience. If you have never written an actual program and never used a command line, you don’t have any meaningful experience.↩︎\n This statement applies to undergraduate researchers or prospective graduate students. I wouldn’t hire a postdoc without any computational expertise. If somebody has done a purely experimental PhD they are unlikely going to be a good match for my lab at the postdoc stage, since we don’t do any experiments whatsoever.↩︎\n I tend to evaluate students primarily on whether they appear to be motivated, whether they appear to be smart, whether I can connect with them, and whether I think they would fit into the lab.↩︎\n This point is also made here. As long as people give you a chance to try yourself at programming and you make an effort, you should be fine.↩︎\n As just one example, it will be more difficult for other students to take advantage of that student’s work and vice versa. Further, once the student leaves, the project may be abandoned or somebody else may have to re-engineer it using the lab’s preferred language.↩︎\n I acknowledge that there may be situations where the convention a lab has chosen is genuinely poor, and where the student truly knows better than the faculty member how to do things properly. However, I think these situations are rare, in particular for labs run by experienced computational biologists. And moreover, if you as a student really have so much computing experience that you can see all the poor decisions your PI is making, why did you join the lab in the first place? You should have seen these issues ahead of time. For example, if I were a prospective graduate student now, and I was told a lab did everything in perl and fortran, I’d run. By contrast, if they used languages I approve of, if they deposited their code on github, and if the code they deposited looked more or less decent, then I should be fine in that lab.↩︎\n   ","date":1389312000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1389312000,"objectID":"5c40247ffbaac16eb2970c7b029c3d28","permalink":"/blog/2014/01/10/what-does-it-take-to-be-a-computational-biologist/","publishdate":"2014-01-10T00:00:00Z","relpermalink":"/blog/2014/01/10/what-does-it-take-to-be-a-computational-biologist/","section":"blog","summary":"Most importantly, you have to want to be a computational biologist.","tags":["Computational biology","Computing","Experimental biology","Graduate school","Undergraduates"],"title":"What does it take to be a computational biologist?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Science"],"content":"  In the ongoing discussion about the value of glamour journals such as Nature, Science, and Cell, I think it’s worth looking back and asking: “How did they rise to prominence?” and “Are they still serving the same role they did when they arose?” So let’s take a quick trip into the history of science communication, before the internet. Then we can ask what the internet has changed, and how we could make the best of current technology.\nI belong to the last generation of scientists that experienced science before the internet. I started doing research as an undergrad in 1995. At that time, I saw a web browser for the first time, and I sent my first email. While the internet had been around for a while by 1995,1 its use was still very limited, and barely anybody outside academia had ever even heard of it. All this would change over the next 4-5 years, and by 2000 the internet started to become ubiquitous.\nI don’t think anybody who got into science after the year 2000 can imagine what keeping up with the literature was like before the internet. I started my postdoc in 2000. During my entire postdoc time (or since), I rarely ever went into a library. By that time, most journals had a solid online presence, including back issues. Articles that weren’t available online could be requested via inter-library loan, and they would arrive electronically. By contrast, during my PhD, I spent a lot of time at the library. I would make weekly trips to browse the latest issues of the scientific journals I was interested in. Because I was working at the interface between physics and biology, I had to visit the physics library and the biology library. For certain articles I also had to go to the chemistry library. I knew exactly which library had which journals, and which journals were available in multiple libraries. (Almost all libraries had Science, for example.) To figure out whether anybody was citing a particular paper, I had to confer with the Science Citation Index, which was a big book available at some libraries. For any article of interest, it would list by which other articles it had recently been cited. Invariably, the list of citing articles would contain articles in journals that were only available in a different library on campus, or not in any library at my university. So, after reading the Science Citation Index, I’d make the trip to a different library, or submit an inter-library loan request, or make a note for my next scheduled trip to a different library to look up a particular article. In the worst-case scenario, it could take weeks until I saw a particular article, and then I’d often find out the article wasn’t really relevant to what I was doing.\nCompare this to how literature search works today. I look up an article on Google Scholar, click on “Cited by” or “Related articles,” and find relevant related articles in seconds. For every article listed, I can get at least the title and the abstract, and for the vast majority of articles I can get the full text, all within a few seconds and while sitting at home on my couch. I can similarly browse any open-access journal, everything on Pubmed Central, and any paywalled journal my university has access to, from everywhere in the world. For all intents and purposes, the second I know a particular article exists, I can look it up and read it.\nWhat has any of this to do with glamour journals? I’m going to argue that in the time before the internet, glamour journals and other highly selective journals served a crucial role. In a world where looking up a reference can take between days and weeks, finding potentially interesting references is much less valuable than finding potentially interesting articles. Yes, you would go to the trouble of hunting down a particular article if it seemed directly relevant for your own work, but you certainly wouldn’t do so just to generally keep up with a broader field, much less all of science. Therefore, reading a journal such as Science or Nature, or even a more specialized but still fairly selective journal such as Genetics, was the only way to keep up with scientific progress. You went to the library, you took the physical copy of the journal, you browsed through it, you read the interesting articles, you learned something useful, you went home/back to your office.\nBy contrast, these days, with nearly any article right at our fingertips, the process of publishing articles and of selecting articles can be decoupled. For example, I don’t consistently browse through the tables of contents of Nature or Science anymore, because I now have other means of discovering interesting articles. Any interesting article in my field I’ll come across sooner or later because Google Scholar recommends it to me, or somebody tells me about it in person, or it gets cited in a paper I read or review. For generally interesting articles, say the latest findings about global warming, I’ll likely see them mentioned on Twitter or Reddit. The advantage of all these methods of finding articles over browsing through tables of contents is that I’m not tied to the venue in which the article was published. I’m just as likely to come across an interesting article published in Nature as one in PLOS ONE. And the moment I learn about an article, I can read it. But imagine a print version of Twitter, in the time before the internet. If I had received per mail, once a week, a list of potentially interesting things published in the most random venues, I would never have followed up with reading any of them. The barrier to doing so would simply have been too high.\nSome people take this reasoning to the extreme and argue that since now everything is easily available online and search engines are powerful, we don’t need selective journals anymore at all. The best science will rise to the top, it will be cited, tweeted, mentioned on reddit, bloggers will write posts about it, and thus we might as well publish everything in PLOS ONE. I am not entirely convinced by this argument, for the following reason: It’s all well and good if other people cite and tweet your work, but what if they don’t? If you think you have done some really outstanding work, work that deserves more attention than your regular bread-and-butter efforts do, in a world where all science is published in PLOS ONE, what options to you have? In a world that has glamour journals, it’s of course obvious what you can do: You write a nice 3-6 page summary of your work, highlighting the most important findings and the broad relevance, you send it to one or more glamour journals, and you hope for the best. If you get through, you’ll have a much higher chance of getting your article cited, tweeted, etc., because people pay attention to the glamour journals, and they like to read short, clearly written articles that highlight key findings and broader relevance. But if there are no glamour journals, then you have no good option of indicating that in your own opionion, this article is more valuable than that article.\nSo let me summarize the facts: (i) In the world of the internet, it doesn’t matter where something is physically published, as long as it is easily accessible through a URL. (ii) Glamour journals have lost the original purpose of making important science easily and broadly accessible. (iii) Publication venues that highlight interesting work by commenting and/or linking to it (such as Twitter, Reddit, Nature News and Views, Google Scholar, etc.) are highly valuable. (iv) Short, clearly written articles highlighting key insights and broader relevance are appreciated and highly valuable. (v) Authors have an interest in pointing out what they think are their most important works.\nThese facts lead me to the following proposal: Let’s take all original science out of the glamour journals. Instead, allow authors to submit short summaries (maybe 2-3 pages) of work they have already published elsewhere, e.g. in PLOS ONE. These summaries would be reviewed editorially, and also by one or two expert scientists who’d be asked to judge whether the original article appears to be scientifically sound and noteworthy. Editors might reject a summary because it isn’t deemed sufficiently interesting or novel, and there would still be fighting and politicing about getting summaries into these glamour journals, but the system would relieve authors of several pressures: (i) Authors wouldn’t have to rewrite an article multiple times just to hope to get it published eventually in one of the selective journals. (ii) Authors could get their results out and cite them properly while still trying for that glamour slot. (iii) Since the original article of record would be in PLOS ONE or PeerJ or similar, it would become generally accepted to have even the most important work published in these journals. Nobody could look at a publication list and say “Oh, it’s just a bunch of PLOS ONE papers.” (iv) Hiring committees and granting agencies would still have the option to evaluate candidates by the number of summaries they have published in glamour journals, though I would hope they would do so to a lesser degree and pay more attention to the original articles.\n The first web browser, which started the development of the modern internet, was released in 1993. The concept of an online journal was unthinkable before the invention of the web browser.↩︎\n   ","date":1388793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388793600,"objectID":"cb9856a04f7c0922ad16f7c2c26dd47c","permalink":"/blog/2014/01/04/how-glamour-journals-rose-to-prominence-and-why-they-may-not-be-needed-anymore/","publishdate":"2014-01-04T00:00:00Z","relpermalink":"/blog/2014/01/04/how-glamour-journals-rose-to-prominence-and-why-they-may-not-be-needed-anymore/","section":"blog","summary":"Academic publishing hasn't yet fully adapted to the internet age.","tags":["Academic publishing","Glamour journals","Peer review"],"title":"How glamour journals rose to prominence, and why they may not be needed anymore","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Science"],"content":"  Update: It turns out the article in the Chronicle is not recent, I misread the date on the page. (The Chronicle has two dates on each page, today’s date and the article publication date.) I stand by everything else I say, though.\nA recent article in the Chronicle of Higher Education argues that “we must stop the avalanche of low-quality research.” The authors decry the rapid growth of the scientific literature, which (as they argue) puts increasing strain on readers, reviewers, and editors without producing much benefit. They argue that this growth is driven by an increasing pressure on scientists to publish more, and the result is increasing amounts of low-quality publications. To address the pressure on scientists, they propose three fixes, of which one is Ok and two are positively inane. Maybe what we really have to stop is the avalanche of low-quality, non-reviewed opinion pieces published on web pages?\nReading through the article, I found it difficult not to wonder whether the authors had ever heard of the internet or of modern information-processing technology (e.g., Google). Now, to be fair, none of the authors are in the natural sciences. The authors work in English, mechanical engineering, medicine, management, and geography. I don’t really know these areas. My own work is in biology, and I’m also somewhat familiar with the publishing cultures in physics and in computer science. So, everything they say may make sense in their fields, but it doesn’t in mine. I’m not convinced we have a major crisis, and I certainly don’t think their proposed fixes are any good. Let’s take a look at their proposed solutions first.\nLimit number of papers submitted for job applications or promotions The first fix, to limit the number of papers that applicants are allowed to submit for job applications or promotions, is actually somewhat reasonable. Applicants should be judged on the quality of their work, not on the mere quantity of output. However, I am strongly opposed to saying applicants are not even allowed to mention anything beyond their key 3-5 papers. Why should productivity be punished? What if they wrote 10 important papers? Should Ed Witten be limited to list only 5 papers? (To date, he has written over 30 papers with over 1000 citations each!) While there are negative outliers in academia, people who produce huge amounts of mindless drivel, I definitely see a correlation between quantity and quality. The most interesting and influential papers are generally written by the most productive researchers. I have previously given arguments for why we would expect such a correlation to exist.\nMost job search and promotion processes that I am aware of have already found a solution to this problem, by asking applicants to submit both (i) a full list of all publications and (ii) the 3-5 most important papers, possibly with a statement explaining their impact. This is good practice that strikes a balance between quality and quantity, it allows applicants to showcase both how good they are and how consistently productive they are, and most importantly, it is already common practice. So point 1 is a non-issue, from where I stand.\n Evaluate researchers by impact factors Evaluating researchers by impact factor is such an absurd and untimely suggestion, I can’t help but wonder whether the authors have been living under a rock for the last 10 years. It’s particularly ironic that the Chronicle of Higher Education would publish this statement a mere 11 days after nobel-prize winner Randy Schekman publicly proclaimed that luxury (i.e., high impact-factor) journals such as Nature, Cell, and Science “are damaging science.” Did the authors really not see this article, nor the widespread outrage it caused over containing a cheap plug for a different luxury journal? If there is one problem we have in science right now, at least in the biomedical field, it’s an over-reliance on impact factors and publications in high-profile journals. The outcry over Schekman’s article shows how sensitive of an issue this is, and how many scientists are concerned about the growing pressure to publish in only the highest-impact journals. Schekman himself addresses this in his response to the criticism he received. Scientists should be judged on the quality of their work, not on whether or not they published in Nature.\n Limit the length of papers published I don’t see how imposing page limits connects at all to the issue at hand. Surely, if we want fewer but higher-quality publications, the papers should be longer not shorter. Also, I strongly oppose to the split model with a brief (4-6 page) main article (i.e., advertisement) accompanied by longer supporting materials. Invariably, the supporting materials are not written as carefully as the main article, and the quality of the paper as a whole suffers. Notably, PNAS just went the other direction, and now allows papers of up to 10 pages in length in their online-only PNAS Plus edition. This was a very welcome change, I think. The 6-page limit of PNAS was often too limiting, whereas most articles fit comfortably within 10 pages.\n Is there too much pressure to publish? While there is pressure to publish, frankly I don’t see that there is excessive pressure to publish. From what I see, for example in conversations with colleagues, the common expectation is reasonable productivity both in terms of quantity and in terms of quality. In terms of quantity, reasonable is usually a number between 1 and 10 papers per year. Publish less, and people start wondering whether you’re working consistently, and in particular whether you’ll keep working in the future. Publish much more than 10 papers per year, and people start looking at you suspiciously. I sat on a grant-review panel once where one applicant claimed his previous 3-year NSF grant had led to ~100 publications. People were very suspicious of this claim and the grant did not get good reviews, even though the science seemed to be reasonable. (I’m not saying the proposal would have been funded if the applicant had had fewer publications, but the high number certainly didn’t help; if it had any effect it was a negative one.) In most areas of Biology, I think 2-3 papers a year will be considered perfectly reasonable for anybody but a senior PI running a large lab. (This includes all papers with your name on, not just first-author papers.)\nIn terms of quality, I stick to my earlier recommendation: publish at least one paper a year that has some real substance. Where exactly that paper is published is secondary, I believe. Publishing the occasional high-profile article in a luxury journal can’t hurt, but I hope that we as scientists can collectively learn to pay a little less attention to where something is published and pay more attention to the content. We shouldn’t hire somebody without having carefully read at least one or two of their papers, and I think the more diligent search committees operate like that already.\nWith regards to excessive workload for editors and reviewers, I think there are several things that could be done relatively easily:\nInstitute a system of reviewing credits, where you receive one credit for each article you review and you have to spend a number of credits (e.g. 6) to submit an article. This would ensure that everybody who publishes carries their fair share on the reviewing side.\n Have more graduate students and postdocs review papers. Not every paper needs to be reviewed by three members of the NAS. In fact, I often find that graduate students write better reviews than senior scientists do, because the graduate students take the job much more seriously and put way more effort into it than an established scientist normally would.\n Have less stringent reviewing criteria, don’t judge impact. Much of the excessive reviewing load actually comes from the pressure to publish in highly selective journals. Thus, many articles make the mandatory trek from Science to Nature to PNAS to PLOS Genetics to PLOS ONE, possibly undergoing four or more separate rounds of review. It’s not uncommon for me to review the same article several times for different journals. And in the end, everything gets published anyway, somewhere. If it was the reviewers’ job to only look for major scientific flaws, then most articles could be published after 1-2 rounds of review, cutting the total review burden way down.\n Improve tools for post-publication evaluation of articles. At present, all we have is citations and word-of-mouth. (“Have you seen the latest paper by X in PNAS? It’s really not very good.”) I’m sure we can do better than that, and over time we’ll find ways to put modern computing power and crowd-sourcing ideas to good use. NCBI’s PubMed Commons is a first step in this direction. I’m sure over the next 10-20 years we’ll see many more innovative ideas to evaluate the quality of scientific work post publication.\n   ","date":1387584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387584000,"objectID":"ff4323c0bcabb908be384f5e6448f10c","permalink":"/blog/2013/12/21/is-there-an-avalanche-of-low-quality-research-and-if-so-must-we-stop-it/","publishdate":"2013-12-21T00:00:00Z","relpermalink":"/blog/2013/12/21/is-there-an-avalanche-of-low-quality-research-and-if-so-must-we-stop-it/","section":"blog","summary":"Putting artificial limits on output is never a good idea.","tags":["Academic publishing","Glamour journals","Impact factor","Peer review"],"title":"Is there an avalanche of low-quality research, and if so, must we stop it?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Science"],"content":"  I see lot of discussion these days about the value of peer review. Are journals too selective? Are acceptance decisions arbitrary? Does peer review actually catch scientific mistakes or fraudulent practices? Wouldn’t it be better to just put everything out there, say on preprint servers, and separate the wheat from the chaff in post-publication review? I’m not quite ready yet to give up on pre-publication peer review. I think it serves a useful purpose, one I wouldn’t want to do away with. In the following, I discuss four distinct services that peer review provides, and assess the value I personally assign to each of them.\nPeer review screens out nonsense and pseudoscience It’s important that somebody screen all potential scientific publications for actual scientific content. I don’t mind publishing null results, replication studies, or studies that present only a very minor advance. All of these works contain real science, and they may find some use at some point in the future. However, we must never mix science with pseudoscience. Someone has to assure that whatever gets published in a scientific journal is not complete nonsense. Even the preprint archive arxiv.org has some sort of a screening and filtering system in place to hold back the crackpots. In most cases, nonsensical papers would be caught by the editor and not even sent out to review. Nevertheless, we can consider filtering out nonsense to be an essential service of the pre-publication review process.\n Peer review catches major mistakes and/or fraud Many people seem to think that it is the reviewers’ job to catch major mistakes and/or fraud. And when they fail to do so, that is taken as evidence that peer review doesn’t work. I don’t think we can put such a high burden on the reviewers. Ultimately, the burden of producing correct and genuine results lies with the author. Peer review operates under the assumption that fundamentally the authors are honest and reasonably capable scientists. If peer review does happen to catch a major issue with a paper, that’s great, but generally I think that post-publication review is the much better venue to address major flaws or scientific misconduct.\n Peer review assess novelty, potential impact, and fit with the journal scope Whether reviewers (or editors) should consider novelty and impact, and whether journals should be selective at all, is probably the most contentious issue in peer review. Traditionally, this has always been part of peer review. However, there are now several journals that explicitly state review should only assess scientific soundness (e.g. PLOS ONE or PeerJ). I think there are valid arguments for both sides. On the one hand, it is imperative that we have publishing venues that will publish any scientifically sound study. Nobody benefits if a valid study is suppressed just because some reviewers didn’t find it interesting. If there’s no obvious scientific flaw, put it out there and let the readers (and Google) sort it out.\nOn the other hand, I think that more selective journals can provide value as well. In my mind, where science has gone off-track is that the most selective journals (which are also considered to be the most prestigious ones, e.g. Nature, Science, Cell, PLOS Biology, PNAS) employ arbitrary selection criteria based primarily on the subjective goal of publishing “the best science.” As a consequence, whether I can publish in such journals depends much more on my marketing skills than on my scientific skills, and also on whether I’m working on a sexy study system.\nBy contrast, the next lower tier of selective journals usually employ more objective selection criteria, and those arguably provide a useful value. For example, I’m an Associate Editor for PLOS Computational Biology, a fairly selective journal. The main requirement for publication in PLOS Computational Biology is that you have produced high quality computational work that yields a novel biological insight. In my mind, it is fairly straightforward to determine whether a paper satisfies that requirement or not. I also think that any capable computational biologist can jump over that bar. As a consequence, I feel that we’re providing useful selectivity without generating excessive artificial scarcity or making highly arbitrary decisions. If I see that somebody has on their CV a couple of PLOS Computational Biology papers, I can reasonably assume that they are doing consistent, high-quality computational work leading to novel insights into biological systems.\n Peer review helps authors improve their articles In my mind, this last point is the most important point, and the reason why I’m not willing to give up pre-publication review in its entirety. In my experience as author, reviewer, and editor, the most common outcome of the review process other than “reject due to insufficient novelty” is “major revision.” The reviewers agree that the study has merit in principle, but they see a number of possible revisions that would improve the article. I have seen it countless times, both as author and as reviewer or editor, that a study was vastly improved after the first set of reviews. Sometimes reviewers catch an issue the authors hadn’t noticed, sometimes they have a really cool idea that brings the study to the next level, and sometimes they simply tell you that you have to work on your writing if you want to get your point across. Either way, this input is invaluable, and it improves the scientific literature tremendously. If we went to a system that operated entirely on post-publication review, we would probably still see the same kind of comments by reviewers, but there would be very little incentive for the authors to go and revise their papers accordingly.\nOne downside to this aspect of peer review is that sometimes reviewers just keep insisting on changes that the authors don’t deem necessary or appropriate. This is another form of peer review gone wrong. The reviewers should make helpful suggestions, but they should not tell the authors how to write their paper. One solution to this issue is to make peer reviews public and leave with the authors the ultimate decision of whether or not they want to publish, as Biology Direct does. Another possibility is to allow authors to opt-out of re-review, as BMC Biology does.\n ","date":1387584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387584000,"objectID":"81aec9bbe8856aa08a65acaafc88e1a4","permalink":"/blog/2013/12/21/the-value-of-pre-publication-peer-review/","publishdate":"2013-12-21T00:00:00Z","relpermalink":"/blog/2013/12/21/the-value-of-pre-publication-peer-review/","section":"blog","summary":"I'm not ready to give up pre-publication review.","tags":["Academic publishing","Glamour journals","Peer review"],"title":"The value of pre-publication peer review","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  I cannot remember ever having seen a graduate student present a PhD thesis proposal and be criticized for lack of ambition. It never happens. Even the weakest students—especially the weakest students—present proposals that are overly ambitious and that won’t ever get done, and certainly not in the 3–4 years remaining until graduation. In fact, in my experience it is exceedingly rare that a student presents a reasonable proposal, one that is actually doable during the remainder of the time in graduate school. Usually, those only happen when students “forget” to have their qualifying exams and end up presenting their “proposal” six months before the intended graduation date. In those cases, the students know that they won’t accomplish much new between proposal day and defense day, and basically present a proposal that consists entirely of completed work.\nIn Biology, most professors expect graduate students to complete about three projects, corresponding to the magical three specific aims in a typical grant proposal.1 In my mind, a graduate student who is defending her proposal, 2–3 years into her program, should have one project completed, one well under way, and one in the early planning stages. Students doing complicated experimental work might be less advanced at that time, but at a minimum they should have one project well under way by the time they defend their thesis proposal. This gives a pretty good rule of thumb for the amount of work the proposal should encompass: Aim 1 should be the work that is in the bag, and Aims 2 and 3 together should not require more than twice the amount of work already accomplished. Instead, what I commonly see is that the completed work is only a small component of Aim 1, which alone is going to take another two years to completion. Aim 2 will need four years on top of that, and Aim 3 another ten. Basically, many graduate students propose to carry out a lifetime of research during their graduate work.\nI don’t quite know why PhD proposals tend to be overly ambitious. Maybe it’s youthful optimism or naiveté. I suspect, though, that there is a component of fear, the eternal graduate student fear of not being sufficiently productive, of not doing enough. Ironically, this fear often causes students to overlook the successes that are within reach and instead try to reach for the stars. In general, doing a successful thesis is a fine balancing act between being overly ambitious and playing it too safe, a topic for another post. However, there’s a difference between an actual PhD thesis and a thesis proposal: The thesis should contain some exciting, risky work, but for the proposal most professors want to see a plan that is doable, not one that might be doable if the stars align correctly. As a smart graduate student, you have two alternative plans, one safe and one daring, you work on both of them at the same time, and you present the safe one during the committee meeting.\nA second, related issue I frequently notice is that students display poor judgment in how much work they can realistically accomplish in the remaining time. Estimates are consistently too optimistic. If you are in year three, and you have completed 50% of your first project, it is unlikely that you’ll complete this and two entirely different projects in the remaining 2–3 years of your PhD. Further, unless you’re a paper-writing machine, it’s unlikely that you can write a paper in less than three months. (And if you are a paper-writing machine, you should have plenty of papers by the time you defend your proposal anyway.) So, if you still have three manuscripts to complete, plus a thesis, the writing time alone is going to be about a year. If you’re already halfway into year three, you’ll have about another 18 months of actual research work you can do, because the other 12 you’ll spend writing. (Of course I’d recommend that you don’t wait all the way till the end before you start writing, but the math comes out the same.) My personal rule of thumb is things take about three times as long as students estimate things will take. So if a student says a particular project needs another three months in the lab plus a month to be written up, I expect that project to be done around the same time next year.\nIn conclusion, when you prepare your thesis proposal, realistically assess how much work you can complete during the remainder of your graduate years. Don’t assume that your productivity will double or triple over the next two years, because it won’t. Budget at least three months for every paper you have to write, and triple the time you think it takes to complete the remaining lab work. If you have papers in review, consider that responding to reviewer comments and revising a paper frequently takes another two to three months, during which nothing else gets done. If you end up with a plan that will require another five years of work or more, then you’ll have to change your aims. See whether your current Aim 1 can be broken down into reasonable sub-aims which can be considered the separate chapters of your thesis. It’s quite common for me to conclude a PhD proposal defense by telling the student it’d be best to scrap Aims 2 and 3 altogether and instead expand Aim 1 into the entire thesis. If you come to that realization before the committee meeting, I don’t have to tell you so during, and everybody is happier.\n While proposals with either two or four aims can also be viable, two can appear as unimaginative (he really couldn’t think of anything else?) and four is getting dangerously close to being overly ambitious, so three it is.↩︎\n   ","date":1386374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386374400,"objectID":"d43a989b9515d31836ad80b5693c0c55","permalink":"/blog/2013/12/07/excess-ambitionthe-eternal-flaw-of-all-phd-thesis-proposals/","publishdate":"2013-12-07T00:00:00Z","relpermalink":"/blog/2013/12/07/excess-ambitionthe-eternal-flaw-of-all-phd-thesis-proposals/","section":"blog","summary":"No thesis proposal has ever been critizied for lack of ambition.","tags":["Ambition","Fear","Graduate school","PhD committee","Specific Aims","Thesis proposal"],"title":"Excess ambition—the eternal flaw of all PhD thesis proposals","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  Simon Goring wrote an interesting post a few days ago arguing that no one reads your blog. In his post, he discussed reasons for why you might want to blog anyway. This post prompted me to tackle a topic I’ve been thinking about for a while: Why should you do science? Why should you publish? No one is going to read your paper either.\nIn particular, while I’m sure everybody agrees on the value of publishing groundbreaking, highly influential papers, most papers are neither groundbreaking nor highly influential. I have written over 100 scientific articles, and by my own modest guess at least 80 of those are completely irrelevant in the grand scheme of things, and probably more. My own measure for acceptable performance in a given year is that I publish about one paper to which I can point and say “probably more than 10 people will read this and actually care.” Over a 15-year career in science, that comes out to about 15-20 such papers, so I’m more or less on track.1 Nevertheless, the vast majority of the papers I write, on average about 6 per year, are not that special and aren’t really read by anybody. So is there any reason to write them at all? Why not just write one big hit a year, or whenever it’s ready, and leave all the chaff unpublished?\nQuality tends to correlate with quantity. In your field, how many people do you know who publish one Nature or Science paper a year and not much else? I can think of maybe one or two people who have made that strategy work for them, but I’d argue that they are successful despite their publishing approach not because of it. For most people, productivity and impact tend to be correlated. The most prolific scientists also write the most widely-read papers and vice versa. It’s just like in the music business, you need to write a lot of songs to write a hit, and the people that write many hits also tend to write many many songs that aren’t hits. And, more importantly, it’s difficult to predict which song will be a hit and which will flop.\nLet me illustrate this idea with an example from my own career. In 2001 I wrote seven papers. Five of the seven have been quite successful, and have been cited over 50 times each. One of them, a Nature paper,2 is still one of my most cited papers of all times, with about 400 citations according to Google Scholar. When we wrote that paper, I was pretty sure we had a big story, so the success of the paper was somewhat expected.3 The second-most cited paper of that year, however, which at present has about 100 citations and is my 13th most cited paper of all time, was a total surprise. Notably, this paper was also one of my fastest ever from original idea to submission. I had a cute idea one afternoon, did a few calculations for a day or two, wrote a simulation in a few more days, and after a little over a week the entire paper was done and out the door. When I submitted this paper, I had no idea whether it was even publishable. Yet it got printed, and people really liked it. For the other papers I wrote in 2001, I also was skeptical whether anybody would ever care about them, and in the end five of the seven did really well. It would have been easy for me to be more selective in 2001 and write only 2 or 3 papers, but if I had done that I’d have missed out on writing a couple of well-received papers.\nThis leads me to lesson 1:\n You don’t know which of your papers other people will like. The more you publish, the higher the chance that something you write is useful to somebody.\n Frequent publishing builds an audience. My next point applies to scientific publishing just as it does to blogging: You need to build an audience. If you regularly publish on a topic, people start taking notice. They will make it a habit to keep an eye on your work, even if they don’t spend a lot of time actually reading your papers. Then, when you finally publish something really good, you have an audience ready and waiting. The exact same paper, published by somebody nobody has never heard of, might not get the same reception. In fact (and I’m not saying this is right, just stating how things are), it might not even make it through review the same way.\nThus here is lesson 2:\n You need to keep publishing regularly so people are aware of you and take you more seriously.\n There’s a limit to this, of course. If all you ever publish is useless drivel then you’ll eventually gain a reputation for publishing useless drivel. Stick to my guideline from the beginning of this post, publish at least one paper a year that is actually good.\nFrequent publishing develops skills. My next point is also just like in blogging: You need to write a lot to get good at writing. With every paper you write, you get a little better. Therefore, even the papers that don’t really have any content of consequence, where you know only three people will ever read them,4 are worth writing just for the exercise. Can you imagine you make a major discovery, a real breakthrough, and then you don’t have the skill to turn your results into an excellent paper? That’d be a disaster.\nThus, we arrive at lesson 3:\n You need to publish as much as possible so you develop the writing and responding-to-reviewers skills that you will need to write your major hits.\n Lesson 3 applies particularly to students and young postdocs. They need all the practice they can get and hence should publish a lot, even if some of their papers turn out thin and inconsequential.\nPublishing clears the mind. My arguments so far can be summarized by saying that more publication quantity equals more publication quality. Some might raise the following objection: By writing fewer papers, they will say, they can put more effort into each one and hence raise the overall quality of their output. In other words, quantity can be detrimental to quality. I am not convinced by this argument. As I said earlier, one of my top-cited papers of all time took me all of two weeks to complete. At the same time, I could point you to papers that I put a huge amount of effort into and they never went anywhere. Impact doesn’t necessarily correlate with effort. More importantly, though, I believe that if one tries too hard to control quality both quality and quantity suffer. We need to publish papers so we are mentally ready to move on and write more, hopefully better, papers.\nIn fact, ideas for papers can hurt your productivity if you get stuck on them. The most insidious ideas are the marginally good ones, the ones that aren’t so bad that they are easily dismissed out of hand but also aren’t good enough that you want to rush to publication. Those kinds of ideas can drag down your productivity for years, because they divert your attention and energy while not going anywhere. The best thing you can do with those ideas is to just publish them and move on. It’s so much easier to dismiss an idea as bad once the paper is out. I have plenty of papers on my cv where I’m the first to say they are pretty pointless.5 But I don’t regret publishing them. If I hadn’t published these papers, maybe I’d still be thinking about the central ideas expressed in them.\nThus, the final lesson:\n The best way to get a weak idea out of your head is to publish a paper on it. Don’t dwell on weak ideas, publish them and move on.\n There you have it, my reasons to keep publishing even though nobody reads (most) of my papers anyway. Now I’d like to hear from you: What are your reasons to publish or not to publish?\n Until you realize that the argument I made was circular, because I arrived at ~80 irrelevant papers by assuming that I’m writing about 1 relevant paper a year, give or take.↩︎\n C. O. Wilke, J. L. Wang, C. Ofria, R. E. Lenski, and C. Adami (2001). Evolution of digital organisms at high mutation rate leads to survival of the flattest. Nature 412:331-333.↩︎\n To be honest, though, 400 citations and counting still blows me away. When we submitted the paper, I hoped that it would garner maybe 50 citations or so.↩︎\n Those three being the two reviewers and the editor of the journal.↩︎\n For example, everything I published in 1998 and 1999.↩︎\n   ","date":1383436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383436800,"objectID":"07b6053e5e6227db9b34c4c21240024d","permalink":"/blog/2013/11/03/no-one-reads-your-paper-either/","publishdate":"2013-11-03T00:00:00Z","relpermalink":"/blog/2013/11/03/no-one-reads-your-paper-either/","section":"blog","summary":"But you should publish nonetheless.","tags":["Academic career","Academic writing","Audience","Publication quality","Publication quantity"],"title":"No one reads your paper either","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Fitness"],"content":"  The majority of people on a diet will tell you that they’re dieting because they want to lose weight.1 If you ask them why they want to lose weight, you’ll hear things like “I don’t want to have a heart attack at 50” or “I have some extra flab” or “I want to get rid of my spare tire” or “I want a six pack.” So people want to be healthy, or they want to look good naked, or both. Importantly, though, none of these goals have much to do with weight per se. What people are actually concerned with is excess fat. And we generally know this, of course. We know that when we say somebody is overweight we really mean the person is overfat. Yet, in day-to-day practice, we don’t use the word “overfat,” we keep saying “overweight.” And as a result, we keep confusing weight and fat, and more importantly, we use the wrong metrics to keep track of our dieting success.\nAsk anybody on a diet how they’re keeping track of their progress, and the answer you’ll hear most frequently is going to be “I weigh myself regularly.” There we have a major problem. People want to lose fat, but they keep track of their progress using a metric that inherently cannot distinguish between desirable (i.e., lean) and undesirable (i.e., fat) mass. As a consequence, they’re setting themselves up for failure. They may indeed lose weight but this weight loss may not be accompanied by the desired improvements in physique and health.2\nThe flawed metric of weight leads to such terrible TV shows as “The biggest loser,” which promote awful dieting advice. If you make it your goal to lose as much weight as possible in as little time as possible, you’ll inevitably burn off a lot of muscle mass. And that’s terribly sad, in my mind. The one thing every obese person has going for them is that they have a substantial amount of muscle under their layer of fat, from all the extra weight they’re carrying around all the time. Strip away the fat and keep the muscle, and you’ll have a strong, healthy person. But burn the muscle alongside the fat, and you’ll end up with a skinny-fat person. This person would now have to embark on a process of regaining (lean) mass, which will be psychologically terrifying and will usually not happen.\nAt this point, I should probably demonstrate that there is indeed a substantive difference between losing fat and losing weight. Enter one of my favorite pictures on the internet. (Warning: mildly NSFW, woman in underwear.) It shows how the same person can look visibly slimmer and more toned after gaining a substantial amount of weight, if that weight comes in the form of lean mass not fat. The reason for this dramatic difference is that muscle is substantially more dense than fat. You need a lot of muscle to fill a decent volume of space, and that muscle is going to weigh.\nIf weight is a bad metric for fat-loss progress, how can you know whether you’re on track with your diet? Let’s first go over all the other commonly used methods that also don’t work:\nAssessing body-fat bia bio-electrical impedance analysis (BIA). Many scales these days have BIA built in as well. When you step on the scales, they show you not only how much you weigh but also what your body-fat percentage is. Only that this number can be quite inaccurate. BIA results depend on numerous factors, not the least of which is your hydration status which may change daily. You can find a more detailed discussion of this issue here. The one-sentence summary is that you shouldn’t track your fat-loss progress with a BIA device, and in particular not with regular scales that have BIA built in.\n Looking at your abs in the mirror. This doesn’t work because it’s easy to trick yourself into thinking you’re doing great when actually you’re not. Even more likely is the opposite, though: You may think nothing much is happening when actually you have changed a lot. Fundamentally, this method is not sufficiently quantitative. You can never really be sure whether things have actually changed and by how much.\n Pinching your belly fat. This method is also surprisingly unreliable, in particular when you’re getting lean. As you’re leaning out, your skin gets looser and you can pinch from a larger area, seemingly being able to pinch more at a time. This effect is particularly pronounced when you’re pinching from top and bottom. Try pinching your belly fat right underneath your navel, either from top and bottom or from left and right. Do you see the difference? Also, sometimes we can have a substantial layer of fat but can’t pinch it. For example, try to pinch the fat on top of your thigh. Can you do that? Chances are, if you can you’re pretty lean. For most people, the fat on the thighs doesn’t really separate from the muscles, and as they lean out it separates more easily.\n  One method that works reasonably well is dual-energy X-ray absorptiometry (DEXA), basically a low-dose X ray. It’s the same method that is used to measure bone density. While it’s a great way to keep track of your body composition over time, it’s also cumbersome, expensive, requires professional equipment, and exposes your body to unnecessary X rays. Not something you want to do once a week.3\nThe other method that works is super cheap, easy, and reliable: get a $5 tape measure and measure your waist circumference (just at the height of the belly button). That measurement should go down over time if you’re progressing successfully. How do you know you’re not losing lean mass at the same time? Your strength should stay the same or go up. If you’re increasingly lifting heavier weights while your waistline is slimming, you can be pretty certain that everything is on track. And if you happen to keep track of your weight at the same time, you may notice that your weight is going up even as your waist circumference is going down.\nSo in the future, don’t plan to lose weight, plan to lose fat. And lose that fat while keeping as much of your weight as you can, maybe even increase your weight by a few pounds!\n As incredulous as it may sound, there are indeed some people who are on a diet to gain weight. There are entire online communities dedicated to gaining weight.↩︎\n It’s important to realize that people can weigh little and nevertheless have poor metabolic health. See e.g. this article.↩︎\n It probably also isn’t sensitive enough to measure changes week by week. But doing a DEXA scan once a year might not be a bad idea.↩︎\n   ","date":1383091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383091200,"objectID":"eb1a7eccb3061a0ed94814000088f4d3","permalink":"/blog/2013/10/30/weight-doesnt-matter/","publishdate":"2013-10-30T00:00:00Z","relpermalink":"/blog/2013/10/30/weight-doesnt-matter/","section":"blog","summary":"Losing fat while gaining weight is totally a thing.","tags":["Obesity","Overweight","Overfat","Weight loss","Weight lifting"],"title":"Weight doesn’t matter","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  I have noticed lately that many scientists write grant proposals with little document structure. Their proposals may have separate sections for background, for specific aims, and so on, but each of these sections is basically a long wall of text. The problem with this approach is that most reviewers will not carefully read all this text, and as a consequence they will miss important elements of the proposal. All else equal, a poorly structured proposal will be much less competitive than a well-structured proposal with many sub-sections and titled paragraphs. Because grant-writing remains one of the most important skills to be acquired by junior scientists, I see a critical need to highlight the importance of fine-grained sectioning in grant proposals.\nI have two specific aims for this post:\nAim 1. Demonstrate effective sectioning by writing this blog post in the form of a grant proposal. Hypothesis: By giving a clear example, I will allow my readers to quickly recognize the value of extensive document structure. I will write the entire blog post as if it were a proposal, and I will use an informative title for each individual paragraph and subsection. I will use short paragraphs that get straight to the point.\nAim 2. Use this post to promote my blog as a whole. Hypothesis: By providing useful and interesting content, I will attract more readers to my blog, who in turn will benefit from my advice. I will shamelessly promote this post on twitter and elsewhere, to the maximum extent allowed by law.\nSignificance Grant-proposal writing is a crucial skill for the modern scientist. These days, being a scientist is as much about writing grants as it is about doing actual science. While we cannot be successful without doing good science and writing interesting papers, our success will be short-lived unless we can also successfully request funding.\nClear structure helps the reader. There is really only one type of reader for a grant proposal: a reviewer. And reviewers are notoriously pressed for time. Imagine having to evaluate 20 grant proposals in an afternoon. The last thing you want to see is a huge wall of text without structure and with no indication where the important pieces are located. You want short, clear paragraphs and sufficient structure, so that you can quickly jump to the relevant sections of the proposal and look up specific issues you want clarification on.\nClear structure helps the writer. As a writer, you’ll actually have a much easier time writing the proposal if you have a clear structure in mind. If you don’t know what the specific purpose of a particular paragraph is, you’re more likely to blather on and not make a clear point. On the flip side, once you’ve written the paragraph heading, all you need to do is write a few sentences that make the appropriate statement and you are done. In fact, when I write proposals (and when I wrote this post) I usually write out all the paragraph headings first and then fill in the blanks.\nAdvice is only useful to the extent that people see it. If my blog has few readers, then I’m not making much of a difference in this world, regardless of how good my advice actually is. Each well-promoted post on this blog increases the visibility of the blog as a whole, which will increase in turn the visibility of each individual post.\n Aim 1: Write this blog post in the form of a grant proposal Rationale. Most people tend to benefit more from concrete examples than from theoretical expositions on a topic. One could read a thousand words on effective sectioning and not have any idea of how to apply these ideas in practice. Or, one could see a simple example and immediately recognize how to apply its principles in one’s own writing. For this reason, in this post I emphasize demonstration over exposition.\nApproach. I will write the entire blog post in the form of a grant proposal. I will have specific aims, which have hypotheses, approach, expected results, and so on. Each individual paragraph in this post will have a paragraph heading that states what the paragraph is about.\nExpected results. I hope that at least some scientist somewhere on this planet will write a better grant proposal after reading this post. I particularly hope that this post will be useful for junior scientists who may not yet have seen many successful grant proposals.\nPotential problems and solutions. First, it is possible that there are aspects to this post that are unclear or confusing. As a result, some readers may get an incorrect impression of what I’m saying. For example, someone could think that they absolutely have to provide a heading for every single paragraph, when sometimes it’s perfectly fine to have two or even three short paragraphs under one heading. To the extent that any readers express such misconceptions in the comments section, I will respond to them.\nSecond, if nobody sees my post, then all my efforts are for nothing. I will address visibility in Aim 2.\n Aim 2: Use this post to promote my blog as a whole. Rationale. Even the most well-reasoned and helpful blog posts are useless unless they are actually read. The visibility of individual blog posts is directly proportional to the overall reach of a blog. Therefore, I have to promote both this post in particular and the blog as a whole.\nApproach. Upon posting, I will tweet about this post. I will also tell colleagues and students about it. If somebody tweets about this post I will retweet their tweet, for added social proof.\nExpected results. I expect to see a spike in web traffic when my tweet posts. I further expect that at least one or two of my followers will favorite my post, and that somebody will retweet it. Finally, I hope to pick up at least one new follower on twitter as a consequence of writing this post.\nPotential problems and solutions. If timing of my original tweet is poor few of my followers may notice my blog post. If I notice poor incoming traffic, I can consider tweeting about this post a second time. Further, if none of my followers tweet about my post then I have nothing to retweet. In this case, I may have to ask a student or friend to write a tweet for me. If all else fails, I can promote my post on facebook.\n ","date":1382918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382918400,"objectID":"9a4fb9b4eea08ab5625e6bf19126894c","permalink":"/blog/2013/10/28/use-fine-grained-sectioning-in-your-grant-proposals/","publishdate":"2013-10-28T00:00:00Z","relpermalink":"/blog/2013/10/28/use-fine-grained-sectioning-in-your-grant-proposals/","section":"blog","summary":"Clear structure helps both the reader and the writer.","tags":["Academic writing","Critical need","Grants","Specific Aims","Twitter"],"title":"Use fine-grained sectioning in your grant proposals","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Science"],"content":"  PLOS Computational Biology just published a new addition to their popular “ten simple rules” series:\n Sandve GK, Nekrutenko A, Taylor J, Hovig E (2013) Ten Simple Rules for Reproducible Computational Research. PLoS Comput Biol 9(10): e1003285. doi:10.1371/journal.pcbi.1003285\n This article is relevant to anybody who wants to do computational research. I’ll make it required reading in my lab. For every single one of these rules, I can think of projects I’ve been involved with1 that ran into trouble or failed because they violated that rule.\nWhile all of the rules are important, I’m particularly partial to these four: avoid manual data manipulation, record all intermediate results, always store raw data behind plots, and provide public access to scripts and results. They will prevent a lot of headaches for both you and the people coming after you who’d like to build on your results.\n All of these projects were run by friends of friends, of course. None of this would ever happen in my lab. 😉↩︎\n   ","date":1382745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382745600,"objectID":"9143550ce4e705b138115c29025e6488","permalink":"/blog/2013/10/26/ten-simple-rules-for-reproducible-computational-research/","publishdate":"2013-10-26T00:00:00Z","relpermalink":"/blog/2013/10/26/ten-simple-rules-for-reproducible-computational-research/","section":"blog","summary":"Avoid manual data manipulation, and record all intermediate results.","tags":["Computing","Data visualization","Data wrangling","Reproducible research"],"title":"Ten simple rules for reproducible computational research","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  Today, I gave a talk in our weekly departmental seminar about giving effective presentations. Here are the slides I used. Not all of them may make sense without the accompanying oral presentation. (There’s one slide in particular where I purposefully tell a different story than the slide does.) However, most of the material should make sense as is.\nIf anything is unclear, please ask questions in the comments!\n Giving effective presentations – Claus Wilke, Oct. 2013\nUpdate July 3, 2018: An updated and expanded version of this presentation is available here.\n","date":1382227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382227200,"objectID":"56257812ef80a4d0590a2316422d9438","permalink":"/blog/2013/10/20/giving-effective-presentations/","publishdate":"2013-10-20T00:00:00Z","relpermalink":"/blog/2013/10/20/giving-effective-presentations/","section":"blog","summary":"There are reasons why some presentations put you to sleep and others don't.","tags":["Assertion-evidence format","Presentations","Public speaking","Slide design"],"title":"Giving effective presentations","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  Amidst the flurry of posts on the recent sexual-harassment-in-science-blogging scandal,1 I found this post on slate.com which made some interesting statements about the value (or lack thereof) of mentors:\n And the mentor-mentee relationship is one of the most fraught of adulthood. We glibly advise people starting out in business to find a mentor, to identify a successful, established, generous person in your field and somehow get her to help you become her.\nThis is terrible advice. It perpetuates old-boy networks, wastes time that early career people could spend actually doing their work, and tells them they are only as good as their contacts and charm. Young people, don’t look for a mentor. Listen to and learn from people who have more experience, but don’t hitch your wagon to their star. Just do your job well.\n Okay then. I guess I can shut this site down and go home. I’ll just tell my students that from now on they’ll have to figure it out for themselves.2 I may give them a word of advice now and then, but other than that they’re on their own. I’m sure the most meritorious ones of them will find their way. After all, I did.3\nNo I won’t. I think there are at least three distinct ways in which a mentor can be valuable. Of those three, the last is probably the most important one. It also provides a relatively clear litmus test on whether a person is truly mentoring or instead potentially abusing his/her power for personal objectives. I agree with this post that the different mentorship functions could (and maybe even should) be filled by different people. And I’d argue that good mentors will encourage you to build a network of people that can all provide additional mentorship to you.\n1. The mentor as coach The first important role a mentor can play is that of a coach, just like in sports. Most people need a coach to perform at their highest level. A coach recognizes your strengths and weaknesses, she calls you out when you’re lazy, and she knows how far she can push you. You are still the one who has to put in all the work, but she makes sure that you do. She also makes sure you do the right kind of work, you don’t waste your time with stuff that isn’t needed and you don’t skimp on things that really need to be done. Even Michael Phelps, the greatest Olympian of all time, has a coach that prepares him for competitions. I don’t think anybody would ever say “Michael Phelps is just as good as his coach. If his coach hadn’t helped him, Phelps wouldn’t have won a single medal.” And yet, the second sentence is probably true. Phelps wouldn’t have succeeded without a good coach. At the highest level of human performance, nobody does.\n 2. The mentor as counselor Second, a mentor can be a counselor, a trusted source of advice when you need help in a professional situation or, depending on your relationship with your mentor, in a situation that tends more towards the personal side. For example, maybe you’re unsure about your professional future. Or you don’t know how to best interact with a difficult colleague. Or you’re wondering whether you should take your dream job or rather follow your partner to a different part of the country. In all those situations, a mentor who knows you well may be able to provide important insight. A person who knows the field but not you may also be helpful, but not necessarily to the same extent. The latter person may not be aware of specific issues you might encounter because of your personal strengths and weaknesses.\n 3. The mentor as sponsor Third, and most importantly, a mentor can and should be a sponsor, a person who speaks up on your behalf and who puts you in contact with the right people and in front of the right opportunities. For as long as hiring is done by humans and not by computers, who you know and what they say about you will be an important determinant of your professional success. You may not like this, you may not think it fair, none of this matters. Reality is what it is. The right contacts help.\nI said the third point would provide a litmus test to the mentor’s intentions. A mentor who truly wants to help her mentees will sponsor them incessantly. She will put them in contact with other important figures in the field, she will send them to conferences or professional meetings, she will give them opportunities to shine. Through all these actions, she reduces her mentee’s dependency on her, since all these other contacts can serve as further mentors as well.\nSo the litmus test is this: Does your mentor/adviser/manager/person in power connect you with other important people? Does she encourage you to showcase your work? Does she hand you opportunities and put you in charge of things? Does she nominate you for awards or other honors? Or, instead, does she keep you out of the spotlight? Does she discourage you from talking to other people? Does she create anxiety and paranoia? (“Be careful who you talk to about your research. They might steal your ideas.”) Does she keep you slaving away by promising big payoffs some day in the future? (“Once you get that Science paper, which you absolutely deserve, you’ll get a faculty job in no time. But now get back to the lab so you can finish that last experiment we need.”) Does she throw up unnecessary stumbling blocks? (“Yes, you have enough work for a regular paper, and I understand you would like to graduate soon, but a Science paper would be so much better for you. Just do another bit of work.”) Does she send mixed messages, such as helping you get papers but then not allowing you to present the work outside the lab?\nIf you can answer the first set of questions with “yes” then you’re working with somebody who wants you to succeed on your own terms and who also knows that nobody succeeds in a vacuum and without any help. If you can answer the second set of questions with “yes” then you have to doubt your mentor’s motives. The second sets of behaviors create dependency, they put you in a position where you need your mentor’s continued favor to keep doing what you’re doing. If you find yourself in that situation, you should start developing an exit strategy. Some of the advice in this post may be helpful.\n But I only succeeded because I charmed my mentor When people have been mentored well, they sometimes start worrying that they didn’t succeed out of their own ability, that they were just handed success because their mentor liked them (impostor syndrome). In this context, it’s important to realize that a mentor who is a sponsor constantly relies on the mentee to perform on his own: At a professional meeting, or in a one-on-one conversation with an important colleague, the mentee has to follow through. Just like Phelps and Phelps alone is swimming for gold, the mentee and the mentee alone is giving the talk, making conversation, doing the work. I don’t believe for a minute that one can take a mediocre student or employee and, through skillful mentoring, make them be successful beyond their own abilities. That’s just not how things work. If Michael Phelps’ coach took me under his wings because I charmed him with my beautiful smile and my bright green eyes I’d probably become a better swimmer but I’d certainly never win olympic gold. If you find yourself thinking “X helped me, therefore I didn’t do this on my own, therefore I don’t deserve this success” you’re likely experiencing a cognitive distortion, specifically all-or-nothing thinking/false dilemma. X helped you, and you did your part, and therefore you succeeded. You absolutely did deserve it. Chances are, if X hadn’t recognized your ability to succeed, she wouldn’t have helped you in the first place.\n  If you missed it, this post gives a good summary.↩︎\n The majority of my students are female and several are non-white, whereas I’m very much non-female and white. Most likely I’m not a good role model for them anyway.↩︎\n In graduate school I didn’t receive much in the form of mentoring from my adviser. I learned mostly from reviewers and journal editors. Reviewers commented on the papers I submitted and told me where my research fell short. Editors taught me important things about how science works, such as that one writes a response to reviewers upon resubmission of an article or that axis labels need to be larger than 2mm on the final printed page.↩︎\n   ","date":1382140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382140800,"objectID":"06c38658a82a0bf01ff616788df099ae","permalink":"/blog/2013/10/19/what-is-the-value-of-a-mentor/","publishdate":"2013-10-19T00:00:00Z","relpermalink":"/blog/2013/10/19/what-is-the-value-of-a-mentor/","section":"blog","summary":"Mentors fill important roles as as coaches, counselors, and sponsors.","tags":["Coach","Counselor","Impostor syndrome","Mentoring","Sponsor"],"title":"What is the value of a mentor?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Writing"],"content":"  It’s surprising how many grant applications do not clearly spell out a critical need. A critical need is the fundamental reason why a grant should exist. Without it, there’s really not much of a point to the grant. And yet, a critical need is frequently not stated. The common mistake that people make is that they confuse a gap in knowledge with a critical need. They clearly spell out what gap in knowledge they plan to address. And mind you, that’s an important component of a grant proposal. But if you stop there, if you never explain why there is a critical need to bridge the gap in knowledge, then your application is going to fall short. Unless the reviewers really like you for other reasons, they will probably not be impressed with your grant application.\nLet me explain the difference between a gap in knowledge and a critical need by way of an example. Assume you go out Saturday night and get drunk. In the morning, you wake up and have no recollection of how you made your way home. This is clearly a gap in knowledge. But there’s no critical need attached to that gap. I couldn’t care less whether you stumbled home, took a cab, or hitched a ride with a friend. Your grant on “The modes of transportation by which I found my way home last Saturday” is not going to be selected for funding by my agency. Now, instead, consider the following scenario. You go out Saturday night and get drunk. You wake up Sunday morning, not remembering how you got home. Upon looking into the mirror, you find that you’re battered and bruised. You’re also covered in blood. And your husband is nowhere to be found and doesn’t answer his cell phone. In this scenario, I think most people would think that there is a critical need to figure out what happened, to fill the gap in knowledge. Your grant on “Why I am innocent and didn’t kill my husband. Honestly!” would probably fare much better than the previous one.\nMy point is: there are all sorts of gaps in knowledge that aren’t attached to a critical need. Grants to fill those knowledge gaps will generally not fare that well in review. Therefore, think carefully about the critical need your research will fill. If you can’t think of one right now, think harder. I’m sure you can immediately name the gap of knowledge you’re working on. The critical need should be just as obvious to you. Note: If you’re a junior scientist working on questions that your adviser has funding for, then your work almost certainly satisfies some critical need. If you’re not sure what it is, ask your adviser.\nWhere in a grant application should you express the critical need? It has to come early, so your reviewers don’t waste a lot of time being bored or disinterested. Also, it needs to be in a position of stress, so your reviewers correctly perceive its importance. Consequently, there’s only a single place in a grant proposal where it fits: the last sentence of the first paragraph. The entire first paragraph should build up to the critical need, which justifies why you’re writing your grant in the first place.\nLet me illustrate this idea with the first paragraph of a grant I recently wrote:1\n Comparative sequence analysis is a cornerstone of modern biology, with applications ranging from determining the evolutionary history of species, to tracking pathogens, to identifying sites in a protein under positive or purifying selection. For protein-coding genes, comparative analysis has shown that protein structure strongly influences sequence variability: buried sites tend to be more conserved, and exposed sites—more variable. Deviations from this expectation can suggest functional importance. For example, a rapidly evolving buried site in a viral enzyme might be near the binding pocket and contribute to the evolution of drug resistance. A conserved exposed site might be involved in important protein–protein interactions. Yet conventional tools for comparative sequence analysis ignore protein structure and operate on sequence data alone. We, therefore, see a critical need to develop comparative methods that can jointly analyze sequence and structural data.\n This was the first paragraph of the Aims page, arguably the first piece of text in the grant that the reviewers read. As you can see, the entire paragraph builds up to the critical need, which is to develop comparative methods that can jointly analyze sequence and structural data. This is a critical need only because we believe—and have some preliminary data to demonstrate—that sequence analysis in a structural context will be more informative for important applications than sequence analysis in the absence of structural information can be. If there weren’t any important applications, or if the structural information made little difference to the outcome of the analysis, then the critical need would evaporate. There’d still be a gap in knowledge around sequence analysis in a structural context, but there wouldn’t be a critical need to bridge that gap.\n For full disclosure, I should say that this grant wasn’t funded. However, it was scored in the top third of applications (26% percentile). From my reading of the reviews, I would say that the reviewers believed our critical need. We just weren’t sufficiently competitive with the actual work we were proposing. Specifically, we didn’t have sufficient preliminary results to give our proposal that aura of magic.↩︎\n   ","date":1381968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381968000,"objectID":"a07755159c0b5a386b6738aa26dff1a2","permalink":"/blog/2013/10/17/the-critical-need-in-a-grant-application/","publishdate":"2013-10-17T00:00:00Z","relpermalink":"/blog/2013/10/17/the-critical-need-in-a-grant-application/","section":"blog","summary":"A grant application has to state clearly why the proposed work must be done.","tags":["Academic writing","Critical need","Grants","Specific Aims"],"title":"The critical need in a grant application","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  Throughout the last decade, funding rates at most US funding bodies have kept declining, and they have now reached awfully low levels. These days, single-digit success rates are pretty common. At the NSF, in some competitions I’ve seen success rates of 5% or less. As a result, most US scientists are struggling to figure out how to make the best of this abysmal situation. One could view the entire granting process as a lottery, and say that at a funding rate of 5% it takes an average of 20 submissions to get one project funded. And certainly some scientists operate this way and just write grant after grant after grant. However, I’m not convinced that that’s a viable strategy. While there is certainly an aspect of randomness to grant review, and sometimes a mediocre grant gets rated much higher than it should while an excellent grant gets triaged, I don’t think that this randomness matters much at the top end. If funding rates were around 30–40% then yes, one could probably write 3–4 grants and expect one to be funded just by chance. But I will argue that the top 5–10% of grants, the ones in the currently fundable range, are fundamentally different. If your grant isn’t like one of them, it probably has a near-zero chance of being funded. And if it is, it may well have a 50% or higher chance. The trick to being funded is hence to only write grants that can score in the top 10%. Easy. (Yes, I’m being sarcastic here.)\nThe good news is that I think it’s relatively straightforward to recognize grants that can score in the top 10%. The bad news is that I don’t know how to write them. Or rather, I don’t know how make all the necessary things come together such that I can reliably write grants that will score in the top 10%. All I can do is write a grant and then evaluate whether it’ll be good enough. Usually—but not always—the answer is “no.” In those cases, I probably might just as well not even submit. For the small number of grants where the answer has been “yes,” my success rate hasn’t been all that bad in recent years.1\nSo how do 10th-percentile-and-up grants differ from lower-scoring grants? I like to think of them as magical. They have all the required pieces coming together in just the right way. They address an important question, use a sexy study system, have just the right combination of theory and experiment, and have extensive preliminary results demonstrating feasibility. They also are well written and easy to understand even by people outside the field.\nAs you can see, some of these elements are not under your control. For example, if you’re a theoretician like me, you may not be able to add experiments to your proposal. You could gang up with an experimentalist, but then the two of you may not have any convincing joint preliminary data. More generally, you may have a great idea, but it may require three years of work to demonstrate feasibility and you won’t get it funded until you’ve put in those three years. Also, the study system you chose to work on, for whatever reason, may just not be as sexy as other systems. If you’re studying virus evolution using bacteriophages and somebody else is doing more or less the same work with some deadly human virus, chances are your proposal will be considered less competitive.\nOn the other hand, some things are under your control. You definitely can improve your writing and your grantmanship. If you’re not regularly scoring in at least the top 30%, then either the science you’re doing is absolutely no good (possible, but not probable) or you just don’t know how to write a competitive grant (more likely). In the latter case, there are resources that you can take advantage of. For example, the seminars and books offered by these people are pretty good.2 The NIH has a page with annotated examples of high-scoring grants. I will probably also write a few blog posts about grant writing in the future, so stay tuned.3\nNevertheless, as an individual investigator, in particular if you’re a junior one, it will always be difficult to jump over the bar separating the top 10% from the bottom 90%. Unless you’re literally the best in the world at doing whatever it is you are doing, your individual track record and preliminary results may not be good enough to compete at the highest level. In general, I think it’s easier to be successful as a team, competing for larger pots of money. If a funding body wants to establish a center or make a large collaborative grant on a certain topic, and you pull together the best people in the nation working on that topic, then your proposal will be hard to beat. This doesn’t mean that the single investigator grant is dead. It just means that you should evaluate carefully (and realistically!) where your work falls. And don’t waste your time on proposals that are not going to be fundable. If, however, you can see that you have all the right pieces in place, that you can write that magical proposal where everything comes together beautifully, then by all means go for it!\n Over the last 5 years, about 2–3 grants that I thought were good enough to be funded did actually get funded. That’s good enough to run a lab on. Over that same time period, I’ve probably written only 2–3 grants that I thought had a realistic chance of being funded. So that’s a near 100% success rate among the really good grants. I’ve of course also written many grants that didn’t get funded. But for all of those, by submission time I could have listed reasons why they likely wouldn’t make it into the top 10%, and they didn’t.↩︎\n I have no affiliation with them. I just took their training once and found it helpful.↩︎\n Yes, I just put myself on the same level with the leading grant coaches and the NIH. I’m still trying to figure out how this modesty things works.↩︎\n   ","date":1381968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381968000,"objectID":"05f3a4b5928b8cabd11f90ac114e7ed9","permalink":"/blog/2013/10/17/which-grants-get-funded-at-single-digit-funding-rates/","publishdate":"2013-10-17T00:00:00Z","relpermalink":"/blog/2013/10/17/which-grants-get-funded-at-single-digit-funding-rates/","section":"blog","summary":"Fundable grants have all the required pieces coming together in just the right way.","tags":["Funding rates","Grants","NSF","NIH"],"title":"Which grants get funded at single-digit funding rates?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous","Professional development"],"content":"  Blogs tend to be ephemeral. They are usually presented as a constant stream of novel contents, where the most recent posts are easily seen but the older posts can be difficult to discover. Even when blogs have excellent archive and search functions, I often wonder whether I have seen all the relevant posts on a topic. And the larger and more active a blog, the more of an issue it becomes. For example, one of my favorite blogs, Mark’s Daily Apple, updates daily and contains thousands of interesting posts. Its archive lists posts by a variety of different criteria, and its search function generally returns relevant hits. Nevertheless, I often have difficulty finding my way around that blog. I’m never really sure that I’ve read the most important articles on a given topic, in the right order.\nI would like my blog to have more permanence, and over time to develop into a useful resource that covers in depth a variety of important topics. As a first step towards this goal, I’m introducing a new section to the blog, Virtual Books. In this section, I am collecting blog posts into chapters of related topics, and the chapters into books. Think of the whole experiment as books that you can read as they are being written. As of today, there are two such virtual books in that section, Scientific Writing and Professional Development as a Scientist. For these two, I feel that I now have sufficient material online that organizing it more systematically makes sense. Over time, as I keep blogging on different topics, I’ll probably add a few more virtual books on different topics.\nWe’ll see how it goes. Let me know what you think. And also, let me know if you’d like me to post on a specific topic.\n","date":1381622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381622400,"objectID":"ebcc89ebe70d9fc9fe2b25be560a3aa9","permalink":"/blog/2013/10/13/virtual-books/","publishdate":"2013-10-13T00:00:00Z","relpermalink":"/blog/2013/10/13/virtual-books/","section":"blog","summary":"I've organized some of my blog posts into book-like collections.","tags":["Academic writing","Books"],"title":"Virtual Books","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  As far as I can tell, one of the major impediments to writing well is an inability to read. I’m not talking about basic illiteracy here. I’m talking about the following tendency that I have seen in many literate people: reading what one thinks was written rather than what was actually written. If you have this tendency, you may subconsciously fix grammatical errors, insert words that aren’t actually on the page, or even fill in larger logical gaps. You may also subconsciously delete words that shouldn’t be there in the first place. You probably do this when you read other people’s prose, and you’ll do it even more so when you read your own prose. As a result, you won’t notice when your writing has issues. And hence you won’t fix the issues. Your readers, however, may notice them, or they may simply not understand what you’re trying to say. If you are interested in writing clear and understandable prose, make sure that you’re actually reading what you wrote, not what you think you wrote.\nCan you read? So, how do you know whether you’re reading sufficiently well? To a first approximation, I’d assume that nobody can read. I know that’s not true, but in my experience it’s an approximation that matches reality reasonably well. However, to be more constructive, let me offer some specific self-assessments for you.\nFirst, in my previous blog post I purposefully introduced a few grammatical mistakes, as a pun. I pointed out the respective paragraph to a couple of students. Some got my pun immediately, but others didn’t notice that anything was wrong. Even when specifically searching for issues they couldn’t find them. Why don’t you check out that post right now and see if you notice anything? The specific sentence I’m talking about is in the second paragraph. What’s wrong with it is explained in the notes.1\nSecond, read the present paragraph carefully.There are several typographic mistakes here. Do you notice them?. It’s very important to pay close attention to even the most minute details. You may think it doesn’t matter much, but some of your readers will pay close attention, and they will notice almost anything. For them, too many little mistakes and issues will make your writing unpalatable. Again, you can find an explanation of what’s wrong with this paragraph in the notes.2\nThird, let’s consider situations where grammatical mistakes actually alter the meaning of a sentence. For example, consider this sentence:\n Painted in exquisite detail, you can sell this painting for a high price.\n What does this sentence tell you? Did you understand that you have a painting that is painted in exquisite detail, and that therefore you can sell it at a high price? If that’s what you read, I’ve got bad news for you: You need to work on your reading comprehension. That’s not what the sentence says at all. The sentence says that you, the reader, have been painted in exquisite detail, and that therefore you can sell this painting (about which we know nothing) for a high price.\nLet’s consider a different example:\n We found that lions do not generally like to eat ice cream which agrees with our prior expectations.\n What did this sentence tell you? Did you understand that we had a prior expectation that lions don’t eat ice cream, and that this expectation was confirmed in our experiment feeding ice cream to lions? If that’s what you got from this sentence then you have to pay closer attention to what is actually written. What the sentence actually says is that certain ice creams agree with our prior expectations. (Whatever they are. We are not told.) Those specific ice creams are not palatable to lions. Other ice creams, those that don’t agree with our prior expectations, may well be palatable to lions, but we are not told anything about them.\nYou might think that there is a punctuation mistake, that a comma is needed after “ice cream.” Unfortunately, even with that comma, the sentence still doesn’t make sense. It just doesn’t make sense in a different way.3\n How to improve There are a couple of simple techniques and exercises that you can do to improve your reading. First, get a good book or two about the intricacies of the English language.4 Go through the examples in these books, in particular the examples of how one should not write, and try to figure out what’s wrong with them and how you could fix them. With practice, you’ll get quite good at recognizing problematic writing.\nSecond, it’s really important that you slow down your reading speed. If you frequently read over grammatical mistakes or logical gaps then you’re reading too fast. It’s Ok to read fast when you’re reading somebody else’s words, but when you proof-read your own you need to be slow. A simple way to slow down your reading speed is to sit down and read your text aloud. It’s really difficult to do that and not notice missing pieces or logical gaps.\nThird, to assess overall flow and sentence connections, it’s important to read larger units of text. If you constantly go back and forth between reading and editing, you may be so focused on individual sentences that you’ll never notice larger issues that may exist in your prose. Make sure that when you proof-read you read larger chunks of text at once.\nFourth, I find it important to read a document multiple times exactly in the same format in which it will be seen by my readers. I can’t exactly pinpoint why it makes a difference but I know it does. For example, when I write scientific papers or grant proposals, I tend to do most of my proof-reading on printouts. On printouts, I always find issues that I didn’t see while editing. In these days of high-resolution screens and tablets, maybe you feel that printing documents shouldn’t be necessary anymore. And maybe you’re right. However, at a minimum, export the document from your word processor and read it on the screen just how your readers would. For example, create a pdf, open it on your tablet, and proof-read there. Make comments in longhand onto the pdf. (There are excellent apps for this purpose.) I proof-read all my blog posts on the web site, in the final format. I always find many minor issues that I didn’t see when I was composing the post.5\nStudents frequently hand me documents that look like they have never been proof-read. And when I ask the students whether they printed out the document and went over it slowly with a pen, the answer is usually “no.” Don’t be that student. Proof-read your documents carefully before giving them to somebody else. Don’t rely on others to find your writing mistakes, find them yourself.\n  The last sentence is missing three articles. It should have read:\n But make one non-native mistake, such as not using an article when an article is needed, and you’ll immediately sound like a person with poor English skills.\n I thought that native English speakers would immediately notice the missing articles and get the impression that this sentence was written by a foreigner. Well, some did and some didn’t.↩︎\n Issues in this paragraph:\n Missing space after “carefully.” (1st sentence)\n Extra period in “Do you notice them?.” (3rd sentence)\n Excessive space around “to” (before and after) in “It’s very important to pay” (4th sentence)\n  ↩︎ With the comma, the sentence says that lions don’t like to eat ice cream, and that ice cream typically doesn’t agree with our prior expectations. If you don’t see that, consider the following modification of the sentence:\n We found that lions do not generally like to eat ice cream, which is cold and full of sugar.\n ↩︎ A couple of good ones are: Lyn Dupre, BUGS in writing; Claire Kehrwald Cook, Line by line; Lynne Truss, Eats, shoots \u0026amp; leaves; Patricia T. O’Conner; Woe is I.↩︎\n I compose my posts in google docs and upload them once they’re done. Then I spend another hour or so copy-editing in the final format.↩︎\n   ","date":1381190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381190400,"objectID":"bd2eb1cacc35768278f46fbf4ac3cd1c","permalink":"/blog/2013/10/08/to-write-well-learn-how-to-read/","publishdate":"2013-10-08T00:00:00Z","relpermalink":"/blog/2013/10/08/to-write-well-learn-how-to-read/","section":"blog","summary":"Print out your document and read it aloud to your cat.","tags":["Copy editing","Grammar","Proof reading","Reading comprehension"],"title":"To write well, learn how to read","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  After having authored thousands of printed pages and having taught writing at the graduate level, all in English (my third language), I’ve come to this conclusion: We non-native speakers have a major advantage over native speakers when it comes to writing in the English language. We may not know how to write properly, but at least we know that we don’t know. Most native English speakers don’t know how to write properly either, but they don’t know that they don’t know. Because we’re acutely aware of our language deficiencies, we non-native speakers will generally put much more effort into learning proper English than native speakers will.\nHowever, I’ve often seen non-native speakers worry about grammatical subtleties that no (untrained) native speaker could discern while at the same time making mistakes that no native speaker would ever make. This can lead to the curious situation where a non-native speaker may actually have a pretty good command of the English grammar and yet his writing will be considered as “poor” and “full of errors.” I’ve thus concluded that it may not matter so much that we truly understand English grammar in all its subtleties.1 What matters most is that we don’t make the mistakes native English speakers wouldn’t make. We can use dangling participles, missing antecedents, and comma splices all day long, and most people won’t hold it against us. But make one non-native mistake, such as not using article when article is needed, and you’ll immediately sound like person with poor English skills.\nFor example, consider the following atrocity of a sentence:\n As a native speaker, writing grammatically correct sentences is difficult for me.\n Most native speakers would happily accept this sentence as correct, even though it has a glaring grammatical error.2 Now consider this sentence:\n As non-native speaker, I can write difficult sentence with only few minor errors.\n Most native speakers would recoil in horror, yet all the second author is guilty of is omission of a few articles. Fix the articles, and the sentence is perfectly fine:\n As a non-native speaker, I can write a difficult sentence with only a few minor errors.\n This simple example shows how important it is that you master proper use of articles. In particular, if you’re from Eastern Europe or from Asia and your mother tongue doesn’t have the concept of articles, you will have to put in some serious effort into understanding articles. Otherwise, your prose will always sound like it was written by a foreigner, regardless of how grammatically correct everything else is. So let me give you a brief primer on proper use of articles in the English language.\nDefinite vs indefinite articles The definite article, which in English is “the”, refers to a particular member of a group. For example:\n The cat is on the roof.\nI have to feed the dogs.\n The author is talking about one specific cat, one specific roof, one specific dog. By contrast, the indefinite article, which in English can be “a,” “an,” or no article, refers to any member of a group. For example:\n A cat is a fierce predator.\nAn elephant eats foliage.\nDogs give us unconditional love.\n The author is now talking about any possible cat, any possible predator, any possible elephant, and any possible dogs. Note that the words “foliage” and “unconditional love” fall under the rule of “things that can’t be counted,” which I’ll discuss in the next subsection.\nOne thing that may be confusing is that in two subsequent sentences, the same word may need an indefinite and a definite article. For example:\n Yesterday, I saw a black cat. The cat crossed the street from left to right.\n The first occurrence of the cat requires “a,” because we haven’t heard about the cat before. Thus, at this point in the story, we can only be talking about any arbitrary cat. By the second sentence, though, the cat has been defined. It’s the one that is black and that I saw. Hence, now I have to refer to it as “the cat.” Similarly, I wrote “the cat” throughout this paragraph because I kept referring to that same, black cat defined in the first sentence of the example.\nIf your native language doesn’t distinguish between definite and indefinite articles it may be difficult for you to get an intuitive sense of what it means to be talking about a specific member of a group or about any arbitrary member of a group. If you experience this problem, you will have to practice deliberately. Don’t think that you’ll just intuitively get it one day, because you won’t. You will have to analyze properly written sentences and for every noun in every sentence figure out exactly why it has the article it does. Then, in your own writing, you will have to go over every noun and determine whether it represents a specific member of a group or any arbitrary member of a group.\n Names, countries, things that can’t be counted Names, countries, and things that can’t be counted generally don’t have articles. For example:\n Martin likes ice cream.\nEngland borders Europe.\n “Martin” is a name, “ice cream” cannot be counted, and “England” and “Europe” are countries. However, don’t get confused by country names that include an article, such as “The Netherlands.” The article is part of the name because the name originally referred to a geographic location, such as “the Alps” or “the Sierra Nevada.”\n Places with distinct sets of social behaviors Finally, here comes my favorite rule about articles. This rule is so awesome it needs to be printed in italics:\nWe don’t use articles in preprositional phrases referring to places that require a distinct set of social behaviors.\nThis is such a mouthful, most people cannot even repeat it without error. Yet we all use it instinctively, when we say things like:\n Where do you go to school?\nHannah goes to college.\nI’ll see you in court.\n Here, “school,” “college,” and “court” are all places that require a distinct set of social behaviors. When you want to refer to the specific building, you might say “the school down the road,” but when you want to refer to the social construct of “school” you would always say that you “go to school down the road.”\n Concluding thoughts If you’re a non-native speaker and your mother tongue doesn’t use articles, you’ll almost certainly have difficulty with using articles properly. Invest some time and energy into getting articles right, because incorrect or missing articles will make your writing stick out like a sore thumb. Any native speaker will immediately notice issues with articles and will conclude that the text she’s reading is written poorly. (Even if, by absolute standards of grammatical correctness, that’s not the case.)\nI’d also recommend that you, if you have any issues with articles, always do a proof-reading step dedicated specifically to articles. Read your entire document from cover to cover and verify that every single noun has whatever article it may need. It’s generally a good habit to do multiple proof-reading passes. Each pass should check for one specific mistake you tend to make. Just add that one more pass and check for articles. When following this recommendation, I expect that you’ll write documents in which all articles are right all the time.\n  Of course, I’d still recommend that you write sentences that are largely free of grammatical errors. Just aim first for eliminating errors native speakers wouldn’t make. Then eliminate the errors that native speakers make all the time.↩︎\n If you don’t know what the error is you’re just demonstrating my point.↩︎\n   ","date":1380585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380585600,"objectID":"fdf7dc3f04fc64cb6e999397c3e91c91","permalink":"/blog/2013/10/01/articles/","publishdate":"2013-10-01T00:00:00Z","relpermalink":"/blog/2013/10/01/articles/","section":"blog","summary":"Articles are not optional.","tags":["Articles","Copy editing","Grammar","Proof reading"],"title":"Articles!","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Fitness"],"content":"  For the first forty years of my life, I thought lifting weights was for meatheads. If you lifted weights, my thinking went, you cared more about your looks than your health or fitness level. Actually, not looks even, just sheer size. I was convinced that my fitness regimen of endurance training (running, cycling, walking), flexibility (yoga), and basic whole-body movements (more yoga) was far superior to stupidly lifting weights in a gym. I mean, look at those guys1 in the gym: they take a barbell, lift it five times, and then they take a five minute break. Do they even break a sweat? I don’t call that exercise, I call that sitting around on your lazy behind. Only when I started to read up on exercise physiology did I realize that lifting heavy is an extremely beneficial activity. Further, it is likely the most important type of exercise we can engage in, in particular as we grow older. And those five-minute breaks are absolutely necessary if you’re doing it right, in particular if you care more for strength than size.\nBefore I continue, though, a word of clarification: While the title of this post says “lift weights,” what really matters is that one engages in resistance training, i.e., putting heavy loads onto the muscles, tendons, and bones. Conventional resistance training involves barbell work, e.g. the barbell squat or the deadlift. However, other forms of exercise can be resistance training as well. For example, there are many excellent bodyweight resistance exercises. If you’re regularly cranking out planche pushups, one-arm chins, or one-arm handstands, you probably don’t have to pick up a barbell anytime soon. To find out whether a particular exercise can be considered resistance training for you, find out how many repetitions you could do at most. If you can’t do more than about eight to ten repetitions, you’re in the resistance range. For example, if the max number of pushups you can do in one go is four, pushups are a viable resistance exercise for you. But if you can easily crank out twenty, pushups are an endurance exercise for you and you have to move on to something harder for resistance work.\nSo why should you do resistance training? First, only heavy resistance training can actually activate and train all muscle fibers, including the strongest fast-twitch fibers. If you go jogging for 30 minutes, even at a pretty fast pace, you may feel tired afterwards, your legs may even be sore, but a substantial fraction of your leg muscle hasn’t actually done anything. By comparison, a single set of five barbell squats, at a weight that you can lift only about five times in a row, will have hit nearly every single muscle fiber in your leg muscles. Thus, you get way more exercise bang for your buck. (Incidentally, that’s why you need a few minutes break between sets of heavy resistance training. The exercises truly are that exhausting.) Second, there is better transfer from strength to endurance than the other way round. Once you have strength, it’s relatively easy to build endurance on top. But just because you have endurance doesn’t mean you can easily add strength. In simple terms, if you can do a one-arm pushup, you could easily acquire the ability to do 50 regular pushups in a row. On the flip side, being able to do 50 regular pushups doesn’t do much for your ability to do one-arm pushups. (If you want to see this principle in action, check out this video of a woman first squatting a barbell weighing over twice(!) her own bodyweight and then squatting a barbell weighing her own bodyweight 33 times. I’m sure she could easily do a couple hundred unloaded squats.)\nI would also argue that strength has much more every-day applicability than endurance. When was the last time you had to run at a sustained effort for 30 minutes, outside an organized race? At least for me, that’s not something I encounter frequently (or ever). But carrying five-gallon water containers from the car, putting my luggage into the airplane overhead bin, moving furniture around while cleaning the house, those are things I do all the time. And every bit of strength I have makes those tasks easier.\nOne of the unique benefits of resistance training, one that cannot be realized any other way, is increased bone density. Bones strengthen when they are subjected to load, and they wither away in its absence. (Incidentally, that’s why astronauts experience substantial loss of bone mass during extended stays in zero g.) If you are young and engage in serious resistance training, you will build a strong skeletal structure that will serve you well for a life-time of activities. And if you are old and engage in serious resistance training, you will maintain and possibly even regain bone mass. By contrast, if you don’t do any exercise at all, or the only exercise you ever do is riding a stationary bike, you will most certainly experience substantial bone loss as you age.\nMany people who are not familiar with weight lifting are concerned of the possible injury risks. They picture themselves crushed under a 200lb barbell and can’t imagine how anybody in their right mind would subject themselves to such a risk. However, weightlifting is fairly safe when done properly, i.e., with good form and using weights that are appropriate to the strength level of the athlete. Compared to other physical activities one could engage in (soccer, football, cycling on public roads), weightlifting does not cause more serious or more frequent injuries. Even among people who lift a lot and lift very heavy, any injuries that occur are usually minor (\u0026lt;1 day of training missed). In the elderly, strength training caused about as many injuries as walking and many fewer than jogging.\nThe only downside to heavy lifting is that you’ll look like Arnold Schwarzenegger. Nah, you won’t. Nobody looks like Arnold by accident. Not even Arnold. That look requires years of dedicated effort, very high-volume training, superior genetics, and the right pharmacological support. If you’re just a regular guy or gal going to the gym a few times a week, you’ll look fit, but you won’t look like the Michelin man.\n For the purpose of this topic, we can safely assume that a person lifting weights in a gym is a man. There’s probably twenty guys lifting weights to one woman doing so. If you’re a woman who is seriously into lifting, I tip my hat to you, and you know what I’m talking about.↩︎\n   ","date":1380585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380585600,"objectID":"d27fd1b20b3ff3354fab2c6122d7605d","permalink":"/blog/2013/10/01/why-i-lift-weights-and-so-should-you/","publishdate":"2013-10-01T00:00:00Z","relpermalink":"/blog/2013/10/01/why-i-lift-weights-and-so-should-you/","section":"blog","summary":"Resistance training is critical for a long and healthy life.","tags":["Bodyweight training","Bone density","Bone loss","Resistance training","Weight lifting","Yoga"],"title":"Why I lift weights (and so should you)","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  Choosing the right lab for graduate school can be a daunting prospect. There are so many issues to consider. So many things that could go wrong. And you have to join the most prestigious lab you can get into, don’t you? Well, let’s consider for a moment what the main point of graduate school is. Graduate school is the time when you transition from being a student to being an independent scientist. It is primarily an educational experience. While in graduate school, you should pick up some subject-matter knowledge in your field. You should become familiar with the most important experimental or computational tools of your trade. You should learn how to choose scientific questions and how to solve them. You should develop general life skills such as how to communicate, how to work with other people, and how to get stuff done on time and to spec. So how do you find the right lab in which to acquire all these skills?\nI think that the most important overall consideration should be whether you feel comfortable with the PI, the other members of the lab, and the overall lab culture. In my mind, this is even more important than the specific research area the lab works in. Graduate school will usually take about five years, and it is an important time in your personal development. The people you meet in graduate school will likely remain colleagues and friends for the rest of your life. If you’re miserable the whole time, it’s going to be an awful experience. And even if you manage to power through the misery, you won’t have performed at your best. You could have done better elsewhere.\nFurther, even in the best-case scenario, you can expect that something is going to happen over these five years that will challenge you or bring you down. Maybe a close friend or relative will die. Maybe you’ll experience a prolonged period of illness. Maybe you’ll get pregnant. Maybe you’ll go through a bad relationship breakup. Maybe you’ll just be generally disenchanted with science or with your project in particular. Maybe you’ll feel that you’re not getting enough done and that everybody else is progressing so much more quickly than you are. Whatever it’s going to be in your case, you can be certain that something is going to come your way. And when it happens, being in a lab that is supportive, helpful, and pleasant can make all the difference between a successful PhD and a premature termination.\nBut what about building a competitive cv? Shouldn’t you go with the most famous lab, so you’ll get great publications and will be set for your future career in academia? I’m not convinced. If you’ve read my earlier post, you know that I believe all that matters career wise is that your cv is strong enough by the time you graduate that you’ll get the next job on your career path. If you’re on the academic track, that will usually mean 2-3 high-quality first-author publications, plus maybe a few more papers where you’ve made smaller contributions. In this context, “high-quality publications” means solid papers in recognized journals in your field. It does not mean Nature, Science, Cell, or PNAS. (While those won’t hurt, they’re generally not needed to get a good postdoc.) If you’re not on the academic track, the requirements aren’t that different. They aren’t stricter for sure, so for the purpose of choosing the right graduate program and lab it’s probably best to just pretend you’re on the academic track. So, if the main goal is 2-3 high-quality first-author publications, this is totally achievable in many labs all around the world. Even in labs that aren’t that well known, in universities that aren’t that highly ranked, students routinely perform at this level.\nConsequently, don’t obsess too much about the prestige of the university. Prestige is overrated at the graduate level. (It is much more important at the postdoc level.) Even the most prestigious labs in the most prestigious places frequently hire postdocs from all sorts of universities. This happens because the prestigious labs tend to employ many postdocs, often many more than they produce graduate students, and therefore they simply cannot fill all their positions with graduates from comparably prestigious labs. As long as you graduate with a competitive cv (see above), you’ll most likely be fine and get a good postdoc position. My personal opinion is that any university within the top 200 of the world university rankings will probably be just fine for graduate school. I got my PhD from a university ranked somewhere past 300, and I still managed to get a good job, at a university that is consistently ranked in the top 40 worldwide and in the top 10 nationwide in my field. I’m not saying here that getting a PhD from a higher ranked institution won’t help you. I just think that it’s not as important as you may think it is.\nRelated to this issue, I would like to emphasize that choosing a lab for graduate school requires very different considerations than choosing a lab for a postdoc. My advice in this post is specifically for graduate students; I may write an article for postdocs at a later date. Some labs are really good for graduate students but not that great for postdocs. Some labs are the other way round. Some labs are great for everybody, but those are much rarer and may be highly competitive.\nIn particular, I would be wary of very large labs that are staffed primarily with postdocs and senior scientists. In such labs, it’s not uncommon for graduate students to be treated as second-class citizens that need to fend for themselves. If you’re in that kind of a lab, you may rarely see your PI. Your day-to-day supervision—if there is any—is likely going to come from a postdoc. At that point, you may be getting worse supervision than you would have gotten had you gone with an inexperienced, first-year faculty member.\nAll else being equal, I would urge you to choose the lab that publishes more. If you’re in a lab that publishes a lot, chances are you’re going to be publishing a lot as well. By contrast, if you’re in a lab that publishes rarely, don’t expect to see your name in print that often. In fact, it’s not uncommon for a weaker student in a very productive lab to build a better track record than a stronger student might do in a lab that doesn’t like to commit words to print.\nShould you go with a junior faculty member or with a more established person? There are arguments for either route. If you go with a junior faculty member, you are more likely to get a lot of personal attention. You have the chance to build a lab from the ground up and to get your name on that lab’s important early papers. Most of the early students of scientists who became famous rose to fame with them. Of course, the early students of scientists who didn’t become famous didn’t, so take that for what it’s worth. The argument for an older, more established person is that that person is more of a known quantity. You can evaluate that person’s productivity, impact on the field, mentoring philosophy, and lab culture. The older adviser is also more likely to have connections that may be beneficial to you, and he/she is less likely to make rookie mistakes. Finally, a younger adviser might end up competing with you if you turn out to be really good. By the same token, an older, very established adviser may suck up much of the available grant money in an entire field. Once you leave the lab, you will have to change field and/or develop a clearly unique and distinct identity to remain competitive.\nSome people worry about joining a younger professor’s lab since he or she might not get tenure. I don’t think this risk is particularly high, unless you’re at a school known for never giving tenure. Of course, be careful if the writing is on the wall and there are rumors that the person whose lab you’re considering may not get tenure. In all other cases, I wouldn’t worry much about the tenure situation. Also, keep in mind that if you go with a famous and established tenured professor it’s not certain either that they will stay for five years at the same place. They might get hired away while you’re in graduate school, and that experience could be almost as stressful as your professor not getting tenure. So don’t decide against a lab out of fear, decide for the lab that overall seems to be the best fit for you. If that turns out to be the lab of an old, established professor, you’ll likely be fine. And if it is the lab of a junior person, you’ll likely be fine as well.\nFinally, you need to be aware that there are generally two types of graduate programs: those that have a rotation system and those that don’t. If there is a rotation system, you rotate with 2-4 labs in your first year, and then you decide in which lab to pursue your PhD work. If there is not, then you get accepted into the program under the assumption that you’ll join a specific lab. The advantage of the rotation system is that you can test-drive a lab before joining. The disadvantage is that if none of the rotations work out, or if you don’t get rotation spots in your preferred labs, you may end up in a lab you don’t like or in no lab at all. If there’s no rotation system, then you have to decide on a lab without really knowing much about it. In the latter types of programs, you can set up your own rotation system of sorts by asking to be co-advised by two or three faculty members. After about a year, you can then decide whether you want to stay in the co-advised situation or whether you’d rather just work with one particular faculty member.\nUltimately, I don’t think it matters too much whether you join a program with a rotation system or not. Either way, I would encourage you to get to know the labs in the program ahead of time, and to only join a graduate program if multiple participating labs look attractive to you. Regardless of how wisely you choose your initial lab, you may reach a point where you have to switch, and at that point it’s good to have alternative options.\n","date":1380412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380412800,"objectID":"c8edb10f741f5e27df81fc667c0d018f","permalink":"/blog/2013/09/29/how-to-choose-the-right-lab-for-graduate-school/","publishdate":"2013-09-29T00:00:00Z","relpermalink":"/blog/2013/09/29/how-to-choose-the-right-lab-for-graduate-school/","section":"blog","summary":"Cultural fit is more important than the specific research project.","tags":["Academic career","Graduate school","Undergraduates"],"title":"How to choose the right lab for graduate school","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  Have I ever mentioned that I hate mobile apps? I’m not talking about apps in general. I think it’s great that I can have a calculator on my phone, or skype. But apps that serve as replacements for websites, such as the facebook app or the linkedin app, I hate with a passion. I think they are a step backwards in web development. They degrade the mobile experience for all of us.\nI encourage you to try the following experiment. Go to your favorite app store and read the reviews of a few mobile apps. What are the most common complaints? “This app lacks features.” “I can’t do with the app what I can do on the website.” “The iphone [android] app has feature X, why does the android [iphone] app lack this feature?” I have yet to encounter a mobile app that can be considered feature complete.\nThe original promise of web 2.0 was that we would never ever again have to worry about software installation, operating systems, or device type. As long as we had a network connection and a browser, we’d be able to use our favorite products and tools. And software developers should be able to deliver a better product, since they wouldn’t have to worry about implementing the same features over multiple architectures. On the desktop, this promise has actually played out. For example, whatever you think about facebook the product, you can’t argue that facebook the web platform isn’t a spectacular piece of web engineering. Similarly with google products, such as drive, gmail, or maps. Squarespace, my webhost, has a fantastic online content management system that allows you to develop both the content and the visual appearance of your website in an intuitive and interactive way right in your browser. In the mobile world, however, we haven’t made much progress. Mobile sites frequently don’t work that well or lack features. And mobile apps, the purported replacement for the mobile sites, also frequently don’t work that well or lack features. More often than not, I find myself requesting the desktop version of a page from my phone or tablet because only the desktop version lets me do what I want to do.\nA particularly egregious case is squarespace, which—as I just said—is great on the desktop. On a mobile device, their content manager is utterly useless. In fact, squarespace in their infinite wisdom have decided that I shouldn’t even be allowed to log into their site if I’m on any type of “mobile” device.1 (What exactly is the difference between a macbook air and an ipad? That the latter needs an external keyboard?) The only option I have is their squarespace app, which, pardon my french, is utter crap. Thus, I have a tablet with computational power that would have been considered worthy of a supercomputer 15 years ago, but I still can’t use it for seemingly simple things such as maintaining my website.\nAnother things that bugs me is that most apps don’t synchronize their state across devices and platforms. Consider twitter. Let’s say I’m browsing twitter from my laptop and I get a new tweet. Great. I read it and I move on. An hour later I open the twitter app on my phone, and the app tells me proudly that I have a new tweet. Great! Let’s see what it is. Oh, it’s the same tweet I read already. A few hours later I open the twitter app on my tablet, and it also tells me proudly that I have a new tweet. Guess what. Yep, it’s the same tweet from before, which I’m now seeing for the third time.2 The twitter app is an interesting case because it looks almost identical to the twitter mobile web interface, with the main difference being that the number of followers I have properly updates on the web interface but not in the app. I’m still not quite sure what the point of the twitter app is.\nThe only app I’m pretty happy with is the gmail app, with the one caveat that it doesn’t allow me to create new labels. I’ve got to go to the gmail website for that purpose. The other app I’m quite happy with is the google drive app. In fact, I wrote part of this post using the google drive app on my phone. But that app also has important limitations. For example, while I can change fonts or font size, and can make things bold or italics, I can’t assign styles. Why?\nClearly, even the largest web corporations don’t have the manpower or capability to keep feature parity among their main website, their mobile site, and their mobile apps. I submit that we’d all be better off if mobile apps disappeared and the googles and facebooks of this world put all their energy into improving mobile web technology and mobile versions of their web sites.\n Their argument is that their content manager might not fully work on a mobile device, and thus they’re trying to protect me from messing up my site. I’d prefer to be treated as an adult and allowed to mess up my site with my tablet if I so wish. I mean, how hard would it be to display a warning screen saying: “This might not work fully. Are you sure you want to proceed?”↩︎\n Of course I’ll see the message a fourth time when I open my email inbox. But I can’t fault Twitter for that, I chose to switch on email notifications. The take-home message for you, my reader, is that if you send me a tweet you can be sure I see it. A lot.↩︎\n   ","date":1380412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380412800,"objectID":"ff4116fe4bdac5ffa4e11c732387a674","permalink":"/blog/2013/09/29/mobile-appsthe-bane-of-the-modern-mobile-web-experience/","publishdate":"2013-09-29T00:00:00Z","relpermalink":"/blog/2013/09/29/mobile-appsthe-bane-of-the-modern-mobile-web-experience/","section":"blog","summary":"What's wrong with a straightforward mobile website?","tags":["Android","Facebook","Google","iPhone","Linkedin"],"title":"Mobile apps—the bane of the modern mobile web experience","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  When you write a scientific article, you should lay out your ideas in such a way that your readers can follow them easily. Every new concept should flow directly from the previous material. Yet more often than not, scientific prose can be difficult to understand. What is going on? Readers expect certain pieces of information in certain positions in a sentence. Satisfy these expectations, and your readers will find your writing clear and convincing. Violate them, and your readers will be confused. All readers expect more or less the same things in the same places. And writers commonly violate these expectations. The two most important expectations readers have concern the kind of material that is presented at the beginning of a sentence, in the topic position, and at the end, in the stress position.1 Here I present my take on how to make the best use of these positions to produce clear and coherent prose.\nThe topic position The beginning of a sentence defines the topic the sentence will cover. Therefore, we refer to the beginning of a sentence as the topic position. Your reader expects two things from the beginning of a sentence: (i) to get a sense of where the sentence (or paragraph, section, entire document) is heading; and (ii) to find a connection to something she knows already. The latter of the two expectations is the more important one. Fail to establish a good connection and you will almost certainly lose your reader’s interest and attention.\nIn the middle of a paragraph, you shouldn’t find it difficult to (re-)establish connection with new every sentence. Just start every sentence with a concept, thing, or person you have already mentioned. At the beginning of a paragraph, however, it can be much harder to get the topic position right. You have to make assumptions about what kinds of concepts, things, or persons your reader will likely be familiar with. Then, you can begin your sentence with one of those things. Don’t start off with something you don’t expect your reader to know. In case of doubt, assume your reader doesn’t know much about anything.\nAs an example of poor management of readers’ expectations, consider the opening sentence of an article on an alternative power source:2\n First proposed more than 30 years ago, systems to harvest utility-scale electrical power from ocean waves have recently been gaining momentum as a viable technology.\n The very first phrase you read, “First proposed more than 30 years ago,” is a participle phrase referring to a noun (“systems to harvest […] power”) that we haven’t seen yet. Thus, as you start reading the sentence, you have absolutely no context into which to place the participle phrase. I suspect you were confused when you read this sentence.\nWe can try to fix this problem by moving the participle phrase to a different location:\n Systems to harvest utility-scale electrical power from ocean waves, first proposed more than 30 years ago, have recently been gaining momentum as a viable technology.\n The revised version is better but still has problems. First, by moving the participle phrase, we have created a new problem, the long distance between the subject (“systems to harvest […] power) and the predicate (“have […] been gaining momentum”). I will ignore this problem here because it doesn’t relate to the topic at hand. Second, the sentence has now in its topic position a relatively obscure technology that will not be familiar to the majority of readers. If the article had been written for a trade journal aimed at experts in wave-energy harvesting, this opening would be fine. But the article appeared in the journal Science, and its diverse audience needs a different starting point. To find the right starting point, we have to determine which part of the sentence will be most familiar to the reader. At the same time, we have to decide which part of the sentence should receive the most emphasis, because the revised sentence should flow naturally from familiar material to important material. I haven’t yet discussed how we can write sentences that emphasize the right piece of information. So let me do this first, and then I’ll come back to this example.\n The stress position The end of a sentence is perceived as the position of most emphasis. Therefore, we refer to it as the stress position. The end of a self-contained part of a sentence, such as a clause, will also be perceived as having more emphasis, and we may refer to it as a stress position as well. You achieve maximum impact in your writing when you place the most important part of your sentence into the stress position.\nThe following two sentences demonstrate how meaning can change depending on what is put into the stress position:\nBears eat salmon in the summer. In the summer, bears eat salmon.  The first sentence emphasizes “summer.” This sentence tells us that while bears eat salmon in the summer they probably don’t do so during the rest of the year.3 Further, the sentence doesn’t tell us how much salmon the bears eat. If all you have is this sentence, you don’t know whether bears eat salmon only occasionally or as a staple. The second sentence, on the other hand, emphasizes “salmon.” It tells us that in the summer, bears eat primarily salmon and not something else. Yet this sentence does not make a strong statement about other times of the year. In spring, bears might well be eating the occasional salmon as well.\nSeemingly minor differences in word order will make a huge difference in how your sentences are interpreted. Even if your readers don’t notice these differences consciously, they will be affected by them. If you place the least important part of a sentence into the stress position, your readers will probably perceive your sentence as weak and not convincing. For example, does the following sentence convey big news?\n Paul finally won after buying over 100 lottery tickets at the store.\n When reading this sentence, you probably wondered what is so special about the store where Paul bought the tickets. Now consider an alternative version:\n Paul had to buy over 100 lottery tickets before he finally won.\n This sentence has two stress positions. The primary one is at the end of the sentence and contains the most important piece of information, “finally won.” The second one is right before the “before” phrase and contains the second-most important piece of information, “over 100 lottery tickets.” The store is not even mentioned, because it doesn’t contribute anything useful to the story.\nNow let’s go back to our example from the previous section:\n First proposed more than 30 years ago, systems to harvest utility-scale electrical power from ocean waves have recently been gaining momentum as a viable technology.\n This sentence has two stress positions. They are occupied by “30 years ago” and by “viable technology.” The phrase “30 years ago” doesn’t seem to deserve much emphasis at all and is thus misplaced. The phrase “viable technology” deserves emphasis. Unfortunately, in this sentence it pushes the energy-harvesting technology into the background. For a reader who has never heard of this technology, that it exists at all might be more important than its increasing viability.\nI propose the following revision:\n A thirty-year old technology is gaining momentum as a viable source of alternative energy. This technology harvests utility-scale electrical power from ocean waves.\n This revision places reasonable elements into both topic and stress positions. “A thirty-year old technology” in the topic position of the first sentence prepares the reader to learn something new about an old technology. Any reader with a broad interest in science and technology can relate to this opening. In the stress position of the first sentence, we have “a viable source of alternative energy.” This choice indicates to the reader that the article contains exciting news about alternative energy sources. The topic position of the second sentence repeats the topic of the first sentence, thus establishing connection. In the stress position of the second sentence, the reader learns about the nature of the technology. Somebody who has never before heard of energy harvesting from ocean waves will be surprised to learn that such a technology even exists. The stress position strengthens this experience of surprise.\n Making paragraphs flow When students hear about the topic and stress positions for the first time, they sometimes conclude that in a series of sentences the topic position of every sentence should contain what was in the stress position of the previous sentence. This is a misconception. The topic position should contain something that is familiar to the reader. Anything that has been mentioned in previous sentences will be familiar to the reader and can fill the topic position. So how do you decide what to put into the topic position? Think about which concept, thing, or person best defines the context of the sentence you intend to write and is most likely going to be familiar to the reader. That concept, thing, or person should be in the topic position.\nOften, multiple subsequent sentences in a paragraph will have the same topic. In this case, the same person, thing, or concept will occupy the topic position of all these sentences. Consider the following two sentences from a news article on a research paper:4\n Shiqiang Wan and his collaborators at the Chinese Academy of Sciences’ Institute of Botany in Beijing set up 36 experimental plots on an Inner Mongolian steppe. They warmed some plots only during the day, others during night-time hours only, and yet others around the clock.\n Both sentences tell us about the research S. Wan and his colleagues carried out. Therefore, both sentences have the researchers in the topic position, once by name and once in the form of a pronoun (“they”).\nIn the stress position of the first sentence, we have “experimental plots on an Inner Mongolian steppe.” Notice that these plots are mentioned again in the next sentence, but neither in the topic nor in the stress position. The stress position of the second sentence contains the various experimental treatments used. These treatments and their resulting consequences are the topic of the entire next paragraph:\n Plots warmed only at night turned the steppe from a net carbon source to a net carbon sink; the extra warming overnight stimulated respiration rates, boosting the plants’ daytime rate of photosynthesis and so their uptake of carbon dioxide. The effects of separate day- or night-time warming did not add up to equal the effects observed at constantly warmed plots.\n Notice how in this paragraph, experimental treatments (and their effects) are in the topic position of every sentence.\nIn other cases, the topic of each sentence varies as the paragraph unfolds. In this case, the topic positions should be occupied either by something mentioned previously or by something the reader can be expected to be familiar with. Consider this opening paragraph from a Nature Editorial:5\n On the 30th anniversary of the first description of AIDS, there is much progress to celebrate, but still much work to be done. Research breakthroughs continue to improve treatments and to provide evidence for newer, better strategies that could help people to protect themselves from infection and prevent those infected from spreading the virus. Just last month, researchers reported a study […] showing that when patients are treated early it reduces the chance that they will pass the virus on to uninfected partners by 96% […]\n The beginning of the first sentence sets the stage for the entire paragraph: “the 30th anniversary of the first description of AIDS.” In the topic position of the second sentence, the author put “research breakthroughs.” This term implicitly links back to the phrase “much progress to celebrate” in the previous sentence. The third sentence begins with “just last month, researchers reported.” This phrase links back to “research breakthroughs” and prepares the reader to expect that the third sentence will give specific details about one of these breakthroughs. As you can see, each sentence has a different topic, but all sentences are logically connected to each other.\nThe concepts of topic and stress positions apply not only to individual sentences but also to larger syntactical units. For example, consider two sentences separated by a semicolon; the end of the first sentence serves as a secondary stress position while the end of the second sentence receives most emphasis. Similarly, the first sentence in a paragraph defines the topic for the entire paragraph, and the last sentence in the paragraph receives the most stress. The concept remains valid for even larger units of discourse. The first paragraph in a section should set the stage for the topic of the section, and, even though there will be many positions of emphasis throughout the section, the last paragraph in the section will hold the most emphasis.\n One paragraph, one topic Because the material in the topic position defines the context of what is to come, it is important that each unit of discourse address only a single topic. At the level of individual sentences, most writers get this intuitively right. It is unlikely that anybody would write a single sentence about two separate topics. However, at the level of paragraphs, it is surprisingly common to see this principle violated. We have all read paragraphs that seem to have no clear point, or that just go on and on drifting from one topic to the next. In your own writing, make sure that every paragraph talks about exactly one specific topic. If you have written a paragraph and you wonder whether it might talk about more than one topic, split the paragraph in two. Repeat as necessary. Short and clear paragraphs are better than long and rambling ones. Likewise, subsections, sections, and chapters should also talk about a single, clearly defined topic.\n  This blog post is my personal take on the material presented in: Gopen and Swan. The Science of Scientific Writing. American Scientist Nov. 1990.↩︎\n J. Scruggs and P. Jacob. Harvesting Ocean Wave Energy. Science 323:1176-1178, 2009.↩︎\n Note that I don’t actually know anything about the natural history of bears except that they hibernate in winter. I assume they eat salmon in the summer, but I may very well be wrong.↩︎\n Research Highlight, August 12. Soil ecology: As different as day and night. Nature 460:783, 2009.↩︎\n Editorial, June 1. A big disease with a little name. Nature 474:5, 2011.↩︎\n   ","date":1380153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380153600,"objectID":"468e383c5775bca613b3adab2e3823ac","permalink":"/blog/2013/09/26/writing-paragraphs-that-make-sensethe-topic-and-the-stress-position/","publishdate":"2013-09-26T00:00:00Z","relpermalink":"/blog/2013/09/26/writing-paragraphs-that-make-sensethe-topic-and-the-stress-position/","section":"blog","summary":"Begin with something your readers know and end with a punch.","tags":["Academic writing","Flow","Reader expectations","Stress position","Topic position"],"title":"Writing paragraphs that make sense—the topic and the stress position","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  According to Internet Marketing 101, a blog needs a catchy title, a clear brand. Something that readers can remember easily and that evokes associations and emotions. The blog author’s name will usually not serve that purpose well. Even if it’s a cool name. Even if it’s as noteworthy a name as “Claus Wilke.” Therefore, with this post, I’m relaunching my blog under a different brand. Henceforth, this blog will be called “The Serial Mentor.”\nI thought a lot about branding my blog, because I don’t want to box myself into a narrow niche. I’m never really sure what I’m going to be passionate about six months down the road. And I don’t really want to start a new blog every few months just so the blog’s brand can match my current fancy. However, I think there is a pretty strong constant in my life, something that has never gone away and hopefully never will. It’s my passion for mentoring people, for helping them perform to the best of their abilities. It’s what ultimately makes me get out of bed in the morning and go to work. I just really like to tell people what to do and how to live their lifes.\nI think that the concept of the “Serial Mentor” captures this constant quite well. I may change the topic of my mentoring; I may even do a 180 on some of the advice I’m giving. But I’ll always try to give the best advice I can, to my best knowledge and judgement at the time. In my day job I’m a tenured professor, and academia is really the only thing I know anything about. Therefore, the target audience for my blog will be primarily young academics, from undergraduates to fledgling faculty members. But hopefully, even if you don’t fall into this group, you may discover some interesting material here.\nBecause of my target audience, many blog posts will revolve around topics of interest to academics, such as writing, public speaking, analyzing and presenting data, and so on. However, I will not limit myself to these topics. I take a broad view of mentoring; anything that makes my mentees perform better is fair game. Thus, for example, my interest in nutrition and fitness. We need to be in optimal physical condition to perform at our best mentally.\nIn particular, the food you eat needs to be healthy and enjoyable. If either element is missing, you won’t be happy and you can’t function at your optimum. Similarly, exercise needs to be invigorating and fun. If you hate going to the gym, or if your exercise wears you down so much that you’re constantly tired and in a bad mood, then you’re not getting sufficient return on your exercise investment. Ideally, exercise should be a small to moderate time investment (~3–6h/week) that keeps you feeling strong and awake the rest of the week.\nFor the next few weeks, I have more blog posts planned about writing and about public speaking, and I’ll also do a few posts on nutrition and exercise. Beyond that, who knows. Maybe I’ll blog about body language, or about building rapport with people, or about choosing the right lab or research project. I might even blog about blogging. If you have a specific topic you’d want me to write about, please ask me about it in the comments.\n","date":1379894400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379894400,"objectID":"12d3aae634662a92de7e027028a3d4a1","permalink":"/blog/2013/09/23/a-blog-needs-a-catchy-title/","publishdate":"2013-09-23T00:00:00Z","relpermalink":"/blog/2013/09/23/a-blog-needs-a-catchy-title/","section":"blog","summary":"I'm rebranding my blog.","tags":["Academic writing","Blogging","Exercise","Nutrition","Public speaking","Serial Mentor"],"title":"A blog needs a catchy title","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  I wrote two blog posts recently that addressed the widespread issue of writer’s block. In the first, I suggested that warming up before writing is a good idea to get you into the zone. In the second, I argued that you need to figure out what the story is before you can write productively. There’s a third element to writing productively. Even if you have figured out your story and have warmed up properly, you may still find yourself staring at a blank page for extended periods of time. If this is the case, you are almost certainly operating with an inner critic that holds you back the moment you want to commit words to paper. You need to silence your inner critic to write effectively.\nBefore I discuss the inner critic in more detail, I want to frame this discussion within the concept of writing modes. It is important to realize that there are two distinct writing modes, contents generation and copy-editing. They have distinct goals, and it is best to not muddle the waters between them. Every time you sit in front of a word processor, you should know exactly which mode you’re operating under. If I asked you “Sally, are you generating content or are you copy-editing?” you should answer immediately, without hesitation.1 In the next two paragraphs I give a brief description of each of these two writing modes.\nContents generation. The sole purpose of contents generation is to get words onto the page. As quickly as possible, and as many words as possible. During contents generation, you should not worry too much about word choice, grammar, or even connection between sentences. Just create material to copy-edit later on.\nCopy-editing. The purpose of copy-editing is to polish your text. Fix all the grammatical mistakes you made. Make sure each sentence connects properly to the previous one. Fix all the awkward word choices you have made and eliminate all colloquialisms. Verify all punctuation. Copy-editing can be hard, and it is usually slow. I sometimes agonize 5–10 minutes over a single sentence I need to fix. Importantly, however, copy-editing is not about contents generation. As you copy-edit, you only work with the material you already have. You don’t try to add entire paragraphs of new material.\nThe inner critic is that inner voice that wants you to copy edit as you’re trying to generate contents. You have in your mind a picture of all these sentences you need to say, but the moment you try to commit them to paper the inner critic comes along and says: “Well, that doesn’t sound too smart. And it doesn’t connect to what you’ve written before. And anyway, who uses words like ‘fun’ in formal writing?” And there you go, switching from contents generation to copy-editing, trying to fix this one sentence you need to write before you can proceed to the next.\nThe problem with trying to copy-edit as you’re generating contents is that you’re constantly keeping yourself from getting into the zone where writing just flows effortlessly. This severely limits your overall productivity. You might think that it comes out the same either way, since yes you’re generating slower but you’re also writing higher-quality sentences. Unfortunately, that’s usually not the case. The secret about writing in the zone is that most sentences are spectacularly useful. With just a little copy-editing, they can generally be brought into a sufficiently decent shape that they can be published. The carefully copy-edited sentences your inner critic makes you write, on the other hand, may be beautiful by themselves but they tend to be poorly connected with their surrounding context. Because these sentences were not written quickly, your mind started to wander from topic to topic as you were writing, and hence the sentences don’t hang together. The latter sentences seem to be telling a totally different story than the earlier sentences. To fix this mess, you’ll need more copy-editing than you would have needed had you written quickly in the first place.\nSo how do you silence your inner critic? You just ignore it. When you know that you’re in contents generation mode, you cannot afford staring at blank paper for extended periods of time. Any time you detect yourself doing so, just write down the first sentence that comes to mind and then move on. Remember, you can always go back and copy-edit. In fact, you should do so anyway.2 When you’re in contents-generation mode, get comfortable with writing half-baked sentences. Just write it down how it is on your mind. If you can’t find the right word, write “that thing.” If you can’t find the correct phrasing, write a sentence that describes the actual sentence that should be there instead, such as “here I need to place a sentence that explains how the inner critic prevents me from writing effectively.” If you want, you can mark the sentence in italics or in a different color to indicate that it urgently needs revision. Either way, do everything you can to generate contents and to not be stuck.\nTo give you a frame of reference: It usually takes me about an hour to generate all the contents for a typical blog post such as this one and then another hour to copy-edit it. In practice, though, I don’t write the whole post before I do any copy-editing. I usually write about a paragraph, copy-edit it, write another paragraph, copy-edit that one, and so on. At the end, I copy-edit the whole post a couple more times before I publish it. During copy-editing, I end up modifying maybe 10% of the text. So you can see that the amount of writing I actually do during copy-editing is minimal compared to the amount of writing done during contents generation. Also, keep in mind that I don’t copy-edit posts on my blog as much as I would any formal writing. I want a raw and direct voice on my blog, more like a conversation than like formal writing, and so I leave copy-editing to a minimum. For example, this post contains a few instances of a dangling “this”—as in “This severely limits your overall productivity”—that I would edit out if this were a scientific paper and not a blog post.\n If your name is not Sally it’s Ok to hesitate a bit and wonder who I might be talking to.↩︎\n Please promise me that you won’t ever hand over your writing to anybody else unless you have gone through at least one serious round of copy-editing after you had generated all the contents.↩︎\n   ","date":1379808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379808000,"objectID":"44c8409f58a1210c7771509e3fe6e386","permalink":"/blog/2013/09/22/silence-your-inner-critic/","publishdate":"2013-09-22T00:00:00Z","relpermalink":"/blog/2013/09/22/silence-your-inner-critic/","section":"blog","summary":"Just write first, and leave the copy-editing for later.","tags":["Academic writing","Content generation","Copy editing","Inner critic","Writer's block"],"title":"Silence your inner critic","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  It’s easier to write when you know what you want to say. “Duh,” you may say, “I could have told you that, Claus.” Yes, it’s a pretty obvious statement. But I wouldn’t dismiss its value so easily. When you’re trying to write something, and you get stuck, you need to know why you’re stuck. There may be two reasons: First, you can be stuck because you don’t know what you want to say. Second, you can be stuck because even though you do know what you want to say, you don’t know how to say it. Those two are very distinct scenarios, and they require different courses of action. Can you tell when you find yourself in either? And if so, do you know how to deal with the situation effectively?\nHow to tell It may require some experience and careful introspection to figure out which scenario you’re in. However, there are a few tell-tale signs. For example, do you have a clear idea of what the overarching story is? And if not, do you at least know exactly what the specific paragraph is about that you’re presently writing? I find that it happens quite frequently to me that I do know exactly what the story is, and I even know exactly what ideas I want to express in the present paragraph, and yet I can’t get the right sentences together. That’s a scenario of not knowing how to say it. On the flip side, if you’re not clear on the overarching story, and if you couldn’t express in a single, short sentence what the current paragraph is about, then you’re still at the stage where you don’t know what to say.\nHere, I would like to take a moment to explain the idea of “having a story.” Every time you write something, there needs to be a story. Even if you’re writing the most boring review article on the latest changes in accounting law, your article needs to have a story line. There needs to be a clear beginning, a clear development, and a clear end. If you can’t express the story of the piece you’re writing in a sentence or two, you probably haven’t figured out yet what it actually is that you want to say.\n What to do when you don’t know what to say The more difficult case arises when you don’t know what to say. The action that needs to be taken is relatively straightforward, however. If you don’t know what to say, if you don’t have a story yet, then you should probably not be writing at this time. Instead, you should be working on developing a story. There are many techniques, such as freewriting, mind-mapping, outlining, talking to friends, taking psychedelic mushrooms. (On further reflection, strike the latter one.) Some of these activities involve you putting words on paper, others don’t. Importantly, none of them involve you writing publication-quality prose. So don’t even try. If you don’t have a story, don’t waste your time trying to write one down.\nThere’s one exception to this advice: Sometimes you don’t know the overarching story but you do have an idea what the specific paragraph or subsection should be about. In this case, it’s fine to write just that part of the text without worrying about the overall story. To give a concrete example, I think it’s fine to start writing up the results of a scientific study before the study is even completed.\n What to do when you don’t know how to say it When you’re only dealing with a problem of not knowing how to best say something, the situation is much easier to resolve. If you know what you want to say in principle, you just have to say it whichever way it comes out. You derive absolutely no benefit from staring at a blank page and agonizing over a single word or a single sentence. It’s much better to just write something down, no matter how awful, and move on. You can always come back later and fix the problematic sentence, after you’ve written all of the surrounding text. I often find that when I revisit the problematic sentence later on, what I wrote the first time round isn’t so awful after all, or even if it is, I can easily find an appropriate fix.\nFor these reasons, I have now made it a habit that whenever I find myself staring at a blank page for more than a few minutes, I force myself to write down the first thing that comes to my mind, and then I move on. It has made a big difference in my overall writing output and my sense of happiness while writing.\n ","date":1379462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379462400,"objectID":"e04383e3f9a3502b0444d3a03c645611","permalink":"/blog/2013/09/18/its-easier-to-write-when-you-know-what-you-want-to-say/","publishdate":"2013-09-18T00:00:00Z","relpermalink":"/blog/2013/09/18/its-easier-to-write-when-you-know-what-you-want-to-say/","section":"blog","summary":"A clear story writes itself.","tags":["Academic writing","Freewriting","Inner critic","Mind-mapping","Outlining","Story line","Writer's block"],"title":"It’s easier to write when you know what you want to say","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  In most pursuits of an artistic or physical nature, warming up is standard operating procedure. An opera singer wouldn’t go out on stage without first singing some arias in the dressing room. An olympic gymnast doesn’t step on the balance beam without some serious stretching, as well as a dry-run of her routine on the ground. A sprinter will do some light jogs, stretches, and maybe jumping jacks before the big race. But writers routinely fire up the word processor (or, like in the olden days, take out pen and paper) and attempt to write award-winning prose without any sort of warm up. I don’t think that’s very smart. I believe warming up is as important for writing as it is for singing, gymnastics, or track-and-field.\nYou do your best writing when you’re in the zone, when the words just flow out of your mind onto the paper. When you’re writing without pause for an hour or more, and then, when you finally take a break and look at what you’ve just done, you see that you’ve finished two pages of excellent, coherent material. How often do you, my reader, experience this state of flow? If this is your normal state of writing, then keep doing what you’re doing, you’re doing fine. My experience, though, from having talked to numerous students, and having taught a writing class for a couple of semesters, is that most people do not describe their regular writing experience in those terms. Much more common descriptions are: “I agonize over every word.” “I stare at a blank page/screen for hours.” “I write a sentence, only to immediately delete it and write it again, over and over.” “Writing is like drawing blood with a blunt needle.” If these latter sentences describe your experience while writing, then try to incorporate some warm-up exercises into your writing routine.1 I bet you it’s going to help.2\nHow do you warm up? It’s easy. Just take an empty sheet of paper and a pen (or open a new document on your computer) and write down any thought that comes to your mind, for about 10-15 minutes. In this exercise, it doesn’t matter so much that you formulate complete sentences, or anything coherent at all. The only thing that matters is that you put words on paper, period. You might think: “But what if I have nothing to say? What if I run out of ideas?” The truth is your mind is never completely empty. However, there may be thoughts you may feel uncomfortable putting on paper, thoughts that are too incoherent, too embarrassing, too silly, to inappropriate. For the purpose of the warm-up, none of this matters. Just write it down anyway. You can always plan to burn the piece of paper afterwards, or to close the document without saving.\nAnd if you truly don’t know what to write, just write that. It is fine to just write “I really have no idea what to write now. I’m supposed to write without pause, but my mind is empty. What can I write when I have nothing to write? I guess I have to write nothing then. Nothing is also words, though. Just words that say nothing.” and so on. The one thing you must not do is stop. The goal of the exercise is to become familiar with the state of flow while writing. The more you experience the flow when writing inconsequential things, the more you’ll be able to recreate the same experience while writing something useful.\nDoes it matter whether you warm up on a computer or with pen and paper? It depends on your typing and thinking speed. I find that I can type faster than I can think. The result is that when I write on a computer, my hands frequently have to wait for my brain to catch up. This is not good for flow. If I write in longhand on paper, by contrast, my writing is slower than my thinking, and I never have to interrupt the constant flow of writing. I think that’s the better approach. It is much easier to reach a state of flow if you’re engaging in an activity that has absolutely no interruption. One that just hums along for 15-20 minutes. However, if you’re a slower typist, or if you can think faster than I can, then warming up on a computer may work for you. Also, if you’re less than 30 years old, you may never have written much in longhand in the first place, and doing so may feel so awkward that it disrupts the flow. I would say try it out and see what works best for you. There isn’t necessarily a one-size-fits-all solution.\nIf you’re already warming up before writing, or if you are going to try it out after reading about it here, please share your experience with me in the comments. I’d like to hear about how warming up for writing works for you.\n If you don’t have a writing routine, that’s a serious issue in itself. A topic for another post.↩︎\n Warming-up by itself may not be sufficient, if you’re a severe case. There are other important techniques, such as silencing your inner critic. I’ll blog about that at some point in the future.↩︎\n   ","date":1379289600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379289600,"objectID":"6cf4643f819b75cee2e6606800a52d24","permalink":"/blog/2013/09/16/2013-09-16-warm-up-before-you-write/","publishdate":"2013-09-16T00:00:00Z","relpermalink":"/blog/2013/09/16/2013-09-16-warm-up-before-you-write/","section":"blog","summary":"Warming up is as important for writing as it is for singing, gymnastics, or track-and-field.","tags":["Academic writing","Flow","Longhand","Warming up","Writer's block"],"title":"Warm up before you write","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Fitness","Nutrition"],"content":"  I was pointed to this infographic on superfoods, which aims at summarizing the scientific information we have about the health benefits of specific foods. It ranks health claims about specific foods by the strength of scientific evidence for the claim, and provides direct links to the relevant studies. The first thing you’ll notice if you look at it is that most claims fall well below promising. However, there are a few that are listed as good or strong. Since I’m somewhat of a nutrition geek, I of course went immediately and looked at the claims that are supposed to be the strongest. I was dismayed to find that of the four claims listed as very strong, at least two are rather dubious. Those two are barley and oats. (I stopped reading after that. The other two may well be dubious as well.)\n Figure 1: Interactive superfoods infographic from informationisbeautiful.net.  There are two issues with those two claims: First, there is no credible health claim. Second, regardless of the validity of the claim itself, the claim is not well supported by evidence. Let’s consider these two pieces in turn.\nCredibility of the health claim: Both oats and barley are listed for cholesterol. The problem is, cholesterol is not a disease. At best, cholesterol is a marker for a disease (cardiovascular disease, CVD). But it’s a really weak marker. It basically doesn’t work. The main reason we are obsessed with cholesterol is that in the 1950s, it was one of the first physiologic markers of CVD that could be easily measured. As a consequence, cholesterol testing became standard, and we all started to worry about cholesterol levels. But the science hasn’t held up. By now, it is pretty well established that CVD is caused primarily by inflammation, and inflammation is caused by an excess number of oxidized Low-Density Lipoprotein particles (LDL particles). A standard cholesterol test measures the amount of cholesterol carried by LDL particles. It is entirely possible to have a small number of particles carry a large amount of cholesterol (high cholesterol, low disease risk) or to have a large number of particles carry a small amount of cholesterol (low cholesterol, high disease risk). Thus, unless a food lowers the number of LDL particles, its effects on cholesterol levels are irrelevant. If this is news to you, read the nine-part series on cholesterol by Peter Attia, in particular part vi and part ix.\nStrength of evidence supporting the claim: The link between oats/barley and cholesterol is supported by nutritional epidemiology, a field that has largely failed to produce any useful insight. Nutritional epidemiology can reveal associations between components of a diet and diseases/disease markers, but it cannot establish any causal relation. Further, because the number of potential confounding variables is huge, and the effect size generally small, nearly all results in nutritional epidemiology are driven by unobserved or uncontrolled confounders. Yes, you could use nutritional epidemiology to establish that eating potassium cyanide is bad, or even that eating arsenic in large quantities is bad, but you’ll generally not be able to ascribe specific health benefits to regular foods that people have eaten for generations.\nThe biggest confounder in nutritional epidemiology is the healthy person bias, which means that people who take good care of themselves will generally be healthier, and they will also do what is commonly believed to be healthy. At that point, nutritional epidemiology becomes a self-fulfilling prophecy. If we’re being told that oats and barley are good for us, then the most healthy-conscious people are going to eat more oats and barley, and hence we’ll see an association between consumption of oats and barley on the one hand and better health profiles on the other hand. The number of people who are like me, who are very health conscious but think that a diet of eggs, steak, and butter is healthy, is rather small. Therefore, I don’t expect any association study in the near future to support my view. But even if it did, it would be just as meaningless, for the same reasons. If you want to learn more about the problems with nutritional epidemiology, I recommend the work by Gary Taubes, in particular his book “Good Calories Bad Calories.” For a quick online read, check out this article.\nSummary: I don’t think we know much about nutrition at all at this time. I’m generally sceptical of any health claim, unless it is linked to a solid, experimentally verified mechanistic explanation. (There can be little doubt, for example, that an excess of refined carbohydrates is a main driver in Type-II diabetes.) But even if a mechanistic explanation is available, we all have different genetic backgrounds and react to food differently as a consequence of that. For example, some people can eat grains and sugar all their life and be fine, while others need only look at a slice of bread and develop insulin resistance.\nFor myself, I’ve come up with the following list of simple guidelines that I think are well supported and reasonable:\nIf you eat something and it makes you feel bad, stop eating it. If you’re frequently tired, have low energy, or have frequent digestive issues (heartburn, bloating, constipation, loose stools), you may be eating things your body can’t handle well. Try an elimination diet. If you suffer from allergies, you may be eating things your body can’t handle well. Try an elimination diet. If you frequently have energy supply problems, i.e., you easily get tired in the afternoon, or you frequently feel like your brain will shut off unless you eat something immediately, you lack metabolic flexibility. Play around with the macronutrient composition of your diet (more fat, more protein, fewer carbs) and see if it makes a difference. If you feel great, have good energy, generally feel awake and productive, it’s very unlikely that your diet has major issues.  ","date":1379030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379030400,"objectID":"7ff699a7e5b3e6ac1d6f96a63feea11c","permalink":"/blog/2013/09/13/do-we-know-anything-about-nutrition/","publishdate":"2013-09-13T00:00:00Z","relpermalink":"/blog/2013/09/13/do-we-know-anything-about-nutrition/","section":"blog","summary":"If you eat something and it makes you feel bad, stop eating it.","tags":["Cholesterol","Diabetes","Heart disease","Nutritional epidemiology","Superfoods"],"title":"Do we know anything about nutrition?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  The other day, I wrote a blog post about critical decision points in an academic career. Titus Brown felt that I was perpetuating the belief that being “good enough” is a necessary requirement to becoming a faculty member. My intention in writing the post was actually the exact opposite, to argue that whether somebody is or is not “good enough” is largely irrelevant to their success in academia, and not something they should spend much time thinking about. Clearly I didn’t quite succeed in getting my points across, so I’ll try again.\n@RELenski You know, I really disagree with @clauswilke phrasing: “Are you good enough to be a faculty member?” even in context here. — Titus Brown (@ctitusbrown) September 10, 2013  @RELenski @ClausWilke Perpetuates belief (unproven) that “being good” is even necessary for being faculty, much less sufficient. — Titus Brown (@ctitusbrown) September 10, 2013   I subscribe to Malcom Gladwell’s threshold theory,1 which argues that beyond a certain minimum required amount of innate talent, professional success is largely independent of talent and depends instead on numerous other factors, such as the amount of training you receive and the opportunities that come your way. In a nutshell, according to Gladwell, you can’t groom the village idiot into becoming a faculty member at Harvard, but any incoming graduate student in any decent university likely has the innate talent necessary to get there.2 From there on out, it’s all just effort, proper coaching, the right connections, and some amount of luck.\nThere can be no doubt that luck is important for professional success, in particular on the road to getting a tenure-track position.3 Many pieces have to fall into place, many of which may not have anything to do with who you are and what you can do. If you’re on the job market in a recession, when there are virtually no faculty searches going on, it’s going to be tough regardless of your track record. If suddenly a new hot area opens up and you happen to not work in that area, it may be difficult to convince departments that you’re the right candidate. My own trajectory reflects this. Without luck, I wouldn’t be a faculty member at UT Austin today. I got my job because Josh Plotkin’s wife needed to be close to a medical school, and UT Austin didn’t have one at the time. So Josh declined my department’s offer, even though it was his first choice. If Josh had been married to a different wife or not at all, or if UT Austin had been ten years ahead of their current schedule to getting a medical school, my life might be very different today.\nAt the same time, I do subscribe to the idea that luck is a skill. I’ve seen this countless times with colleagues, friends, and family. Some people are just consistently lucky. They always seem to make out alright. And others appear to be consistently unlucky. Something always goes wrong for them, no matter what they do. As somebody who (I believe) falls on the luckier side of the spectrum, and also as somebody who has a good sense of how actions connect to possible outcomes,4 I can usually spot the behavioral patterns that cause people to be lucky or unlucky. Show me somebody who is consistently unlucky, and I’ll tell you what they’re doing wrong. It would take more than a few lines in this already far-too-long blog post to explain specifics. So I’ll defer that for another time. For now, if you think you’re consistently lucky, keep doing whatever it is you’re doing. If you think you’re consistently unlucky, you probably have a tendency to use the wrong priorities in your decision making. You might make decisions out of fear, or out of a desire for pleasure, or for immediate benefit, rather than based on a rational assessment of the long-term consequences of your decisions. It might help you to discuss your decisions with a thoughtful mentor, and to listen to her advice.\nLet’s get back to the original question. What does it take to become a faculty member? First, you need some amount of innate talent. If you’re still reading, and you’re not constantly thinking “so many complicated words,” you probably have sufficient innate talent. Second, you need some genuine luck. For example, you accidentally meet somebody at a conference who turns out to be really supportive of your work; or you make a genuinely unexpected, major discovery; or your major competitor falls while rock-climbing and is out for a year, just when you go onto the job market. Third, you need some engineered luck. You need to see opportunities when they come your way and take advantage of them. When issues arise that could cause you trouble down the road, you need to deal with them efficiently and effectively. You generally have to behave in such a way that you’re not your own worst enemy. Fourth, you need to be willing to put in the required effort. The impressiveness of a cv is strongly correlated to the amount of work expended to developing said cv, and nothing is ever going to change that. And fifth, you need to have the resilience to slog through the downturns that you will inevitably encounter on your path in academia. There will be times when nothing seems to go right, when no reviewer likes your papers or grant proposals, when you feel you’re just spinning your wheels with nothing to show for. You will have to work through these periods to be successful in academia.5\nWhich of those five points fall under your control? The first does not. However, you’re still reading, so that point is irrelevant. The second doesn’t either. There’s nothing you can do about genuine luck or genuine misfortune. So don’t spend any time thinking about it. The other three points fall under your control, and they contribute (by my own, totally unscientific estimate) to at least 70%-80% of your success. So get cracking.\n The threshold theory is described in Gladwell’s book “Outliers.” It’s a great book. If you haven’t read it yet, do so.↩︎\n Realistically, if you start with serious coaching only in graduate school it may be too late for star-level success. The kids that were groomed to become Harvard professors when they were three years old will have an enormous head start, one that may be difficult to catch up to. You should still try, though.↩︎\n On this note, I find it interesting how many faculty members who are now among the most established scientists in their field were at some point close to giving up on academia. For example, Richard Lenski describes his winding path to his first faculty appointment here. I heard about this story first when I was on the job market and thought I’d never find a decent job, and I found it strangely comforting.↩︎\n I’m an INTJ. My mind is all about possibilities, and how they are connected to what’s happening right now.↩︎\n Of course the main issue here is to distinguish between constructively slogging through a temporary setback and delusionally keeping on going even though the situation is truly hopeless. I hope my previous post can help there. As should any capable adviser or mentor.↩︎\n   ","date":1378771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378771200,"objectID":"5fda54ec49e93b22928302e432fb722a","permalink":"/blog/2013/09/10/how-good-is-good-enough/","publishdate":"2013-09-10T00:00:00Z","relpermalink":"/blog/2013/09/10/how-good-is-good-enough/","section":"blog","summary":"Asking yourself whether you're good enough for an academic career is rarely useful.","tags":["Academic career","Graduate school","Postdocs","Tenure track"],"title":"How good is good enough?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  I strongly recommend that junior scientists (and even senior scientists) list submitted papers on their cv. The main reason is the inevitable delay between when a project is done and when a paper finally comes out. If I see a cv with no publications in the last year, I don’t know if that is because the person got lazy or because there are five papers in the pipeline that just haven’t made their way out of review yet. If I see a couple of papers listed as “submitted” or “in review” it gives me confidence that the person hasn’t gotten lazy yet. Also, from the titles of the papers, I can get a sense of where the person’s work is going at the moment.\nSome might be concerned that a paper that isn’t formally accepted isn’t quite a paper yet, since it doesn’t yet have the official stamp of approval. Therefore it shouldn’t be on the cv. After all, it might never see the light of day. This kind of reasoning does not really reflect reality. As far as I can tell, if a paper has been submitted it might as well have been published, because realistically most papers that get submitted will get published eventually. I have published over 100 papers, and throughout my entire career I can recall maybe 3 or 4 cases where I gave up on a paper after review. I see similar statistics as a reviewer or editor: Most papers that come my way and that I consider to be of insufficient quality to appear in print do so anyway, eventually. So I’m going to argue that maybe 5% of papers get submitted somewhere but never formally appear, while the remaining 95% are on track to becoming published works. I’m a theoretical physicist, and to me 95% is close enough to 100% that I don’t care about the difference. Once a paper has been submitted, I count it as a published paper.\nThe argument becomes even stronger if a senior scientist is a coauthor on the paper. If that senior person generally publishes solid works, and if he or she agreed to submission of the article with their name on it, chances are it is a solid piece of work as it currently stands. Reviewers may still have some issues that they’re going to nitpick over. However, realistically reviewers are wrong as often as they are right, and why should I give more credence to some random, anonymous reviewer than to the senior person whose work I respect?\nThere is one caveat, though: The number of papers listed on your cv as “in review” should be commensurate to your typical publication output. If you have published two papers a year for the last three years and you list 20 that are in review, I will be skeptical about the quality of those papers and will wonder whether maybe your success rate from submission to publication is not near 100%. But if you usually publish two papers a year and you list three in review, that looks reasonable and I won’t give it a second thought.\nI view papers “in preparation” differently, however. “In preparation” means nothing. A paper that is submitted must have gotten to the point where at least one, and usually several, scientists felt it could be published in principle. A paper in preparation could be nowhere near that point, and it might never get there. I certainly have had plenty of papers in my life that were “in preparation” and eventually transitioned to “nobody even remembers what the project was supposed to be about.” If I listed all of those papers on my current cv, it’d probably be twice as long and half as useful. If you have a paper in preparation that you really want to list on your cv, then hurry up, get it done, and submit it. And put it on a preprint server, too, so you and others can cite it.\n","date":1378771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378771200,"objectID":"04982c245cc9869f392e6a8ac5b79881","permalink":"/blog/2013/09/10/should-you-list-a-paper-in-review-or-in-preparation-on-your-cv/","publishdate":"2013-09-10T00:00:00Z","relpermalink":"/blog/2013/09/10/should-you-list-a-paper-in-review-or-in-preparation-on-your-cv/","section":"blog","summary":"List papers in review but don’t list papers in preparation.","tags":["Academic career","CV"],"title":"Should you list on your cv a paper that is in review or in preparation?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Visualization"],"content":"  If I were king of the world, I would decree that every man or woman who releases a software product, for pay or for honor, with the purpose of graphing data, shall, upon pain of death, ensure that the default axis labels, axis tick labels, and legends are printed at a reasonable size, legible to your aging king’s declining eyesight. However, because I would be a fair and wise king, I would also decree that every such man or woman have a one-month grace period to bring their software into compliance. Without such a grace period, I’m afraid all authors of currently available graphing software would have to instantly lose their heads.\nI have been in science for almost 20 years, and I have used and seen used a myriad of different graphing programs. When I was a grad student, gnuplot was all the rage. As a postdoc, I mostly used xmgrace. These days, I rarely make figures myself, but my students use everything from R with various plotting libraries, python with matplotlib, to MATLAB and even Mathematica. (As an aside, MATLAB and Mathematica, the commercial products, are both strong contenders for ugliest default graphics, by a wide margin. Apparently neither of the parent companies can afford to employ a graphical designer.) NONE of these programs use sane defaults for axis labels. They don’t use sane defaults for other things either, but this post is about axis labels.\n Figure 1: Scatter plot created in R, using the functions pdf() and plot() with default options.  Getting axis labels right shouldn’t be that hard. Figures usually appear in print at a width of about 3” to 5.5” (depending on whether they span one or two columns in a typical two-column layout). So, when you scale down the figure to that size, the font should be at a reasonable size, somewhere in the range of 10pt–12pt. Make it 9pt at 3” for your default settings, and you’ll never be terribly off. How hard can it be? Very hard, apparently. Try it out: Take your favorite plotting program, make a simple graph, say an x–y scatter plot using default settings, then scale the resulting figure to 3” and see if the labels are at a suitable size. If I do this in R, I get the result shown in Figure 1.\nThere’s more things that are wrong with this figure than just axis labels, but axis labels is what I’m focusing on here. Clearly they are too small. I bet you’ll get the same result in your favorite plotting program. By default, virtually all plotting programs I’m aware of make axis labels way too small.\nSo, what is going on here? First, I doubt that the people writing plotting software are experienced scientists who have prepared thousands of publication-quality figures. So maybe they just don’t know any better. Second, and more importantly, I believe the culprit is screen preview. Take the same figure, blow it up to a width of 20” on a modern, high-resolution monitor, and the axis labels look just fine. In fact, if you take a figure with properly sized axis labels and blow it up to 20”, the axis labels look outright scary. I can totally understand how somebody who has only ever looked at graphs on screen would feel uncomfortable making fonts bigger. Unfortunately, we the consumers of plotting software will generally have to produce figures to be used in print, and thus we have to scale the fonts to an appropriate size, even if it scares us. Apparently the authors of said software don’t have the guts to do so.\n","date":1378771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378771200,"objectID":"4cbb38d91d1445a8293a864a04e1c88d","permalink":"/blog/2013/09/10/the-axis-labels-are-too-damn-small/","publishdate":"2013-09-10T00:00:00Z","relpermalink":"/blog/2013/09/10/the-axis-labels-are-too-damn-small/","section":"blog","summary":"Look at scaled-down versions of your figures to assess whether the axis labels are legible.","tags":["Data visualization","Visual design"],"title":"The axis labels are too damn small","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia","Professional development"],"content":"  If you’re an undergraduate contemplating an academic career or a graduate student considering the next steps, you may have the long-term goal of becoming a tenured professor at a major research university. At the same time, you may have serious doubts about whether this is the career for you. Are you good enough to be a faculty member? And if you’re not good enough, will you waste years of your life with little to show for it in the end? Even if you’re good enough, is that sufficient, or will you also need an extraordinary amount of luck? By embarking on an academic career, will you be making a high-stakes gamble that may have a catastrophic outcome if you lose? These are serious doubts, and they can make the prospects of pursuing an academic career seem overwhelming and pointless. As a substitute for these overwhelming, larger-than-life questions, I’d like to offer a set of critical decision points and simple rules about how to proceed. I hope that these suggestions will make the path to an academic position more navigable and less stressful.\nLet me first clarify, though, that I don’t think every graduate student has to become a tenured professor at a major university. In fact, I believe that the majority of graduate students are not on track to become faculty members. For example, I read about a case study once where of an entering class of 20 graduate students at Yale university, only 2 had a tenure-track career 10 years later (I’m recalling this from memory, so I may have some details wrong, but the gist was approximately that.) Losing that many students to pursuits other than pure academia is Ok, as long as the majority of them finds satisfying and appropriately compensated employment. And I’m pretty sure they do. They certainly do if they picked up serious computational skills during their PhD. On the other hand, while I don’t see it as my mission to turn every student of mine into a professor, I also don’t want to see highly gifted and capable students give up on an academic career just because they perceive it as an impossible feat, one they shouldn’t even attempt.\nFrom undergraduate to graduate student If you’re currently an undergraduate, you shouldn’t even think about whether you’re on track to becoming a professor. It’s impossible to know anyway, and it doesn’t matter for the main decision you have to make: Should you go to graduate school or not? Unless you are under strong financial pressure to earn money right away (e.g. you have enormous student debt, or you have three children that you have to support on your own), this decision should not primarily be a financial one. For most students, graduate school is approximately cost-neutral: The stipend you’re paid while working as teaching assistant or graduate research assistant covers your basic living expenses. You don’t save any money while you’re in graduate school, but you also shouldn’t accumulate any debt. You could think about graduate school in terms of income lost over five years versus your future earnings potential, but frankly, if you think in these terms I don’t think a graduate program in science is right for you. Get a graduate degree in business, economics, or management, and embark on a career of serious money making.\nA graduate degree in science is for people who really care about figuring things out, or about solving problems. As an undergraduate, you have to be aware that graduate school will be very different from your undergraduate experience, unless you’ve already spent a substantial amount of time in a research lab. Graduate school is not about passing exams, getting good grades, or cramming material. In the end, it’s all about doing science and writing papers. Some people have a 4.0 undergraduate GPA and fail in graduate school, and others have a 2.9 GPA and succeed. If you really care about figuring things out, if you could see yourself spending months at a time getting to the bottom of an issue, then graduate school is for you. Don’t worry about the naysayers that say a PhD is a worthless piece of paper. I am not aware of any evidence that a PhD in science will hurt your subsequent employability. It may not help you much, depending on how things go, but as I said already, you shouldn’t get into a PhD program for the money anyway. You should get into it because of your passion for research.\n From graduate student to postdoc Ok, you’ve now made your way almost all the way through graduate school and the end is in sight. Should you continue and search for a postdoc position? Or should you jump ship and look for alternatives? At this point, I think it is justified to ask about earnings potential. You have obtained the most advanced degree you’ll ever get. From here on out, you’re not in it for the education, you’re in it for the experience. You have to ask yourself: Would I rather make money, or would I rather do nothing but research for a few years? For most academics, the postdoc time is a uniquely rewarding and free time. A time during which you can (mostly) freely pursue whatever research you care about, on your own schedule. You have completed your 10,000 hours of science by that time, so you can hit the ground running and do interesting stuff. For poor compensation, mind you. If your mindset is “I don’t really know what else I’d want to do anyway” then go ahead and do a postdoc. But if you can see a clear alternative path, and if that path looks attractive to you, then that alternative path may be the better choice.\nImportantly, though, it is still not time to ask yourself whether you’re on track to becoming a faculty member. Plenty of graduate students don’t do that well, only to recover spectacularly during their postdoc. And others do well as graduate students but falter as postdocs. Generally, the former group does much better than the latter on the academic job market. I’m part of the former group, and I made out alright. I like to say that if you erased from my resume every single thing I did during graduate school, nothing of consequence would change. I got a job as a faculty member anyway.\nYou do have to make an honest assessment, though. Where do you stand relative to your fellow graduate students? Would you say your performance is comparable to most? Better? Worse? After five years in graduate school, you may not yet have made an earth-shattering discovery, but you should know by now whether you’re cut out for science or not. In particular, do you have one or two papers to your name for which you did the majority of the work, including the conceptual work? (I don’t care how good they are, just that they got done.) If after an honest assessment you find that you’re not really cut out for science, then don’t do a postdoc. Find a different occupation.\nOne word of hope for finding a postdoc position: For as long as I can remember, the job market has been in favor of postdocs. Any capable graduate student who wants to can find a decent postdoc position. So don’t ever worry about not getting a postdoc position. If you want one, you’ll get one.\n From postdoc to faculty member Now you’re two to three years into your postdoc. Finally it’s time to ask yourself whether you’re on track to becoming a faculty member or not. Take honest stock. Where are you, compared to other people in the field that you’d be competing with on the job market. Ask some senior scientists about an honest evaluation. Hopefully your postdoc adviser will be able to tell you where you stand. In my opinion, if you’re three years into a postdoc and you’re nowhere near ready to apply for a faculty position, then it may be time to consider alternative careers. If you’re three years in and you’re ready to apply, then go for it and see how it goes. If you’re three years in and you’re getting close but you’re not quite there yet, then it’d be reasonable to wait another year. But don’t keep saying “I’ll be ready next year.” At some point, if things don’t work out in academia, you have to cut your losses and move on. Where that point is is a somewhat arbitrary and a bit of a personal choice, but I’d place it around five years. After five years of a postdoc-level position, you should find something more permanent. And if that job is not a tenure-track faculty position, then you may have to settle for research scientist, lecturer, administrator, or whatever else you can make work for you. There are plenty of reasonable career paths for a scientist, just don’t become a career postdoc.\nNow, you can’t expect things on the job market to work out the first time round. You may not be quite ready, the big paper you wrote may not yet be that well known, or it may just be a bad year for academic hiring. If by your own and by your senior colleagues’ assessment you are ready to get a faculty position, then don’t despair if it doesn’t work out the first time round. Try at least two rounds. Also, if you changed your field after your PhD, or if you didn’t really do much of consequence as a graduate student, you may need a little more time as a postdoc. I was a postdoc for five years, and I think I needed that time to be really ready for a faculty position.\n Summary As undergraduate, follow your passion. If you have a passion for figuring things out, get a graduate degree and see if you still like it five years down the road. Don’t worry about not being good enough.\nAs graduate student, if your passion hasn’t disappeared, and if you can stomach another three to five years of being poor, go for the postdoc. Don’t worry about not being good enough.\nAs postdoc, do an honest assessment of where you stand. If you are competitive on the job market, go for it. If you’re almost competitive, do what needs to be done to eliminate the “almost.” If you’re nowhere near competitive after about three years, start thinking about alternative options.\n ","date":1378425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378425600,"objectID":"cf2e2780ca9e422222a9945bf3436fcc","permalink":"/blog/2013/09/06/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career/","publishdate":"2013-09-06T00:00:00Z","relpermalink":"/blog/2013/09/06/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career/","section":"blog","summary":"Take things one step at a time.","tags":["Academic career","Graduate school","Postdocs","Tenure track","Undergraduates"],"title":"From undergraduate to faculty member: Critical decision points in the academic career","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Fitness","Nutrition"],"content":"  About a year ago, I gave up breakfast. The truth is, I’ve never liked breakfast. When I wake up, I’m not hungry. Why should I eat? However, breakfast is important, right? Everybody knows, breakfast is the most important meal of the day. Not eating breakfast is associated with all sorts of ills.1 It will make you fat. It will give you heart disease. Why would anybody in their right mind not have breakfast?\nWell, two things happened about a year ago that made me change my mind. First, I learned about the recent trend of intermittent fasting, which basically amounts to not eating for extended periods of time on a somewhat regular schedule. One of the most popular schedules for intermittent fasting is 16 / 8, which means that every day you fast for 16 hours and then you have an 8 hour window in which you’re allowed to eat. If you do the math, if you skip breakfast, have lunch at noon, and finish dinner before 8pm, you’re on a 16 / 8 intermittent fasting schedule. So 16 / 8 intermittent fasting is really just a fancy term for “skipping breakfast.” Second, and more importantly, I read this life-changing article: “Why does breakfast make me hungry?”2 This article, written by one of the leading intermittent fasting proponents, explains in detail the hormonal reasons that cause some people to get really hungry shortly after breakfast. In fact, I had always noticed that I got really hungry about an hour or so after having had breakfast. And it didn’t seem to matter much what I ate, or how much I ate, for breakfast. I would be reliably hungry around 10am–11am. (I’m not an early riser.) So clearly, what was written in this article held true for me.\nNow, between having a solid scientific explanation for why breakfast seemed to make me more not less hungry and a cool name for my new habit of not eating breakfast, I decided to take the plunge with 16 / 8 intermittent fasting. I haven’t had more than maybe 5–10 breakfasts, total, over the last year. Well, technically, my break fast is the first meal I eat after fasting, regardless of the time. So to be more precise, I haven’t eaten before noon more than maybe 5–10 times, total, over the last year. When I started out, I would have coffee with some cream in the morning, so I had a small caloric intake shortly after waking up. But lately I’ve given that up as well. I now take my coffee black.\nWhat has been the outcome of this experiment? If you google “intermittent fasting,” you can read about all sorts of demonstrated or plausible health benefits, such as increased insulin sensitivity, improved body composition, or neuroprotection. But I don’t want to talk about that here. Instead, I want to talk about how it has affected me, personally, in my day-to-day life.\nMost importantly, my dependency on regular feeding has gone way down. Do you ever have the sense of “I’m starving; my brain is going to stop functioning unless I get food right now?” I used to have these sensations all the time. But if you think about it, it can’t be true. Unless you’re anorexic, if you live in the civilized world you’re not about to starve. You’re not about to starve if you haven’t had food for a day. Realistically, you’re not about to starve if you haven’t had food for a week. You’re certainly not about to starve if you haven’t had food for a few hours. So why would your body tell you so? Because after years of around-the-clock feeding, after rarely if ever experiencing more than a few hours in the non-fed state, your body has forgotten how to make effective use of its energy reserves. The required genes are not turned on. You can’t burn the layer of fat on your belly, even though it’s there. So your body screams for food. I know mine used to. Now, after a year of intermittent fasting, I don’t usually have this issue anymore. I’m certainly not hungry during my regular fasting window. And even if I have to fast longer, for example because I really have to get something done and can’t eat at my regular lunch hour, it doesn’t really matter to me. I just keep going, and I eat when I can. I also don’t usually snack anymore. Why should I need a snack if I’ve just eaten a few hours earlier? My body isn’t even done digesting yet.\nThe other huge benefit is all the extra time I now have that I’m not spending on thinking about getting food, procuring food, preparing food, eating food. After getting out of bed, I usually have at least six waking hours before I first seriously think about eating. That’s a lot of productive time. Once you start cutting meals, you start realizing how much time and effort they require. Now mind you, I like to eat, and I like to prepare food. But once or twice a day is plenty.\nI also don’t really experience afternoon slumps anymore. I feel overall much more awake. I have to add the caveat, though, that concomitantly with intermittent fasting I’ve also reduced my carb intake, a lot. Metabolically, the fasted state and the state on a low-carb, high-fat diet are very similar, so it’s hard to distinguish which intervention has caused what.\nBut intermittent fasting is not all unicorns and rainbows. There are a few clear downsides that need to be mentioned. First, it took me probably 6 months to get really comfortable with extended fasts (16+ hours). Initially, there were days when I felt quite hungry, when I was literally looking at the clock waiting for my feeding window to open up. Second, on an intermittent fasting protocol, when you eat, you need to EAT. I usually have two meals a day; hence, each meal needs to be around 1100 Cals or so. (I don’t really keep track, but I estimate that I eat around 2200 Cals a day. Definitely not less, maybe more.) I rarely worry about excess calories when I eat, but I frequently worry about not getting sufficiently many calories. As a regular faster, when you go out to eat with your friends and family, you may find that they think you’ve gone nuts. While they barely finish their chicken breast, you order a couple of appetizers, extra butter for your steak, and some extra sides. And still you leave the restaurant hungry. Third, if you have business or social meal events during your fasting window, you have to decide whether you want to be weird and watch your company eating or rather break your fast. I’ve gotten quite good with just having a black coffee during breakfast events, but depending on your job and social demands, it could be difficult.\nSo, has skipping breakfast made me fat and given me heart disease? Well, I have to admit that I’ve gained about eight pounds over the last year. And I’ve also lost about an inch around my waist. That’s what they mean when they say “improved body composition.” As to heart disease, so far I’m alive and kicking. Of course I can’t promise you that I won’t drop dead from a heart attack tomorrow. I’ll take my chances, though.\n That’s the kind of nonsense that frequently passes for science in the field of nutrition. Not eating breakfast is associated with all sorts of ills, mostly because both skipping breakfast and the associated ills are indicators of a stressful lifestyle and of poor eating habits. There’s absolutely no evidence that skipping breakfast in the context of a well-formulated diet and otherwise healthy lifestyle is harmful. Controlled studies generally find the opposite. For example, skipping breakfast is a simple method to control overall caloric intake.↩︎\n The author of this article is quite a character. But the science is solid.↩︎\n   ","date":1378252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378252800,"objectID":"386bf1f19f5e051e9c5343f8e97ff726","permalink":"/blog/2013/09/04/a-year-without-breakfast/","publishdate":"2013-09-04T00:00:00Z","relpermalink":"/blog/2013/09/04/a-year-without-breakfast/","section":"blog","summary":"No, it's not the most important meal of the day.","tags":["Breakfast","Heart disease","Intermittent fasting","Low-carb diet","Obesity"],"title":"A year without breakfast","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Nutrition"],"content":"  I just learned about this review article that was published earlier this summer in the European Journal of Clinical Nutrition:\n A. Paoli, A. Rubini, J. S. Volek and K. A. Grimaldi. Beyond weight loss: a review of the therapeutic uses of very-low-carbohydrate (ketogenic) diets. European Journal of Clinical Nutrition 67:789–796, 2013; doi:10.1038/ejcn.2013.116\n This is a fantastic article summarizing the current knowledge about ketogenic diets. Read it!\nUpdate: The article lists the following as diseases with strong evidence that ketogenic diets can be beneficial: obesity, cardiovascular disease, Type II diabetes, epilepsy. The article lists the following as diseases with emerging evidence that ketogenic diets can be beneficial: acne, cancer, polycystic ovary syndrome, neurological diseases (e.g. Alzheimer’s).\n","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377993600,"objectID":"d7ea1587330a3566a69d2c4350798f15","permalink":"/blog/2013/09/01/a-review-of-the-therapeutic-uses-of-very-low-carbohydrate-ketogenic-diets/","publishdate":"2013-09-01T00:00:00Z","relpermalink":"/blog/2013/09/01/a-review-of-the-therapeutic-uses-of-very-low-carbohydrate-ketogenic-diets/","section":"blog","summary":"The European Journal of Clinical Nutrition just published a fantastic article summarizing the current knowledge about ketogenic diets.","tags":["Cancer","Diabetes","Heart disease","Ketogenic diet","Low-carb diet"],"title":"A review of the therapeutic uses of very-low-carbohydrate (ketogenic) diets","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  Today is the first day that I am officially Associate Chair of the newly formed Department of Integrative Biology. As I am finding out now, this is the worst calamity that has befallen me in my entire not-so-short life. I have never received that many condolences, that many pitiful looks, or that many expressions of sympathy. After I accepted the position, my predecessor, who is a close collaborator of mine and a mentor to me, told me he was torn between warning me of my impending doom and staying silent so he could be free. He ultimately chose his freedom. Most of the colleagues to whom I mention my new position assume I was coerced, likely at gunpoint. Alas, I actually volunteered for the job. Am I delusional or simply masochistic?\nI may well be delusional, but I’m not masochistic. Fundamentally, I’m curious. I need to understand how things are and how they work. After seven years of teaching undergraduates at a major public university, I still had no clue about the inner workings of undergraduate education. Every year, I was teaching my main undergraduate course, the course I had originally been hired to teach. On top of that, I was teaching a few other things, mostly whatever struck my fancy. I had no idea if that was what was expected of me or not; I had no idea if what I was doing was best for the university or the students; and I certainly had no idea what anybody else was doing. Now, the person who should know all of this is the Associate Chair. It’s his job to coordinate all the teaching, all curriculum-related work, and all budgetary issues related to teaching, with the exception of salaries for tenured and tenure-track faculty members. Therefore, when the opportunity opened up for me to volunteer for that position, I decided to go for it. What better way to learn about a system than being in charge of it?\nNow the thing is, even though my first official day is today, I’ve been de-facto Associate Chair since May. The reason is related to the two innocent words in the first sentence of this post, “newly formed.” We didn’t have a Department until today, we had a Section. The Section was part of the larger School of Biological Sciences, which took care of all teaching-related matters. The reorganization of the School into separate departments has been ongoing since late spring, and all the people who will have leadership roles in the new departments have been hard at work, mostly behind the scenes, to make sure things keep running smoothly. By now, I’ve got a pretty good idea of what it means to be Associate Chair. And I’m not yet ready to shoot myself. We’re good for now. Honestly.\nThe first few months as acting Associate Chair have certainly been interesting. I have learned a lot. For example, much of the upper university administration runs on emailing spreadsheets back and forth. As a strong supporter of version control and online repositories for everything, that was a bit of a shock to me. However, as part of the reorganization we’re trying to put better processes in place wherever we can. We now store the spreadsheets in shared folders.\nI think this is going to be an exciting adventure. The reorganization gives us the opportunity to evaluate every single practice we have followed in the past and ask whether the practice truly serves the students and the college or whether we could do better. By dismantling the behemoth School of Biological Sciences, we’re giving curriculum-related decision making back to the individual departments, closer to the faculty members who are actually standing in the classroom and interacting with students. Yes, this will mean more administrative work for some faculty members. But it should also mean a better experience for the students, who ultimately are the reason we exist in the first place. I’m looking forward to this process, and I’m glad I’ll play a significant role in it.\n","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377993600,"objectID":"8bf8cdd4e5f93fbe1ddfd5ec6640cf20","permalink":"/blog/2013/09/01/my-new-job/","publishdate":"2013-09-01T00:00:00Z","relpermalink":"/blog/2013/09/01/my-new-job/","section":"blog","summary":"I'm dipping my toes into university administration.","tags":["Associate Chair","Integrative Biology","Teaching","Undergraduate education"],"title":"My new job","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  This morning, an article in the Guardian is making the rounds on the academic twitter feeds. The article is written by an anonymous graduate student, and it argues that graduate students are underpaid and that their salaries should be doubled. When reading the article, I couldn’t help but feel that it lacked the careful analysis, logical reasoning, and deep thought befitting of a graduate student. The author is either not aware of or willfully ignores how graduate students are paid and why. I am willing to give the author the benefit of the doubt, though. I recently had a conversation with a senior faculty member at my institution and she also didn’t really understand how graduate students are paid. So here’s the quick summary: per hour, graduate students are compensated better than most postdocs and lecturers. After tenure-track faculty members, graduate students probably get the best deal in academia.\nA few caveats up front: I’m speaking only for natural sciences. Also, I’m speaking primarily for the US system. However, I got my PhD in Germany, and most of what I’m saying here applies to that system as well, as far as I know. I am aware that in absolute terms, graduate student salary is low. I think most professors are aware of this. In fact, our department is currently going through a strategic planning process, and the number one issue identified by our faculty was low graduate student salaries. However, I suspect that most people are thinking about a ~10% increase in graduate student salaries, not a doubling. Finally, I completely agree with this blogger that everybody in academia is underpaid. In fact, when I meet with high-level executives from industry and tell them how much I make, they just stare at me in disbelief. So keep that in mind. Nobody is in academia for the money. With that, let’s have a look at graduate student compensation, let’s consider for what work they actually receive it, and let’s see how it stacks up compared to postdoc and lecturer compensation.\nGraduate students are enrolled in a university degree program. As part of that program, they are expected to take classes and carry out independent study. The independent study component is basically their research program, and the final demonstration that they have completed their independent study is the PhD thesis. Note that none of this effort is compensated in any way. It is a fundamental principle of university education, not just in the US but in most places, that you don’t get paid to participate in a degree program. In fact, in most places you have to pay tuition to do so. In the US, tuition is quite substantial, and ultimately the graduate students are responsible to pay it in full. Now, in most reasonable graduate programs in the natural sciences, graduate students don’t actually pay tuition, and they do receive a stipend. How does this work? One possibility is that students can receive fellowships, but I don’t want to address fellowships here. The more common scenario is that graduate students are being paid as either Teaching Assistants (TAs) or Graduate Research Assistants (GRAs) or a combination of the two. In this scenario, the stipend graduate students receive is for their TA or GRA work. Generally, TA or GRA appointments also come with funds to cover tuition. So on top of their stipend, graduate students receive substantial additional compensation, on the order of $10,000 a year at my institution, and amounting to much higher levels at other schools. Because graduate students are paid for TA or GRA work, not for their studies, TA and GRA appointments are generally half time, 20h per week. I remember, when I did my PhD in Germany, that my GRA appointment contracts always contained a clause to the effect that my supervisor was required to leave me adequate time outside my GRA duties to carry out my own, independent research.\nSo how much do graduate students actually make? Typical salaries are around $2000 per month. Lucky graduate students make a little more, maybe $2200–$2300, while the unlucky ones may make only around $1900. Remember, though, that these amounts are for a 50% time position. If you extrapolate to an annual rate at 100% time, you end up somewhere in the range of $50,000, give or take. Almost no postdoc and very few lecturers make that kind of money. (Postdoc and lecturer salaries are closer to $40,000, and often below that.) And remember, that’s without tuition remission, which goes on top of the salary.\nThus, when graduate students are employed to do research (as GRAs), they are paid more per hour than postdocs are. And when they are employed to teach (as TAs), they are paid more than lecturers are, for a comparable workload. In particular, when a graduate student works as TA for a lecturer, the student makes more money than the lecturer does for that course, even though the lecturer has more responsibilities. (At my institution, one course pays for 33% of the time of a lecturer but for 50% of the time of a TA, and the TA has the higher base rate!)\nGraduate students that work in well-funded labs generally get employed as GRAs rather than TAs, at least a substantial fraction of the time. Strictly speaking, the work they do as GRAs is separate from what they are working on for their degree, but most professors will try to give students work assignments that align with their own research plans. So if you’re a graduate student, are employed as GRA, and have no assignments beyond working on something that will count for your thesis, you’re getting a really good deal. You’re basically given the option to double-dip, to use the same work for both compensation and education.\nNow, as a thought experiment, what would happen if we actually paid graduate students at 100%? It’s simple. Most GRA positions would disappear. Already, if you do the math, you realize that a graduate student and a postdoc are comparable expenses. One year of graduate student salary plus tuition is comparable to one year of postdoc salary, in particular at schools where tuition is high. (As faculty member, if I want to employ a student as GRA, I have to pay the student’s tuition from my grant.) I know many colleagues who say they’d rather hire a postdoc than a graduate student because they get a better deal for their money.1 If you now increased the annual cost of a graduate student by another $22,000, nobody in their right mind would ever hire another graduate student. You’d have to double the salaries of everybody, graduate students, postdocs, lecturers, and professors, to keep some sort of balance among the various compensation levels, and to prevent professors from hiring only postdocs. I’m personally not opposed to doubling the salaries of everybody, but realistically the money is just not there.\nTo summarize: Of all the things we can (and should) worry about in academia, high undergraduate tuition, low funding rates, poor job prospects for postdocs, tenured professors who’ve turned into dead wood, and so on, paying graduate students at 50% effort is the least of my worries.\n Incidentally, in computer science it’s the other way round. Because most PhDs in computer science can go to industry and make a lot of money, postdocs can command a much higher level of compensation in that field, and hence professors are more likely to hire graduate students than postdocs.↩︎\n   ","date":1377907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377907200,"objectID":"42936a39ef227709b22a84cdc862e229","permalink":"/blog/2013/08/31/atqeelrnfeyb3e03sycsdpl7p5zc83/","publishdate":"2013-08-31T00:00:00Z","relpermalink":"/blog/2013/08/31/atqeelrnfeyb3e03sycsdpl7p5zc83/","section":"blog","summary":"In terms of dollars per hour, graduate student pay is surprisingly high.","tags":["Compensation","Graduate school","Percent effort","Postdocs"],"title":"Why graduate students get a reasonable deal—A response to the anonymous grad student in the Guardian","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  When I was growing up, computers were a still a pretty unusual thing. As a result, people could generally be subdivided into two types: those that knew their way around computers and those that didn’t. The ones that knew their way around computers really knew things, often down to the hardware level. (I had a book listing the entire operating system of my Commodore, in machine language.) The others pretty much knew nothing, and they knew that they knew nothing. So the world was in order. Everybody knew their place. These days, computers are ubiquitous. Everybody and their dog knows how to fill out a web form or install an app. Yet unless we venture beyond the shiny interfaces provided by the Microsofts, Apples, and Googles of this world we remain just as illiterate as the earlier generation. We just don’t know how much we don’t know.\nWhat prompted me to write this post? At my university, I have the pleasure of using email service provided through Microsoft’s new Office365. And yesterday, I made the mistake of trying their email filtering solution. My goal was a simple one: Set up an email filter that takes all replies (but not original posts!) to a certain mailing list and moves those messages into a special folder. You should know that all messages to the list are tagged with a unique identifier, something like “[list-X]”, so it’s easy enough to find those messages. But how do we know a message is a reply, not an original post? Well, for original posts, “[list-X]” appears at the beginning of the subject line. For replies, the subject line usually begins with “Re: [list-X]” or “RE: [list-X]” or maybe even “Aw: [list-X]” (the latter happens if somebody is using an email program in the German language). So original posts and replies are easy enough to tell apart. All we have to do is create a filter rule that captures all posts whose subject contains, but doesn’t begin with, the tag “[list-X]”. How hard could that be?\nWell, in Office365, this is a problem of infinite difficulty. It cannot be done. You can filter by sender, you can filter by receiver, you can filter by keywords in the subject line, but you cannot filter for specific sequences of words, and you cannot filter for words that do appear in the subject line but not at the beginning. Now, if you’re a modern-day computer illiterate, you may think: “Well, of course Microsoft programmers couldn’t include a separate option for any random combination of conditions somebody could come up with. They have to make reasonable selection among common cases, and there’s just no way around that.” If this is your thinking, then what you do not know is that computer scientists have long had a simple solution to this problem, a solution called “regular expression.” (If you’ve never heard of regular expressions, look them up. They are super powerful. They are the computing equivalent of a swiss army knife, a chain saw, and a pickup truck all in one.) All Microsoft would have to do is add one more option, “filter by regular expression,” and I could create the most spectacular filtering rules. And this option is trivial to implement. It would take a skilled programmer about an afternoon to add. Likely, the underlying filtering software in Office365 already employs regular expressions, so all that Microsoft programmers would have to do is allow me to access that software layer directly. But they don’t, and so I can’t.\nNow, why don’t they add an option that would be tremendously useful and trivial to add? There are two possible interpretation. It’s either because they don’t want to scare us (benign interpretation) or because they don’t want us to be in control of our computers (malicious interpretation). Whatever the reason, the outcome is the same. If all you know is the polished user interface of consumer software, you’ll know computers as magical contraptions that can do incredible things, as long as somebody has thought of the things you might want to do. If you want to do something different, though, something unconventional, then that’s usually not possible, as far as you know. I suspect that if you have grown up in this environment, you don’t even know what it is you can’t do. You have no good mental model of the underlying technology, so you don’t know what should be easy and what might be difficult. Dumbed-down consumer software keeps you ignorant of the true power of computing technology.\nA conspiracy theorist might pose that this is done on purpose. If you don’t really understand how computers work and what they are capable of, you don’t realize how easy it would be to, for example, take the metadata1 of your phone and text messages and figure out with whom you’re likely having an affair. I don’t really believe in massive conspiracies, though, so I think the more likely explanation is that in the effort of making software simple and accessible to all, it’s often easier and less work to simply hide the true underlying capabilities. Either way, the end result is the same. Plenty of people who think they know how to use computers but really they don’t.\nAs to Office365, I’ll file a bug report. Fat chance they’ll act on it.\n Metadata in this case means call and text records, but without their content. Basically a list of who did you call when, who called you, who did you text, and who texted you.↩︎\n   ","date":1377820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377820800,"objectID":"5c2c62b3818d0c7a827ca9dbcbc8315a","permalink":"/blog/2013/08/30/is-consumer-software-creating-a-new-generation-of-computer-illiterates/","publishdate":"2013-08-30T00:00:00Z","relpermalink":"/blog/2013/08/30/is-consumer-software-creating-a-new-generation-of-computer-illiterates/","section":"blog","summary":"Let's dumb down this software even further.","tags":["Computer illiteracy","Computing","Office365","Programming","Software"],"title":"Is consumer software creating a new generation of computer illiterates?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  Writing is hard. But writing a scientific paper? Much less so. That’s because nearly all scientific papers follow a simple, four-section outline: Introduction, Methods, Results, Discussion. Just put the required information into those four sections and you’re done.\nIntroduction The Introduction sets the stage. It explains the scientific question, why the question is interesting, and what you have done to address the question. Many papers have never-ending Introductions, but frankly I doubt anybody actually wants to read a paper with a long Introduction. In my mind, an introduction requires only three paragraphs: A first paragraph introducing the broad topic and explaining why it is interesting. A second paragraph describing a specific gap in knowledge or unsolved problem. And a third paragraph explaining how your work attempts to close the gap or solve the problem. Done.\n Methods The methods need to describe in detail what experiments you have done, what analyses you carried out, and so on. There’s little to be said about Methods, other than that most Methods are actually too short. It’s a lot of work to describe everything you’ve done in exquisite detail, so most people get lazy at some point and leave something out. I’d encourage you to be as detailed as possible with your Methods.\nIn terms of actually writing and structuring the methods, it’s a good idea to group related methods into subsections. An example could be: Experimental protocol; Sequencing; Data analysis; Modeling.\n Results The Results are the heart of the paper. There’s no research paper without Results. I like to approach Results from the figures and tables. Think about which figures and tables you want to present, then write a paragraph for each. Each paragraph should start with a brief explanation of what you did and why, and then it should present the actual results.\nFor example, a Results paragraph could read:\n To determine whether lions can thrive on a vegetarian diet, we raised 10 captive-bred lion cubs on tofu burgers. As control, we raised a second group of 10 cubs on raw beef. We monitored body weight and size, activity level, fur shininess, and health of each cub for a time period of three months. We found that vegetarian-raised cubs grew slower and had a lower overall weight increase over three months (t-test, P = 0.002). Surprisingly, diet did not affect fur shininess (t-test, P = 0.15).\n Notice how the first three sentences describe the question and briefly outline the experiment, while the subsequent two sentences describe the actual results. The next following paragraph in the Results should now raise another question and answer it.\n Discussion The Discussion will generally need at least 4-5 paragraphs, and will likely grow a few paragraphs after you have addressed the referee reports. While the Discussion is probably the hardest part to write, there’s a simple structure to a typical Discussion that makes things easier.\nThe first paragraph in the Discussion should summarize the Results. Most readers will read the Abstract, maybe the Introduction, and then the Discussion. Write the Discussion as if it were the first thing your readers saw.\nThen you need 2-3 paragraphs placing your results into a broader context. What does your work mean for the major question described in the Introduction? Also, how does your work relate to other work in the field? What specifically are the similarities and differences?\nNow you need at least 1-2 paragraphs pointing out some potential drawbacks of your work. Every work has potential drawbacks, or at least limiting assumptions. List specific conditions under which your conclusions might be invalid, or assumptions you made that may not be true. As reviewers read your paper, they will assemble in their mind a list of potential drawbacks they’re going to call you out on. To the extent that you’ve already addressed their concerns in your manuscript, you’ll have an easier time in review.\nFinally, and this is somewhat optional, you can write another paragraph that summarizes all your findings once more. Many papers have such a concluding paragraph, but it can feel redundant if you opened the Discussion with a strong summary paragraph, in particular if your Discussion isn’t that long. I’d say use good judgement on whether you need the closing paragraph or not. In case of doubt, write it, and see how the paper flows with or without this paragraph.\n Results, Methods, Discussion, Introduction While the order of the sections in the paper is going to be Introduction, Methods, Results, Discussion (or possibly Introduction, Results, Discussion, Methods), you shouldn’t write the paper in that order. That would be backwards. There’s no paper without Results, therefore you should write Results first, possibly in parallel with Methods. Once you have Results and Methods, you can start writing the Discussion. Only once you have a pretty good draft of Results through Discussion should you start working on the Introduction. If the Introduction is the last major section that is missing, it will write itself, I promise. In particular if you keep it to three paragraphs.\nI haven’t talked about the abstract yet. The abstract should be a mix of the first two paragraphs of the Introduction and the first paragraph of the Discussion. Write the abstract at the very end, when everything else is done.\n Length There’s no minimum length to a scientific paper. In general, I’d say scientists are more likely to write papers that are too long than papers that are too short. I would recommend not to worry about insufficient length at all (but do worry about excessive length). If you’ve got all the elements I’ve discussed here, and your paper is 3 pages long, great. Send it out! Also, 3-6 figures and tables total is a good number. If you’re way beyond 10, you need to cut or move stuff to the supplement. A paper that is too long will not be read, regardless of how good it is. Honestly. Just cut it down.\n ","date":1377734400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377734400,"objectID":"f76dd4431c37aaa8b151e500df930e3b","permalink":"/blog/2013/08/29/writing-a-scientific-paper-in-four-easy-steps/","publishdate":"2013-08-29T00:00:00Z","relpermalink":"/blog/2013/08/29/writing-a-scientific-paper-in-four-easy-steps/","section":"blog","summary":"Nearly all scientific papers have the same standard outline.","tags":["Academic writing"],"title":"Writing a scientific paper in four easy steps","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  In my experience, most graduate students and many postdocs think of science as a two-step process: First, you do science. You do experiments, collect data, write code, carry out statistical analyses. Then, once you’re done doing science, you sit down and write up your results for publication. Within this mental model, an important question arises: How do you know that you have done enough science? When should you stop collecting data and start writing a paper?\nI’ve seen plenty of graduate students struggle with getting papers out because they can’t convince themselves that they have done enough science and are ready to start writing. There’s always another experiment to be done, another analysis to be run. In my opinion, the fundamental issue here is not that these students have difficulty judging when they have done sufficient work. The real issue is that the mental model of science as a two-step process is flawed. Realistically, you will never have done so much science that there is nothing else to do. And at the same time, even if you think you have a complete story, you almost never do. Anybody who has written at least a few papers will have experienced the situation where, as you’re making your case for one conclusion or another, you realize that you could make this case that much stronger with another experiment, or at least another analysis. What happens then is that you go back into the lab, do the work, and subsequently use the additional results to write an improved manuscript draft.\nTherefore, in my mind, the question “when should you stop doing science and start writing a paper” is ill-conceived. Doing science and writing about it are two sides of the same coin. They should happen at the same time. In my mind, there is an obvious simpler question, and it has a simple answer. The simpler question is “when should you start writing a paper?” The answer to this question, in my mind, is “as soon as you have at least one result.” As soon as you have a result, you can write it up. Make a figure, add a caption, write an explanatory paragraph or two, and put it into a document section titled “Results.” Place a brief outline of the methods used into an accompanying section titled “Methods.” As you keep doing more science, keep adding your results to the document, and see how the story unfolds. If there are obvious gaps, think about the work you need to do to fill them. Once you think that you have a reasonable story, all you have to do is add an introduction and a discussion and you’re done writing your paper. Submit.\n","date":1377475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377475200,"objectID":"f22682b768d848bf2681bf39a6f61b7e","permalink":"/blog/2013/08/26/when-should-you-stop-doing-science-and-start-writing-a-paper/","publishdate":"2013-08-26T00:00:00Z","relpermalink":"/blog/2013/08/26/when-should-you-stop-doing-science-and-start-writing-a-paper/","section":"blog","summary":"Start writing as soon as you have at least one result.","tags":["Academic writing","Science"],"title":"When should you stop doing science and start writing a paper?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Fitness","Nutrition"],"content":"  The scientific consensus is that long-term weight loss and weight control is impossible. Yet some people seem to manage. So what gives? The truth is, nobody knows. The science of nutrition and weight loss is still recovering from 40 years of collective delusion, and frankly most scientific studies in this field are not that insightful. (I do have high hopes, though, that the Nutrition Science Initiative is going to be a game changer. Some of the smartest people in the field, with access to very substantial private funding, should make a difference.) In the absence of solid science, I feel that I can freely speculate about why some people succeed and others don’t. So what follows below are my own opinions, poorly sourced and not scientifically proven.\nThere are about six distinct approaches to weight loss (not necessarily mutually exclusive), and people have succeeded and failed on all of them: calorie counting, exercise, low-fat diets, low-carb diets, ancestral diets (paleo, primal), and intermittent fasting. The only thing that everybody seems to be able to agree on is that a low-protein diet (less than 0.7 grams of protein per pound of lean body mass per day) is not a good idea.\nNote that I’m following general convention here and talk about weight loss, even though we should really be talking about fat loss. There’s no reason to believe that muscle loss is good for anybody under any circumstances. Also note that I’m not considering surgery or drug-assisted methods for weight loss. (Yes, you can get ripped on tren and clen. And no, I wouldn’t do it.) I’m also not discussing serious medical issues that would prevent weight loss, such as insulinoma or leptin deficiency.\nSo let’s consider the advantages and disadvantages of the six weight-loss approaches:\nCalorie counting. Calorie counting absolutely works. If you meticulously keep track of everything you eat, and you make sure you eat at a consistent deficit of at least a few hundred calories a day, you will lose weight. However, there are a number of downsides: First, you have to be meticulous about keeping track, to the extent of weighing all your food. This requires an OCD-level of attention to your food intake. Second, as you restrict your food intake, you may feel low on energy, moody, or develop headaches. Third, long-term caloric restriction can mess up your leptin levels and your thyroid, and then you’ll need regular diet breaks to fix these issues, another level of complication.\n Exercise. Conventional wisdom says that you need to exercise to lose weight. Yet the consensus these days, both among scientists and among fitness experts, is that exercise is a poor tool for weight loss. You generally can’t out-exercise a poor diet. I’ve seen estimates that maybe 5% of the population will be able to lose weight primarily through exercise and the remaining 95% will not. This statistic is easily verified in any gym, where you’ll find plenty of people that are fit, strong, and also overweight. My heart breaks everytime I see an obese person struggling on the treadmill or the elliptical. These people have seriously gotten the wrong advice. They’d be much better off fixing their diet and hanging out on the sofa in front of the TV than wasting their willpower on pointless exercise while keeping poor dietary habits.1\n Low-fat diets. Low-fat diets are the diets we’ve been told for years we should follow to lose weight. They are supported by people like Ornish, who has demonstrated remarkable health improvements in people on his diet. (In this context, it’s important to realize that Ornish has only ever compared his diet to the standard American diet full of refined carbohydrates and soft-drinks. There’s no evidence whatsoever that Ornish’s diet performs better than other well-formulated, healthy diets.) There can be no doubt that low-fat diets can work. Some people do really well on those diets. Yet many others do not. And if you’re an adult male, and care about your testosterone levels, you might stay clear of these diets because they lower testosterone levels.\n Low-carb diets. Low-carb diets, aka the Atkins diet, have been extremely polarizing ever since Atkins wrote his first book. For the longest time, we’ve heard that the Atkins diet will clog your arteries and cause heart disease. At the same time, a few daring individuals tried it out and found they lost a lot of weight. Careful review of the scientific evidence shows that well-formulated low-carb diets are perfectly healthy, and I suspect that most obese people will do very well on low-carb diets. Major downsides of low-carb diets are (i) poor societal acceptance; you’re constantly swimming against the stream; (ii) a 3-4 week induction phase during which you may feel miserable; (iii) reduced thyroid function and low leptin, which may require targeted carbohydrate refeeds to address. Also, while low-carb diets sometimes seem to work like miracles for very obese people, they are not a weight-loss panacea. In particular, to reach extreme levels of leanness it may be necessary to up the carbohydrate intake.\n Ancestral diets (paleo, primal). Ancestral diets are primarily about food quality. While many people are hung up on the name “paleo,” these diets fundamentally boil down to the recommendation to avoid highly processed foods and foods that make you sick. I don’t see how anybody can take issue with these recommendations. I personally am a big fan of paleo diets, in particular Mark Sisson’s primal approach to food. At the same time, it must be said that just going paleo does not guarantee weight loss. In particular, if you knock yourself out on paleo desserts (e.g. banana-coconut smoothie, blueberry paleo ice cream, paleo muffins) you may find that the scales don’t move quite as much as you might have hoped.\n Intermittent fasting. Intermittent fasting is the latest weight-loss craze. What it boils down to is skipping meals on a regular basis. For example, you could never eat breakfast, or you could eat only one meal a day, or you could eat only every other day. At this time, it’s not very well understood how to best fast intermittently, and whether the exact fasting schedule makes a difference. However, there can be no doubt that some people derive impressive results from intermittent fasting. The science on intermittent fasting is still in its infancy, and we don’t really know whether the results are mostly due to inadvertend caloric restriction (it’s hard to overeat if you eat only 1-2 times a day) or due to actual hormonal changes, e.g. improved insulin sensitivity. But one thing seems pretty clear: skipping breakfast is not bad for you, despite what you will read in Cosmopolitan or Men’s Health.\n  The one thing I’m absolutely convinced of is that there’s not one best approach to weight loss. We all have different genetics, different personalities, and different societal pressures, that all affect which approaches may or may not work for us. Some people may do really well on calorie counting while others could never maintain the required discipline. Some people are really happy on low-carb, high-fat diets while others get grossed out by the amount of fat you have to consume on such diets. However, all approaches have in common that they require some amount of discipline; I’m not aware of any diet on which you can eat unlimited amounts of cookies. So it’s important to find an approach that works for you, and that you can stick with in the long run, with relative ease and consistency.\nI’m also convinced that short-term dieting is pretty pointless, unless you’re a bodybuilder or figure model getting ready for stage. You need to find an approach to eating (i.e., a diet) that you can maintain long-term, without thinking much about it. You should never think of diet as something you do for a few weeks to lose weight and then you stop. Diet is how you eat, every day, for the rest of your life. And if your diet doesn’t give you satisfaction, see if you can change it to something better. If I had to be on the Ornish diet, I’d feel like I’m eating sadness every day. By contrast, on my mostly low-carb, mostly paleo diet, I’m eating plenty of meat, eggs, fish, butter, cream, spinach (I love spinach), nuts, and dark chocolate, and I rarely if ever eat anything I’m not absolutely excited about.\nFinally, I believe that diet success largely depends on how well we can access the fuel stored as fat on our bodies. Approaches such as low-carb dieting, paleo, and intermittent fasting all create hormonal environments that increase metabolic flexibility and make it easier to use body fat for energy. The same hormonal changes may happen for those people who are successful on calorie-counting diets or extensive exercise, but not for those who fail on those approaches. Think about it as follows: Why is anybody ever hungry? One pound of fat contains roughly 3600 Calories, more than sufficient fuel for an entire day for most people. And very few people don’t carry at least a few pounds of extra fat on them. So why would they be hungry multiple times a day, clearly before those energy reserves have been used up? When we’re hungry, there is hormonal signaling that tells us we need to refuel, even though objectively we don’t. The more we can manipulate our body to suppress this hormonal signaling, the leaner we will be without experiencing discomfort.\n I’m not saying here that exercise is pointless. Exercise has a lot of benefits, it’s just not very useful for weight loss. Also, an obese person already gets plenty of exercise just by carrying around all the extra weight they do. Immagine strapping a backpack weighing 50 or 100 lb onto your back and walking around with it all day. That would be plenty of exercise, wouldn’t it? I think that for any person who is seriously overweight, the right strategy has to be to first lose weight purely by diet, and then start exercising once a normal weight range has been reached.↩︎\n   ","date":1377388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377388800,"objectID":"3d150272fd7a90ebaa53d4c5dce9dd20","permalink":"/blog/2013/08/25/the-great-weight-loss-mystery/","publishdate":"2013-08-25T00:00:00Z","relpermalink":"/blog/2013/08/25/the-great-weight-loss-mystery/","section":"blog","summary":"Short-term dieting is pointless.","tags":["Fat loss","Intermittent fasting","Low-carb diet","Low-fat diet","Paleo diet","Weight loss"],"title":"The great weight-loss mystery","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  Today’s advice is written specifically for undergraduates, even though graduate students and postdocs may benefit as well. (I certainly didn’t figure these things out until I was a faculty member myself.) What is the best way to approach professors by email, in particular if you want or need something from them? I’ll give you the most important advice up front: Be absolutely clear about your intentions. Tell me exactly what you want or need from me, and why. This will save both of us a lot of time, energy, and frustration. (Frustration would be mostly on your part, though, when I silently ignore your messages.)\nAs a professor, I am constantly being inundated with requests, propositions, recommendations, and demands. And most of them fall into the category of spam, or at least not very high on my priority list. Almost daily, I receive requests from people who would like to join my “esteemed laboratory.” They usually come from overseas, sport a long list of qualifications in the latest experimental techniques, and seem to have no knowledge of the fact that my lab is entirely computational (it says so right on our homepage). I’m also constantly asked if I want to participate in this or that activity, survey, or committee. (Do I want to be on the university committee that decides on the color of the men’s changing room in the new gym? No.) Over time, I’ve gotten quite good at deleting or at least ignoring these emails. Usually, I don’t need to read past the first or second sentence before I send the message to the circular filing cabinet. If you want to reach me, you have to somehow make it through that noise. Your message has to be clearly different.\nNow, reaching me through this noise may seem a daunting task, but it’s actually not that bad. The truth is, I want to interact with you, I truly do. For example, I have over 10 people in my lab, from undergrads to senior scientists, and almost all of them got there by sending me an email at some point. They all got through to me. In order for me to be able to help you, though, to consider your request, I need you to help me. I need you to be crystal clear in what you need or want. Do you need to see me before Friday because you want to drop my class before the deadline? Say so. I’m not going to chew off your head. (An aside: Students seem to be extremely shy about requesting a drop. I really don’t care. If you want out of my class, I won’t be in your way.) Would you like to meet me because you’d like to work in my laboratory? Say so. If you’re an undergrad, say whether you are looking for a paid job or are willing to volunteer/work for course credit. If you’re a graduate student, tell me why you are interested in my lab and what topics you’d like to work on. In general, the more clearly you can spell out what it is you want from me, the quicker I can decide whether I can be of help or not. And if I receive a clear, well-formulated request that I have to deny, I’ll generally respond quickly with a “no,” and possibly with suggestions where else you could go. By contrast, I’ll generally just ignore or delete any messages whose intent is not clear to me.\nIf you would like to request a meeting with me, please suggest possible times that would work for you. Don’t just write “I would like to meet with you.” Write “I would like to meet with you. I’m available this week Wed. before noon or Thurs. after 2pm.” This saves us one round trip, because I can immediately suggest a time that might work for both of us.\nFinally, if I ignore your message, don’t take it as a “no,” try again. I may simply have overlooked it. Or I may have had the best of intentions to respond to you, but then I got distracted by something, then I had to teach a class, and by the time I was back in my office your email was long forgotten. So if I don’t respond to your message, send me another one the next day, or maybe two days later. In general, I think you should try at least 2-3 times before you conclude that your message is being actively ignored.\nUpdate: I wanted to add some thoughts about how to address professors in email. If you’re an undergrad, I think you should write “Dear Dr.” + last name. In my case, that would be “Dear Dr. Wilke.” If you’re a graduate student or postdoc in my department, first-name basis is fine, so “Dear Claus” or just “Claus.” If you’re a graduate student or postdoc at a different institution, I think the formal “Dear Dr. …” is the better option, in particular if we’ve never had any interactions before. (If we hung out at a conference over a beer and talked until 2am about everybody and their dog, “Claus” is probably fine.) If you choose the formal address, pay attention to the response. If the response is signed just with a first name, you can assume you’re on first-name basis from there on out.\n","date":1377216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377216000,"objectID":"5bf7c3e2794366d33165db5a7df37f70","permalink":"/blog/2013/08/23/how-to-approach-professors-by-email/","publishdate":"2013-08-23T00:00:00Z","relpermalink":"/blog/2013/08/23/how-to-approach-professors-by-email/","section":"blog","summary":"State clearly what you want or need.","tags":["Email etiquette","Graduate school","Postdocs","Undergraduates"],"title":"How to approach professors by email","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Academia"],"content":"  At this year’s BEACON Congress, we had undergraduate lightning talks. One student, three slides, five minutes. Next. I rather enjoyed this session. In my mind, some of the most engaging talks of that conference happened in that session. (And I’m not saying this just because my student Dariya won an award for best science presented.) This got me thinking. Maybe we should institute lightning talks more commonly at conferences. And not just for undergraduates, for everybody.\nThe beauty of the lighting talk is that presenters have to focus meticulously on the most relevant aspects of their work. And the good presenters absolutely manage to do that. They get their story across in three slides no problems. As expected, the bad presenters don’t. However, they wouldn’t do well with more time either, and at least a bad lightning talk is over quickly. Normally, a talk that bores you to death would continue on for twenty minutes or more, up to, God forbid, an entire hour if it’s a keynote speaker.\nSo here is my proposition: We should make lightning talks a more common feature of scientific conferences. Don’t just have lightning-talk sessions for undergraduates, also have them for more senior scientists (yes, up to and including established principal investigators). This would allow more people to present their work, and at the same time it would generate more opportunities for one-on-one interactions.\nSpecifically, I’d like to suggest the following. Consider a regular afternoon session at a conference, 2pm to 6pm, with two parallel tracks. Let’s assume 10 talks per track (approx. 20 minutes per talk plus one or two short coffee breaks). That’s 20 talks during the afternoon, of which any given conference attendee can see at most 10. I’d replace those two parallel tracks with a single track of lightning talks combined with associated poster sessions for the people who just presented. E.g., 2pm–2:50pm, 10 speakers give their lightning talks. 2:50pm–4pm, the same 10 speakers present their posters. 4pm–4:50pm, another 10 speakers give their lightning talks. 4:50pm–6pm, the second 10 speakers present their posters.\nDo I think that all talks at conferences should be replaced by lightning talks? Probably not. (Even though I’m tempted to say yes, my tolerance for boring or poorly presented talks is pretty low.) However, a good mix of invited keynote talks, regular 20 minute talks, and lightning talks would probably make for a very exciting and dynamic conference. I hope somebody tries this out. If you do, please invite me!\n","date":1377129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377129600,"objectID":"804bb985c5620bd772d3ca7ad2f90aac","permalink":"/blog/2013/08/22/a-call-for-lightning-talks-at-scientific-conferences/","publishdate":"2013-08-22T00:00:00Z","relpermalink":"/blog/2013/08/22/a-call-for-lightning-talks-at-scientific-conferences/","section":"blog","summary":"Short talks can be incredibly exciting. And when they're not, at least they're over soon.","tags":["Conferences","Presentations"],"title":"A call for lightning talks at scientific conferences","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  Prezi is all the rage lately. It seems everybody and their dog is switching over to prezi for presentations. My twitter stream has more prezis than it has powerpoints, keynotes, openoffices, or whatever else people use to make presentations. (Latex beamer? Please don’t tell me you use latex beamer.) Just last week, I gave a presentation on giving engaging presentations, and one of the first questions I received afterwards was what I thought about prezi. In my opinion, everything I said in my talk applied to prezi just the same as it did to powerpoint.\nIt seems that people think prezi will magically make their presentations wonderful. Well, I’ve got news for you: it won’t. If you don’t have a story, prezi won’t help you. If you tell your story backwards, prezi won’t help you. If you have no stage presence, prezi won’t help you. If your slide design is atrocious, prezi won’t help you. If you fill your slides with text you don’t read out aloud, prezi won’t help you. Moreover, prezi gives you the unique new power of making your audience seasick.\nSo what’s the deal with prezi, what problems does it cause, and how could we use the prezi paradigm to make great presentations? The unique feature that distinguishes prezi from most other presentation software is that instead of individual slides that you flip through you have one large canvas on which you can pan, rotate, and zoom. This allows for some really cool effects that are not possible with any other presentation software, but it also adds a whole new level of complexity. Essentially, to make the most of prezi, you need to have some knowledge about videography. Very few people fit that bill and are sought-after public speakers.\nSpecifically, the two main issues with the prezis I’ve seen are:\nUnexpected and excessive camera movement. The whole presentation can feel like a roller-coaster ride. You never know what’s next, but for sure it’s going to be some serious flying over the canvas. Experienced videographers know that excessive panning and zooming is disturbing, but apparently this info has not yet filtered through to the typical prezi user.\n Distracting and mysterious previews of the material to come. Prezi encourages a slide design where the contents of the next slide is visible in the present slide, albeit scaled down to a really small size. I think that’s a bad idea, because it distracts the audience. Every time I see a prezi, I start wondering which element of the current slide we’ll zoom to next. Can I find the hidden text in the current slide? Needless to say, while I’m having these thoughts, I’ve stopped listening to the speaker, and I’ll probably miss most of the salient points in the presentation.\n  I’ve thought a bit about how one could work around those issues, and I’ve come up with the following design concepts. This list is not exclusive; there are almost certainly other really cool ways to make prezi work. I just don’t have enough imagination to dream them up myself.\nInfinite pan: Just choose one direction (up, down, left, right, whatever you prefer) and keep panning in that direction. Simple, predictable, boring. But it will not detract from your presentation. And that’s a good thing! Astute readers will of course have noticed that the infinite pan effect can also be achieved with transition effects in powerpoint or keynote.\nInfinite zoom out: Start at the highest zoom level and add new material by zooming out further and further. The previous material will appear as a trail of little specks after a while. This might be a pretty cool effect.\nInfinite zoom in: Like the infinite zoom out but in reverse. Start at the lowest zoom level (where you can see the entire canvas at once) and keep zooming in. This effect has the disadvantage that it can cause the audience to speculate about what’s going to come next, so I wouldn’t use it. But otherwise it’s sufficiently predictable that’s it’s probably a reasonable choice.\nIn general, just choose a consistent movement pattern for your camera and stick to it. Also, make use of prezi’s ability to make things appear in the current viewport. If you have a slide with a title and three bullet points, I think you should zoom/pan/rotate to the appropriate viewport containing only the title. Then, the bullet points should appear one by one as you go over them, but without further movement of the camera.\nFinally, I wish prezi added the possibility to swap canvases during the presentation. If it had that feature, it would have the best of both worlds. One could do regular powerpoint presentations (each new slide is a new canvas), pure prezi-style presentations (each new slide is just a different viewport on the same canvas), and hybrids (e.g., a different canvas is used for different major parts of the presentation). I suspect that some clever people could make really cool presentations with a system that allows for the hybrid design.\nIf you have a prezi that you think makes intelligent use of prezi’s paradigm, and that doesn’t have the issues I outlined above (disorienting movements and/or mysterious previews of things to come), please share that prezi with me. I’d like to be able to say that I’ve seen a great prezi.\n","date":1377043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377043200,"objectID":"eba4c4182b8ce81e3589accb08e9aca9","permalink":"/blog/2013/08/21/my-gripes-with-prezis-and-some-suggestions-for-making-good-prezi-presentations/","publishdate":"2013-08-21T00:00:00Z","relpermalink":"/blog/2013/08/21/my-gripes-with-prezis-and-some-suggestions-for-making-good-prezi-presentations/","section":"blog","summary":"Please don't make me seasick.","tags":["Slide design","Powerpoint","Presentations","Prezi","Public speaking"],"title":"My gripes with prezi, and some suggestions for making good prezi presentations","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  Mention LinkedIn, and you generally get two types of responses. Either you will hear that LinkedIn is the most important invention in the search for jobs since the invention of the printed resume, or you will hear that LinkedIn is completely irrelevant and that you shouldn’t waste your time with it. In my mind, there is no doubt that LinkedIn plays an important role in connecting people with new employment opportunities in the business world. For example, I know some people here in Austin who run a successful recruiting company, and they operate almost entirely on LinkedIn. If you don’t have a LinkedIn profile, you’re basically invisible to them. (Did I mention that they generally look for candidates with advanced knowledge in data analysis, visualization, and statistics, basically the exact kind of person my lab trains?) However, things are different in academia. I don’t know of a single faculty member who got her job through LinkedIn, and I doubt I’ll hear about such a case any time soon.\nSo should you, as a scientist, spend valuable time polishing your LinkedIn profile and connecting with people on the site? In my opinion, the answer is absolutely “yes”, and I’ll explain below why I think so. I will separately address two different groups of people, scientists in training (undergraduate, graduate student, postdoc) and faculty members.\nScientists in training As a scientist in training, the most important thing you have to realize is that it is by no means certain that you will end up in academia. In fact, most graduate students and even many postdocs will never become faculty members. And that is not a problem, in and of itself. Not everybody needs to become a professor. As long as our graduates find appropriate, satisfying, and well compensated employment, the world is in order. But what this means to you, as scientist in training, is that until you sign that offer letter for a tenure track position, you need to be open to alternative options. Building a solid LinkedIn profile and network may just provide you with the ticket to alternative career options.\nAlso, do not underestimate the value of the connections you build early in your career. If you go to a top university and/or generally hang out with smart kids, I can guarantee you that the majority of your current friends, however inconspicuous they may appear, will go on and make something of themselves. Check back where they are ten to fifteen years from now, and you’ll be impressed. (If you don’t generally hang out with smart kids: what’s wrong with you?) The dude from across the hall that you always met in the gym may just have gotten tenure at Harvard. The girl who was two years ahead of you in graduate school may just have gone through the IPO of the company she founded after graduating. And the hottie you had a fleeting crush on when you attended your first conference as an undergraduate may now be on the committee that is considering hiring you for your next job. So take networking seriously, even as a lowly undergraduate. You never know who you will want to contact again ten years down the road, or who will become important to your career at some point in the future.\n Faculty members For faculty members, using LinkedIn is probably less about the next job opportunity. Notwithstanding people who don’t get tenure, and notwithstanding people who leave academia to work at Google or at D. E. Shaw, or to found their own company, the general rule is “once a faculty member, always a faculty member.” For faculty members, I believe the value of LinkedIn is in the network which they can provide their students access to. As a faculty member, if you have done your job right, you should have a solid network of influential and successful people, not all in academia. You should be connected to former students or colleagues who have left academia to work in industry. You should also be connected to people in industry you have met at social events. So when one of your students approaches you about alternative career paths, you should be able to put that student in contact with the right people.\nAs an example, I recently had a student in my lab who was interested in consulting. Through LinkedIn, I was able to connect that student to two people who have successful careers in consulting. One of the two was a graduate student at Caltech while I was a postdoc there. The other was the husband of a former coworker of my wife. Without LinkedIn, I would not have known how to get in touch with either of them. (An observation that may come as a bit of a surprise to academics: not everybody can be found through a simple Google search of their name. In fact, most people can not be found through a Google search.)\n Concluding thoughts Is LinkedIn the be all of professional networking? Probably not. Do you absolutely need to have an active, up-to-date LinkedIn profile to be successful as a scientist? Almost certainly not. Nevertheless, there are tangible benefits to keeping your LinkedIn profile active, so I think it’s worth it. And let’s be real, updating your LinkedIn profile doesn’t take a lot of time. With the time it took me to write this blog post, I can keep my LinkedIn profile updated for the next several years.\nFinally, because we academics need contacts outside academia, and because people move back and forth (maybe more forth than back) between academia and industry, I think that social networking sites geared specifically to scientists, such as ResearchGate, are not particularly attractive. These sites generate an artificial distinction between scientists and other people when reality is more fluid.\nYou can find my LinkedIn profile here: Claus Wilke on LinkedIn. Connect with me if we’ve ever had a meaningful professional (or social) interaction.\n ","date":1376956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376956800,"objectID":"4fe56080d3d0de1fd757da56b5570e18","permalink":"/blog/2013/08/20/should-you-as-a-scientist-be-active-on-linkedin/","publishdate":"2013-08-20T00:00:00Z","relpermalink":"/blog/2013/08/20/should-you-as-a-scientist-be-active-on-linkedin/","section":"blog","summary":"Networking is important.","tags":["Industry","Linkedin","Professional networking","Social networking"],"title":"Should you as a scientist be active on LinkedIn?","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Miscellaneous"],"content":"  I’ve finally broken down. I’ve made a Twitter account. For years, I tried to hold off, thinking that Twitter was something for a younger generation, with a better stomach for cryptic text messages. The typical Twitter conversation is such a random stream of letters and special characters, made up of usernames, hashtags, and abbreviations of regular words, that it makes the winning entry of an obsfucated perl contest look outright legible. My thinking was that I gave up on perl for a reason. Why should I subject myself to Twitter? Anyway, this weekend I broke down and made a Twitter account. And I have to admit that it has its uses. While I don’t see myself doing long conversations over Twitter any time soon, I can see how it excels at disseminating and sharing information.\nHowever, now that I’m exploring Twitter, I’m experiencing an entirely novel form of emotional social-networking distress: Who do you follow? And, more importantly, if people you know in real life follow you on Twitter, do you have to follow them back? Nothing I’ve learned from my experience on other social networking sites has prepared me for this dilemma. LinkedIn is easy. I treat it as a professional address book. If I’ve met you in person or had a professional interaction with you, I’ll connect with you on LinkedIn. Facebook is the same but for purely social interactions. If I’ve met you in a social setting, I’ll connect with you on Facebook. Of all the services I know, Google+ is the closest to Twitter, since it doesn’t enforce reciprocal befriending. However, Google+ is easy too, because nobody uses it anyway, as far as I can tell. And in any case, Google+ always gives you the option to put people into the circle for “people I know but don’t really care about.”\nSo here are my Twitter rules, for now: If you’re a student in my lab, I’ll follow you, because I want to get to know you better. If you’re a family member, I’ll follow you, because it would be embarrassing not to. If I’m genuinely curious about you or your work, I’ll follow you. If I’m unsure if I should follow you or not, I’ll hold off for now. Since I’m still figuring all of this out, I’d rather have the list of people I’m following grow slowly than add a bunch of people right away and have to later remove them when I realize I wasn’t interested in them afterall.\n","date":1376870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376870400,"objectID":"4cb59f9c0be8f8f0f2506aa2ffd64404","permalink":"/blog/2013/08/19/the-emotional-distress-of-being-a-new-twitter-user/","publishdate":"2013-08-19T00:00:00Z","relpermalink":"/blog/2013/08/19/the-emotional-distress-of-being-a-new-twitter-user/","section":"blog","summary":"All this social media stuff is hard.","tags":["Facebook","Google","Linkedin","Twitter","Social networking"],"title":"The emotional distress of being a new Twitter user","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Science"],"content":"  This is a post I originally wrote for my lab webpage. I’m reproducing it here (with minor edits) as an exercise in getting to know this blogging platform.\nConfusing significance and effect size Statistical significance (a low P value) measures how certain we are that a given effect exists.\nEffect size measures the magnitude of an effect. What exactly effect size is depends on the analysis, examples are a correlation coefficient, the difference in means for a t test, or the odds ratio for a contingency-table analysis.\nMany results we encounter in the real world are highly significant but of low magnitude. For example, if you knew with near certainty that a particular dietary supplement extended your life span, on average, by 2 weeks, would you care? Probably not. Even though the finding is highly significant (near certain), the magnitude of the effect is so low that it basically doesn’t matter. Yet it is common in scientific studies, and in press reports about them, to only emphasize the significance of a finding but not the magnitude. Sometimes authors don’t even bother to report effect sizes at all, they only report P values and point out how significant their results are. This is bad science. The P value is primarily a measure of the data set size. The larger the data set, the lower the P value, all else equal. To be important, an effect has to have a large magnitude; just being highly significant is not enough.\n Correlation is not causation This issue is pretty well known, yet people fall into this trap over and over again. Just because one quantity shows a statistical association (correlation) with another variable doesn’t mean that one of the two variables causes the other variable. This problem is more common in press reporting about scientific studies than in the studies themselves. For example, a study might report an association between cell-phone use and cancer. In the study, the authors might be careful to point out that they don’t know why increased cell-phone use correlates with cancer in their study population, and that the underlying cause might be unrelated to cell-phone use (e.g., for some reason exposure to a carcinogen correlates with cell-phone use in the study population). Yet, inevitably the press release about this study will read “cell-phone use causes cancer.”\nIn general, to reliably assign cause and effect, one needs to carry out an experimental study. In an experimental study, a population is randomly subdivided into treatment and control groups, and the treatment group is subjected to a well-defined experimental manipulation. For example, people are divided into two groups at random, one group is made to use a cell phone for 2 hours each day, the other group is forbidden from using a cell phone ever. After 5 years, count which group developed more cancer. By contrast, studies that only show association but not causation are usually observational studies. In such studies, we simply observe what variables are associated with each other in a sample.\n Focusing on tenth-order effects and ignoring first-order effects This issue is not so much an issue of poor statistics but rather of poor placement of emphasis. It is very well explained by Peter Attia here, so I’ll not elaborate on it any further here.\n Aggregation by quantiles erroneously amplifies trend In many situations, one would like to know how one quantitative variable relates to another. For example, we might be studying a certain bird species and ask whether the amount of a certain berry that males of that species eat has an effect on the mating success of those males. The canonical (and correct) way to study such questions is via correlation analyses.\nHowever, it is surprisingly common to see analyses where instead one of the variables is aggregated into quantiles (groups of equal size) and the second variable is presented as an average of the quantiles of the first variable. In the above example, we might classify birds into four groups (quartiles) by their berry consumption (lowest 25%, second lowest 25%, and so on) and then plot the mean mating success within each group as a function of the quartile of berry consumption. Such an analysis is misleading, because it erroneously amplifies any relationship that may exist between the two variables.\nLet’s illustrate this issue with some simulated data, using R. First we generate two variables x and y, weakly correlated:\nn \u0026lt;- 10000 # sample size x \u0026lt;- rnorm(n) # generate first set of normal variates y \u0026lt;- 0.1*x + 0.9*rnorm(n) # generate second set, weakly correlated with first cor.test( x, y ) This is the output from the cor.test() function:\n# Pearson\u0026#39;s product-moment correlation # # data: x and y # t = 10.485, df = 9998, p-value \u0026lt; 2.2e-16 # alternative hypothesis: true correlation is not equal to 0 # 95 percent confidence interval: # 0.084862 0.123636 # sample estimates: # cor # 0.1042886  The correlation is highly significant (P \u0026lt; 2.2e-16) but weak (r = 0.10). The variable x explains only 1% (that is the square of the correlation coefficient, r^2) of the variation in y. In terms of the birds example, this could mean that while berry consumption is indeed related to mating success, the relationship is so weak as to be virtually meaningless. (Knowing how many berries a given male bird ate tells me pretty much nothing about his specific mating success.)\nFigure 1 shows the relationship between x and y. As indicated by the correlation analysis, knowing x doesn’t really tell us anything about y.\n Figure 1: Relationship between x and y in our made-up example dataset.  Now let’s aggregate the data into quantiles of x and plot the mean +/- the standard error of y within each quantile of x:\n# calculate to which quantile each x belongs qn \u0026lt;- 10 # number of quantiles q \u0026lt;- quantile(x, probs = seq(0, 1, 1/qn)) q[qn] \u0026lt;- q[qn] + 1 # make sure the last quantile is larger than max(x) quant.x \u0026lt;- tapply(x, 1:n, (function(x) sum(x\u0026gt;=q))) # calculate means and SEs of y per quantile library( Hmisc ) # for errbar plot mean.quant \u0026lt;- tapply(y, quant.x, mean) SE.quant \u0026lt;- tapply(y, quant.x, (function(x) sd(x)/sqrt(length(x)))) errbar(1:qn, mean.quant, mean.quant+SE.quant, mean.quant-SE.quant, xlab=\u0026#39;quantiles(x)\u0026#39;, ylab=\u0026#39;mean(y) for quantile\u0026#39;)  In this example, we chose 10 quantiles. The resulting graph is shown in Figure 2.\n Figure 2: Mean y (+/- standard error) as a function of quantiles of x.  Suddenly, it looks like there is a very clear and quite strong relationship between x and y. If you were given only this graph, you might think that knowing how many berries a male eats would tell you a lot about that male’s mating success. Indeed, the top quantile, on average, has an approximately 200% higher y (200% higher mating success) than the bottom quantile.\nAlso note the apparent nonlinearity. The top and bottom quantiles seem to have very much increased/reduced y relative to the middle ones. Note that we see no such feature in the scatter plot of the original x and y values.\nFinally, the exact same data look quite different depending on the exact number of quantiles. Figure 3 shows the same data presented with 6 quantiles.\n Figure 3: Mean y (+/- standard error) as a function of quantiles of x. Now using 6 instead of 10 quantiles.  And Figure 4 shows the same data presented with 20 quantiles.\n Figure 4: Mean y (+/- standard error) as a function of quantiles of x. Now using 20 instead of 10 quantiles.  As you can see, the same data look quite different depending on the exact number of quantiles we use.\nSo, whenever somebody shows you data aggregated into quantiles, ask for an x–y scatter plot and a correlation coefficient. And then square the correlation coefficient and evaluate the % variance explained. A squared correlation coefficient below 0.1 (r \u0026lt; 0.3) means the effect is pretty much non-existent, regardless of how low the P value is.\n ","date":1376784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376784000,"objectID":"8e7145a85873c65d9e17e593df34b4c8","permalink":"/blog/2013/08/18/common-errors-in-statistical-analyses/","publishdate":"2013-08-18T00:00:00Z","relpermalink":"/blog/2013/08/18/common-errors-in-statistical-analyses/","section":"blog","summary":"Does your analysis mean what you think it means?","tags":["Correlation","Effect size","Statistics"],"title":"Common errors in statistical analyses","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Professional development"],"content":"  At this year’s BEACON conference, Art Covert and I gave a presentation on how to give engaging presentations. The slides for my part of the presentation are available here. If you browse through the slides, you’ll see that some of them are rather text-heavy. I did this on purpose, to demonstrate that text-heavy slides are not the bane of engaging talks, if presented appropriately. By all accounts, despite the amount of text on my slides, my presentation was engaging.\nOne of the first recommendations that we usually give our students is to put less text on their slides, and instead use images, drawings, and diagrams. I wholeheartedly agree with this recommendation in principle, and for most of my presentations I spend a lot of time developing graphics instead of text. However, I think that there are other recommendations that we should emphasize first; the text-heavyness of slides really is a minor issue. After all, one can absolutely give an excellent presentation using text-heavy slides, and one can also give a terrible presentation using slides with very little text.\nThus, I propose to replace the advice of using less text with the following advice, which I call Claus’ 1st law of giving presentations:\n All text on slides needs to be read aloud, word for word.\n (Similarly, all visual elements need to be pointed out and explained.) The problem with text-heavy slides arises when the presenter paraphrases the text or, even worse, talks about something completely different while displaying the text-heavy slide. The audience members cannot process two different streams of information, one visual and one auditory, at the same time. Hence, they have to make the decision of either listening or reading. Whatever decision they make, they will likely feel that they missed something, and they will be more likely to disengage from the presentation altogether. I believe in particular that when audience members start reading instead of listening to the presenter, the presenter has lost them at that point and will likely not get them back for the remainder of the talk.\nBy contrast, if the presenter reads the text word for word, the visual and the auditory cues reinforce each other. The audience will be more engaged and less likely to drift mentally. For the same reason, I like text to appear line by line, as I read it, rather than all in one block. Again, this increases the synchronicity between the visual and auditory cues and gives the audience members less opportunity to drift. If you ever get the chance to see a talk by Steven Pinker, observe how he reinforces auditory and visual cues. Nearly his entire talk is spelled out word for word on his slides. His slides basically serve as sub-titles to his voice. (You can probably find an example of this on YouTube. If you do, please post the link in the comments below.)\nNote that an additional benefit of my 1st law is that you can never make slides too text-heavy, because there is a limit to how much text you can read during the time alotted for your presentation.\n","date":1376784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376784000,"objectID":"5485721ccea42ea474b38d3ce68a739f","permalink":"/blog/2013/08/18/engaging-presentations-and-text-heavy-slides/","publishdate":"2013-08-18T00:00:00Z","relpermalink":"/blog/2013/08/18/engaging-presentations-and-text-heavy-slides/","section":"blog","summary":"Think of the text on your slides as subtitles to your talk.","tags":["Slide design","Presentations","Public speaking"],"title":"Engaging presentations and text-heavy slides","type":"blog"},{"authors":["Claus O. Wilke"],"categories":["Writing"],"content":"  I’ve always wanted to write a book. For years, I have considered possible topics, thought about detailed contents, even drafted a first chapter or two. Yet I have never followed through. I’m right there with the millions of people who fantasize about being a great author but never do anything about it. However, unlike most of these people, I actually am an author. Writing is a major part of my job. I have published thousands of pages, mostly in the form of scientific papers. I have written winning grant proposals. I have edited journal articles and conference proceedings. I have even taught university-level classes on how to be a successful writer. Surely, if I seriously wanted to write a book, I could.\nSo why haven’t I? The simple truth is that I have a short attention span and get bored easily. I would find it quite difficult to stay engaged with a single topic for as long as it would take to write the book. Chances are, I’d write a few chapters and then I’d lose interest. At that point, there’d be two possibilities: (i) I abandon the project. (ii) I push through regardless. Of course, of those two possibilities, only the latter would result in a finished book. And the latter possibility is also the much more unpleasant one. At some point in my life, I may still embark on this book project, but for now I admit defeat. I have yet to find a book idea for which pushing through regardless seems worthwhile.\nSo here I am. I enjoy writing. I enjoy writing things other than just scientific papers. In my humble opinion, I’m quite good at writing, or at least not entirely terrible. So let’s try this blogging thing. Maybe my short attention span is better matched to blogging than to writing books. I know I can stay focused for long enough to complete one blog post, and maybe even a series of blog posts about the same topic. Who knows, over time I might even collect enough material on this blog that eventually I can collate parts of it into a coherent book of sorts.\nSo with this post, I open this blog. I make no promises about specific topics I’ll blog about, nor about post frequency or longevity of this project. I might be too lazy to update this blog on a regular schedule. I might get bored of blogging entirely, regardless of subject matter. Either way, for now I’ll try this out and see where it goes.\n","date":1376697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1376697600,"objectID":"c8db9c03d8761b3c91ff927e0f688b37","permalink":"/blog/2013/08/17/a-blog-seriously/","publishdate":"2013-08-17T00:00:00Z","relpermalink":"/blog/2013/08/17/a-blog-seriously/","section":"blog","summary":"My very first blog post.","tags":["Blogging","Books"],"title":"Why not write a book?","type":"blog"},{"authors":null,"categories":null,"content":"This is a list of all blog posts ever posted, in reverse chronological order.\n 93. Fundamentals of Data Visualization (01/23/2018)   92. Move over Strunk and White: My all-time favorite books on writing (11/12/2017)   91. Springer's abusive licensing demands (10/16/2017)   90. Goodbye Joyplots (09/15/2017)   89. Do you have to publish papers to obtain a PhD? (01/06/2017)   88. How to reject a rejection (01/02/2017)   87. Reading and combining many tidy data files in R (06/13/2016)   86. The one time I failed to parasitize an established clinical researcher (01/24/2016)   85. When will that paper be ready? (12/28/2015)   84. Don’t use the passive voice? (12/19/2015)   83. Hiding journal names from your publication list stinks (12/08/2015)   82. Formatting figure captions and tables (11/24/2015)   81. The Google Scholar preprint bug redux (10/08/2015)   80. How to not mess up your bibliographies with Bibtex (10/02/2015)   79. Avoiding the official style (08/26/2015)   78. Goodbye Squarespace, Hello Github (08/06/2015)   77. Safety projects (07/01/2015)   76. cowplot R package now available on CRAN (06/04/2015)   75. Beyond bar and line graphs (04/29/2015)   74. PLOS ONE publishes analysis of grant writing costs and benefits (03/24/2015)   73. Teaching a new introductory class in computational biology and bioinformatics (02/04/2015)   72. What constitutes a citable scientific work? (01/02/2015)   71. Post-publication review of the PLOS ONE paper comparing MS Word and LaTeX: How not to compare document preparation (12/27/2014)   70. Perfectly smooth transition between fixed and variable positioning of HTML elements using CSS and Javascript (12/23/2014)   69. How to prepare an article for resubmission, Part II (12/18/2014)   68. Relationship between h index and total citations count (12/08/2014)   67. How Google Scholar discourages young scientists from posting preprints (12/02/2014)   66. How to prepare an article for resubmission (11/16/2014)   65. The Google Scholar preprint bug (11/01/2014)   64. Should peer-review be double-blind? (10/18/2014)   63. How to schedule a committee meeting (10/14/2014)   62. In defense of anonymous peer review (10/12/2014)   61. To grid or not to grid (10/07/2014)   60. R Markdown, the easiest and most elegant approach to writing about data analysis with R (10/04/2014)   59. A critique of Chatterjee et al., The Time Scale of Evolutionary Innovation, PLOS Comp. Biol. 2014. (09/24/2014)   58. A grammar of data manipulation (09/17/2014)   57. Double Jeopardy (09/13/2014)   56. Keep your data tidy, Part II (07/21/2014)   55. Keep your data tidy (07/20/2014)   54. Surviving the pre-tenure years at an R1 university (07/12/2014)   53. Eat more gluten? Maybe not. (07/11/2014)   52. Share your preliminary work with other people, even if you think it’s crap (07/08/2014)   51. How to develop a research question, Part II (06/18/2014)   50. How to develop a research question (06/15/2014)   49. Uri Alon on creativity and staying sane in science: “Yes and ...” (06/14/2014)   48. How to pick a thesis committee (01/26/2014)   47. 6 reasons to do your graduate work in the lab of a junior PI, and 6 reasons not to (01/25/2014)   46. Understanding the graduate-school interview or recruitment event (01/14/2014)   45. What does it take to be a computational biologist? (01/10/2014)   44. How glamour journals rose to prominence, and why they may not be needed anymore (01/04/2014)   43. The value of pre-publication peer review (12/21/2013)   42. Is there an avalanche of low-quality research, and if so, must we stop it? (12/21/2013)   41. Excess ambition—the eternal flaw of all PhD thesis proposals (12/07/2013)   40. No one reads your paper either (11/03/2013)   39. Weight doesn’t matter (10/30/2013)   38. Use fine-grained sectioning in your grant proposals (10/28/2013)   37. Ten simple rules for reproducible computational research (10/26/2013)   36. Giving effective presentations (10/20/2013)   35. What is the value of a mentor? (10/19/2013)   34. The critical need in a grant application (10/17/2013)   33. Which grants get funded at single-digit funding rates? (10/17/2013)   32. Virtual Books (10/13/2013)   31. To write well, learn how to read (10/08/2013)   30. Articles! (10/01/2013)   29. Why I lift weights (and so should you) (10/01/2013)   28. Mobile apps—the bane of the modern mobile web experience (09/29/2013)   27. How to choose the right lab for graduate school (09/29/2013)   26. Writing paragraphs that make sense—the topic and the stress position (09/26/2013)   25. A blog needs a catchy title (09/23/2013)   24. Silence your inner critic (09/22/2013)   23. It’s easier to write when you know what you want to say (09/18/2013)   22. Warm up before you write (09/16/2013)   21. Do we know anything about nutrition? (09/13/2013)   20. How good is good enough? (09/10/2013)   19. The axis labels are too damn small (09/10/2013)   18. Should you list on your cv a paper that is in review or in preparation? (09/10/2013)   17. From undergraduate to faculty member: Critical decision points in the academic career (09/06/2013)   16. A year without breakfast (09/04/2013)   15. A review of the therapeutic uses of very-low-carbohydrate (ketogenic) diets (09/01/2013)   14. My new job (09/01/2013)   13. Why graduate students get a reasonable deal—A response to the anonymous grad student in the Guardian (08/31/2013)   12. Is consumer software creating a new generation of computer illiterates? (08/30/2013)   11. Writing a scientific paper in four easy steps (08/29/2013)   10. When should you stop doing science and start writing a paper? (08/26/2013)   9. The great weight-loss mystery (08/25/2013)   8. How to approach professors by email (08/23/2013)   7. A call for lightning talks at scientific conferences (08/22/2013)   6. My gripes with prezi, and some suggestions for making good prezi presentations (08/21/2013)   5. Should you as a scientist be active on LinkedIn? (08/20/2013)   4. The emotional distress of being a new Twitter user (08/19/2013)   3. Engaging presentations and text-heavy slides (08/18/2013)   2. Common errors in statistical analyses (08/18/2013)   1. Why not write a book? (08/17/2013)   \n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a605f326d3cd86ee31c3b9b68b11f06","permalink":"/toc/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/toc/","section":"","summary":"This is a list of all blog posts ever posted, in reverse chronological order.\n 93. Fundamentals of Data Visualization (01/23/2018)   92. Move over Strunk and White: My all-time favorite books on writing (11/12/2017)   91. Springer's abusive licensing demands (10/16/2017)   90. Goodbye Joyplots (09/15/2017)   89. Do you have to publish papers to obtain a PhD? (01/06/2017)   88. How to reject a rejection (01/02/2017)   87.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":" Many of my blog posts can be considered sections in books that I might have written but probably never would have. So, here I\u0026rsquo;m trying to assemble these books as they get written.\nScientific Writing Chapter 1: Writing productively  Warm up before you write Silence your inner critic It’s easier to write when you know what you want to say When should you stop doing science and start writing a paper? When will that paper be ready? No one reads your paper either  Chapter 2: Constructing meaningful sentences and paragraphs  Avoiding the official style Writing paragraphs that make sense—the topic and the stress position Don\u0026rsquo;t use the passive voice? Articles! To write well, learn how to read  Chapter 3: Writing scientific papers, grants, etc.  Writing a scientific paper in four easy steps How to prepare an article for resubmission How to prepare an article for resubmission, Part II How to reject a rejection The critical need in a grant application Use fine-grained sectioning in your grant proposals  Chapter 4: Creating professional documents, graphs, and figures  Formatting figure captions and tables The axis labels are too damn small To grid or not to grid How to not mess up your bibliographies with Bibtex  Chapter 5: Miscellaneous topics  Move over Strunk and White: My all-time favorite books on writing  Professional Development as a Scientist Chapter 1: The academic career  From undergraduate to faculty member: Critical decision points in the academic career How good is good enough? How to choose the right lab for graduate school What is the value of a mentor? Surviving the pre-tenure years at an R1 university  Chapter 2: Being successful in graduate school  Understanding the graduate-school interview or recruitment event 6 reasons to do your graduate work in the lab of a junior PI, and 6 reasons not to How to pick a thesis committee How to schedule a committee meeting Excess ambition—the eternal flaw of all PhD thesis proposals Do you have to publish papers to obtain a PhD?  Chapter 3: Giving presentations  Giving effective presentations  Chapter 4: Applying for jobs  Should you list on your cv a paper that is in review or in preparation?  Chapter 5: Applying for funding  Which grants get funded at single-digit funding rates? The critical need in a grant application  Chapter 6: Miscellaneous topics  How to develop a research question How to develop a research question, Part II Safety projects Share your preliminary work with other people, even if you think it\u0026rsquo;s crap What does it take to be a computational biologist? Should you as a scientist be active on LinkedIn? How to approach professors by email  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4d20b9adc49fc07478957be3a8d36f8e","permalink":"/virtualbooks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/virtualbooks/","section":"","summary":"Many of my blog posts can be considered sections in books that I might have written but probably never would have. So, here I\u0026rsquo;m trying to assemble these books as they get written.\nScientific Writing Chapter 1: Writing productively  Warm up before you write Silence your inner critic It’s easier to write when you know what you want to say When should you stop doing science and start writing a paper?","tags":null,"title":"Virtual Books","type":"page"}]